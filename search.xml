<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[世界需要什么样的智能系统]]></title>
    <url>%2F2019%2F07%2F16%2FWhat_kind_of_intelligent_system_does_the_world_need%2F</url>
    <content type="text"><![CDATA[本文摘自吴翰清-世界需要什么样的智能系统(节选) 科技的进步是为了解放生产力我将生产力的进步分为五个阶段：体力劳动，机械化，电气化，信息化，智能化。其中每一次科技的进步，都会带来生产力的解放，对社会的改变是巨大的。 在140年前发生的第二次科技革命，让电力深入到各行各业。自从中央发电站和交流电变压器等关键技术构建的电力基础设施成型后，获取电力的成本逐渐降低，各种各样的电气应用开始涌现，人们获取到了新的、稳定的能源。 我们现在知道电力最早是应用在电话、电报、电灯上的，也正是电气照明这一需求，拉动了电力基础设施的发展。因为在当时电力的用途比较单调，并没有今天这么琳琅满目的电器。在100年前爱迪生通用电气与威斯汀豪斯之间的主要竞争就是聚焦在电气照明领域。我们很难说在这个过程中，到底是电灯泡更重要，还是发电站更重要。我曾经比喻说当前云计算面临的窘境，就是「中央发电站」已经造出来了，我们有单集群上万台服务器规模的算力基础设施，但是「电灯泡」在哪里却没有找到。我们用「中央发电站」在点「煤气灯」，今天托管在云计算上的业务，大多数依然是「信息化系统」。而理想中的会消耗大量算力的应用，应当是「智能化系统」。我们一直在苦苦追寻云计算的「电灯泡应用」，却求之不得。 这里需要讲清楚「信息化系统」和「智能化系统」的区别。我认为「信息化系统」的本质是编辑数据库，一个业务系统如果存在大量人工交互，依赖于人提交表单来完成业务，那么就是一个信息化系统。而我理想中的「智能化系统」，应该是以自动完成任务为目的，以任务作为输入，以完成的结果作为输出，中间的过程应该是机器高度自动化完成的。以其完成任务的复杂度，来评价其智能程度的高低。 从这个角度看，「智能手机」并不智能，依然是个「信息化系统」。市面上形形色色的智能系统也都只是冠上了智能的名号在鱼目混珠。我并不是说「信息化系统」没有价值，信息化系统很有价值，但不是下个时代的东西。自从计算机技术发展以来，产生的各色各样的信息化系统极大地改变了世界，完成了从「电气化」到「信息化」转型升级的重要一步。这就是我们看到各色各样的计算机系统开始应用在各个领域，帮助人们更加高效的管理工作和提供服务。 互联网在这一过程中扮演了放大作用。我认为互联网本身并不是生产力，互联网只是连接了成千上万个信息化系统，从而具备了规模效应。互联网是规模经济，能让一个系统的价值实现上千倍、上万倍的放大，但是生产力是信息化系统本身提供的。能够接收互联网连接服务的终端，是浏览器，是 iOS 和 Android，这些端的演进本身是重要的。百度通过互联网连接了人和信息，腾讯通过互联网连接人和人，阿里通过互联网连接了人和信息化服务。但是这些都不是下一个时代的东西。 下一个时代会发生的事情，首先是出现智能化系统对信息化系统的升级换代，然后会出现通过互联网连接所有智能化系统的公司。智能化对信息化的升级换代，是一次巨大的生产力进步，处于社会变革中的商业公司的结局是适者生存。从历史来看，在信息化时代的PC操作系统升级换代到移动操作系统，其过程就是天翻地覆的。苹果的iPhone 发布之后，所有的开发者都不再给微软的 Windows 写软件，而转去给 iOS 写软件，对微软带来了强烈的冲击，如果不是微软后来又抓住了云计算的机遇，就很可能会从此一蹶不振。从商业发展的角度看类似事件一定会发生，在信息化时代的庞然大物很可能随着一次生产力的变革就变得无足轻重。那么现在所有的问题在于，未来世界需要的智能系统到底是什么？ 让机器获得智能，一直是计算机科学家孜孜以求的事情。在过去简单的专家系统，依靠经验和规则，也能处理简单的任务。但有一个弊病是对于专家经验未覆盖的异常情况，机器就不知道怎么处理了。所以后来出现了数据驱动诞生的智能。 我们看到当机器具备一定的智能后，就能处理相对简单的任务，从而部分地解放人的生产力，此时增加机器规模就等同于增加人力的规模。而机器智能和人的智能又各有所长，机器运算量大且不知疲倦，因此对于很多工作都有可能做到精细化管理。这往往能带来成本的节约。 比如在过去公交车的排班是按照经验，在一个线路里设置好公交车的数量，但是如果市民的出行情况发生波动时，公交车的供需关系之间一定会存在差异，有的线路会繁忙，有的线路则会空闲，从而出现资源的浪费。要解决这一问题需要先统计清楚每辆公交车每一趟的精确载客人数，再依靠机器智能精细化的调度公交车到不同的线路，就能在同等资源下实现效率最优。因此使用机器智能的好处是显而易见的。 五年前做不出大规模的机器智能系统我们看到在生产力发展的过程中，从信息化到智能化的这一转型升级正在到来，已经到了爆发的前夜。这得益于四项技术的成熟：云计算、大数据、IoT、网络连接技术。 我们知道机器智能当前的发展是得益于对脑科学的研究，以及算力的进步，让神经网络进化到了深度学习，从而在视觉、语音等领域有了重大突破。算力的重要性毋庸置疑，但是光有算力依然难以在实际的应用中取得成功，还需要其他几项技术的成熟。在当前的技术环境来说，云计算为智能提供了足够的算力，是算力基础设施；大数据技术提供了数据处理的方法论和工具，是数据基础设施（当前还没有垄断性的数据基础设施，碎片化严重）；IoT 技术将智能设备的成本降到了足够低，为部署丰富的神经元感知设备提供了基础；网络连接技术，从4G到5G，为数据的高速传输提供了重要基础。 如果有科技树这种说法的话，那么机器智能的大规模应用，就需要先点亮前四个技术，这是基础。在五年以前，这几项技术的成本是制约我们将智能技术大规模应用的主要瓶颈。到今天已经逐渐成熟了。 在一项新技术刚出现的时候，我们往往会遇到两个问题。 第一个问题是人才的稀缺性问题。我们知道一个懂深度学习或其他机器智能技术的博士生刚毕业的年薪可能比得上一个工作了十年的程序员。业界各处都需要机器智能，供不应求。 第二个问题是技术的成本问题。新技术刚出来的成本一定是昂贵的，就像云计算刚出来的时候也是先解决能力问题，再解决效率问题。我前些时看一个报告，AWS 的 EC2 推出到现在连续降价了57次。我们熟知的摩尔定律，计算的性能每18个月翻一倍，也就意味着同等算力的硬件每18个月会降一半的成本。机器智能作为新技术也有同样的规律，在一开始我们不要指望它的成本会足够便宜到能进入千家万户，新技术的普及需要时间。只是我们往往迫不及待。 这两个问题决定了机器智能在一开始的时候，应该首先被应用在对社会效率撬动最大的那个点上。从商业上我们要找到这样的场景，来让这项技术脱离实验室，走向社会，通过商业来源源不断的滋养这项技术的迅速成长。 世界需要什么样的机器智能系统这两个问题随着时间的推移很快就能解决。但今天产业界真正碰到的问题我认为是搞偏了方向。这体现在两个方面。 第一个问题是未来不应该存在一个「人工智能」的产业，我们今天的分类就分错了。就像自电力基础设施诞生以来，各行各业都需要用电，因此电力成为了一个关键生产要素。我认为未来智能也是一个关键生产要素，每个行业都需要，因此不需要单独划分一个人工智能产业。单独搞了一个人工智能产业，反倒不知道这些公司在干什么了，这些公司自己也产生了困惑。最终应该像今天的零售业一样，每个做零售的都有个电商部门，会通过互联网来做营销和销售。未来每个企业也应该有一个部门，就是负责他们的智能系统的建设与训练。要像训练宠物一样训练智能系统，使他具备智能。这不是某一家人工智能公司要做的事情，而是每家公司都要自己做的事情。 第二个问题和机器智能技术的发展有关。因为最近这次机器智能的热点是从深度学习开始，在视觉、语音等领域有了巨大突破，因此产业化后的企业往往都是在做视觉、语音、自然语言处理等工作。但是我们千万别忘了完整的人脑智能是从「感知」到「行动」，并通过不断的反馈完成高频率的协同，最终诞生了智能。 只做「感知」是一个巨大的误区，从技术上讲没有问题，但是从商业上讲创造的社会价值就很有限了，因为其解放的生产力相对是有限的。 从生产力发展的角度来讲，评判一个智能系统的社会价值，应该以它解放生产力的多少来衡量。只做「感知」就是只能看，但是做了这么多大型项目后，我发现所有的价值创造都是在于「处置」环节。因此只做感知，很难讲清楚投入产出是否值得，但是一旦开始进入到「行动」环节，就会开始解放生产力，价值是可被量化的。这里的行动，是机器智能实现了对人力或其他设备的调度。 实际上从技术发展的角度看，我们早就拥有了让机器智能做决策的能力。搜索引擎和个性化推荐，就是典型的通过机器智能做决策。通过每天处理海量的数据，最终实现精细化的匹配。 所以我认为一个完整的「智能系统」，是包含了「感知」与「行动」，其中支撑行动的是决策和调度的技术。而衡量这个智能系统是否有价值的标准，是看其解放的生产力的多少。 遗憾的是，到今天为止我认为业界并不存在一个理想的「智能系统」。业界当前的状态我称之为「有智能，没系统」。很多人工智能的创业公司拥有局部的智能能力，比如视觉、语音、NLP、知识图谱、搜索、推荐等中的一项或多项技术，但是很少有公司有完整的技术栈。而像 BAT 等公司具备完整的技术栈，但是却并没有将所有的技术整合成为「感知」+「行动」的一个完整系统，而是各项技术以碎片化的形式存在。尤其是将所有技术应用到某一个具体场景中解决某一个具体问题的，更是寥寥无几，而这正是催生出这一智能系统的关键所在。所以这是一个工程化的问题，工程化的挑战在于整合所有智能技术，实现完整的「感知」+「行动」能力，并有效的控制成本，实现对开发者友好的接口。 在智能技术的角度来看，「自动驾驶」和「智能音箱」是两个完整的从「感知」到「行动」闭环的场景。我认为这两个场景可以用来打磨机器智能技术，但是当前在商业上比较难成功。「自动驾驶」解放了所有的驾驶员，对解放生产力的价值非常明显，但是因为受制于今天城市的道路基础设施，因此对老城市的意义不大。今天城市的道路不是为自动驾驶设计的，也很难容纳下自动驾驶的汽车。因此自动驾驶更适合航空、航海、物流等领域，商业范围一下小了很多。「智能音箱」综合了多项机器智能技术，其核心技术「对话机器人」被称为人工智能领域的圣杯，想要做好难度相当之大。但是「智能音箱」当前的阶段对家庭中各种任务的生产力解放极其有限，价值很难讲清楚，最后沦为玩物的可能性比较大。尽管如此，随着时间的推移，随着基础设施的更新换代，这两项技术也会逐渐焕发出他们的生命力。 如果用航空业来比喻的话，今天的智能技术，就好比造飞机，市面上已经有了很多零件和引擎，但是所有的厂商都拿着零件当飞机卖，客户以为他买了一架飞机，其实只是买了个零件（因为生产力并没有得到多大的解放）。而今天真正的难点在于飞机设计图纸都还没有。 所以我打算先画一张，造架飞机玩玩。 构建智能时代飞机想要真正飞上天，还需要几个东西。 首先是飞行员。飞行员不一定要懂得怎么造飞机，造飞机是个门槛很高的活。但是飞行员要懂得怎么开飞机，最后还要让人人都能坐飞机。我认为飞行员就是未来各个企业里智能部门的员工，他们负责训练买来的智能系统，让智能系统真正具备智能。由于各个企业拥有的数据的不同，以及「飞行员」技能的高低和责任心，最后的各个企业的智能系统的聪明程度也会出现差异。世界是丰富多彩的。 其次是航道。我认为航道依然是基础设施提供商的，包括运营商、云计算厂商等。 最后是机场。机场需要负责所有航班的调度和协同，为所有的飞机提供服务。这是最有意思的地方。我认为「机场」是最后真正的商业模式，就像苹果的 AppStore 一样。 我认为在智能时代的「机场」，最重要的工作是给机器智能系统提供服务，而并非给人提供服务。 想象一下未来互联网里，70%-80%的人口是机器智能，他们处理了未来世界的绝大多数工作，而每一个机器智能又是有一个主人的。其主人可以是个人，也可以是组织，但都是有主权的。每一个机器智能存在的目标都是为了完成某个或多个任务。那么为所有的机器智能提供服务，就会是一个巨大的商业模式。 机器智能系统的自动协同是通往未来的关键路径 同时我也认为当前的机器智能产业，过于重视人与机器的交互，而忽视了机器与机器的交互。而后者才是更重要的事情。因为人与机器的交互依然是回到了信息化系统的老路上去，而机器与机器的自动协同，则是在进一步将智能系统的价值实现规模放大。 因此未来有必要给所有的机器智能定义一套语言，他们之间的交流可以像人一样拥有自己的语言，实现简单的逻辑。而所有机器智能之间的交互与协同，是不需要人工干预的，就像你家的孩子与邻居家的孩子自己会去玩耍一样，你不需要干预到他们的交流之中，他们自己会各取所需地完成各自的任务。 以「一网通办」的业务举例。在当前一网通办的主流实现办法是将政府各委办局的数据实现全量汇聚后，进行数据治理，并梳理流程，重塑业务。这种大数据应用的思路依然是停留在信息化建设的老路上，其弊端是想推动新技术落地的前提是流程先改革，同时各个不同地区的高度定制化导致很难在全国实现规模化的产品。但其实也可以有另外一种智能化的建设思路，让每个委办局自己建一个机器智能系统，其任务就是代替公务员处理各自的窗口业务。当市民来提交一个申请时，经过认证后，该委办局的机器智能系统就根据所需材料，自行向其他委办局的机器智能系统发出协同请求，经过几轮机器智能之间的交流和协同之后，市民很快就得到了他想要的结果。这种多个机器智能系统之间自动协同的机制，对流程的冲击明显会小很多。 机器智能之间的交互与协同需要通过网络连接到一起，但安全性是可控的，因为是业务之间的协同，而并非数据本身发生了交换。因为每一个机器智能都有自己的主人，所有的训练过程也都发生在其主体内部，因此数据并不需要被拿出来交换共享。主人可以设定机器智能什么能说，什么不能说，所有的安全控制都发生在智能系统内部，而一旦连接到互联网要与其他机器智能协同或使用「机场」提供的服务，就会转为「默认不信任」模式。 至于机器智能系统到底部署在公共云还是专有云，这并不是一个重要的问题，主人爱部署在哪里就部署在哪里。所以时至今日，云计算依然有被管道化的危险，就像运营商被互联网内容提供商管道化一样，未来云计算厂商也可能会被智能厂商管道化。因为云计算和大数据都不是智能。 A组也因此，为了以上这些构想，我受命在阿里云成立「A组」。「A组」成立的使命就是为了构建出这一机器智能系统，让智能时代更快的到来。 我认为这是一件需要整个社会共同努力三十到五十年的事情，就像在过去的三十到五十年我们在信息化建设上付出的所有努力一样。 以上，就是我想对世界说的话。 我说，你听。 阿里云-GTS-A组 吴翰清]]></content>
      <categories>
        <category>Quote</category>
      </categories>
      <tags>
        <tag>智能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[存在主义心理动力学]]></title>
    <url>%2F2019%2F06%2F09%2Fexistential_psychodynamics%2F</url>
    <content type="text"><![CDATA[以下内容节选自『存在主义心理治疗』-欧文・D・亚隆 存在主义观点强调一种不同类型的基本冲突: 既不是与被压抑的本能抗争之间的冲突，也不是与内化了的成人之间的冲突。而是，在个体面对存在的既定事实时引发出来的冲突。而我所说的存在的“既定事实”，意指某些终极关怀、某些人之所以为人的必然特质。 怎样发现这些既定事实的性质？在某些意义上来说，这个任务并不困难。方法就是深度的个人反思。条件很简单：从充斥着我们每个人经验世界的日常琐事中抽离出来，给自己以独处、沉默、时间以及自由。如果我们能够清除或者“囊括”日常生活，如果我们对于自己在世界上的“处境”，对于我们的存在、我们的界限、我们的潜力进行深刻的反思，如果我们深入到所有层面的最底层，我们必然会面对存在的既定事实，面对“深度结构”，我之后将称之为“终极关怀”。这些反思过程常常为某些紧急体验所催化。这些常被称作“边缘”或者“临界”状态，包括如下体验：面对自己的死亡、面临某些重大不可逆转的决定或者某些深具意义的图式在眼前坍缩。 本书涉及四个终极关怀：死亡、自由、孤独和无意义。个体与这些生命真相的正面交锋，构成了存在主义动力性冲突的内容。 死亡。最显而易见的、最容易理解的终极关怀就是死亡。我们现在存在，但是总有一天，这种存在会终止。死亡将如期而至，没有逃脱之路。这是一个恐怖的真相，能引发我们巨大的恐惧。用斯宾诺莎的话来说，“每一事物都在尽力维持自身的存在”；而存在的一个核心冲突就是，对死亡必然性的意识与继续生存下去的愿望之间的张力。 自由。另一个相对来说不太容易理解的终极关怀是自由。一般来说我们都认为自由是一个毋庸置疑的积极概念。有史以来，人类不是一直都在渴望并为自由而奋斗吗？然而从终极层面来看，自由是与忧惧偶联在一起的。在存在的意义上，“自由”意味着外部结构的空白。与日常经验相反的是，人类并不是进入(和离开)一个拥有内在设计、高度结构化的宇宙。实际上，个体对他自己的世界、生活设计、选择以及行为负有全部责任–也就是说，个体是自己世界的创造者。“自由”在这种含义上，带有一种可怕的暗示：它意味着在我们所站立的地方并不坚实–什么都没有，是空的，无底深渊。所以，存在主义一个关键的动力性冲突就是，我们无根基的处境与我们对根基与结构的渴望之间的冲突。 存在性孤独。第三个种终极关怀是孤独–不是伴随着寂寞的人际性孤独，也不是个人内心的孤独(与自身的其他部分隔离)，而是一种根本性孤独–既与生命隔绝，也与世界隔绝–隔绝在所有其他孤独之下。无论我们之间变得有多么亲密无间，仍然存在一个最终无法逾越的鸿沟；我们每个人都是独自一人进入这种存在，同时也注定要独自离开。一方面是我们对自身绝对孤独的意识，另一方面是对接触、保护的渴望，以及成为一个更大整体的一部分的愿望，存在性冲突就是这两个方面之间的张力。 无意义。第四个终极关怀或存在的既定事实是无意义。如果我们注定得死，如果我们构建我们自己的世界，如果每一个人最终都是独自一人深处于一个无关紧要的世界之中，那么生命有什么意义？我们为什么要活着？我们应该怎样活着？如果并不存在为我们预先设计的蓝图，那么我们每个人就必须构建自己的生命意义。然而，一个人自己创造出来的意义能否坚强到令其容忍生活？人类这种寻找意义的生物，却被投入到本身无意义的宇宙之中，于是，存在的动力性冲突便从进退维谷的境地中滋生出来。 不止听一个人说过，哲学要浅尝辄止。好像的确是这样，，浅尝辄止，哲学帮我们构建更独立的思考方式，而这种思考方式让我们保持自我，不会流于众人。然而，哲学再往深处，便是深渊。这深渊便是虚无主义，像上面提到的『无意义』。无数个周末午休的后醒来，惊讶于周末的无所事事与时间的悄然流逝–周末午后的贤者模式。唯有读书、写代码、看电影或者其他的沉浸式活动让人暂时从虚无主义中回过头来，沾沾烟火气，我还活着，接地气的活着。 这四个终极关怀中，，死亡于我，并不可怕。只希望 骄傲的人应该死于一场意外，让一切都猝不及防。事实上，在某种程度，我甚至有些期待：死亡是多么难得的一次经历！难得到一生只能经历一次。上面也有提到『反思过程常常被某些紧急体验所催化』，死亡便是其中之一。我想，在哪个临界点，我们一定『会像放电影一样，人生过往历历在目』。那一刻，完美的人生应该说出一句话，，『这辈子，没遇到一个坏人』。 自由于我，，接触到哲学之后，便认识到完美的自由是相对的。所以，很能理解为什么要有文化审查，为什么要在互联网世界中修建长城，，诸如此类。当然，也有痛苦：我还有好多欲望，欲望让人变得不那么自由。 孤独于我，，已经试验性的独自生活了一年多。一天中，有16h+的时间，我是满意的。唯有独自下班到回家这期间会有些，，孤独。也不是不能忍受，毕竟只有那么一小段。我还可以通过哪些沉浸式的活动，让自己活在自己的世界中，活在云端。偶尔，偶尔也会有那么一个念头：来块儿黑客帝国中的牛排也不错喔~(这块牛排真的太诱人了，满足了我对牛排的所有美好想象[彪眼泪])。 无意义，，呐，这个就可怕多了。深渊，我害怕的深渊。如果有一天我决定结束自己的生命(短期内应该预见不到这一天)，那一定是因为这个原因。之所以，读这本书，也是因为不想放弃治疗。周末午后的贤者模式还是回来，希望能从这本书当中，找到一些答案。第十五页中有提到： 要处理生命中无情存在的事实，只有两种方法–对真相感到焦虑，或者否认–而两者都令人不快。塞万提斯借着不朽的堂吉诃德之口说出了这个问题：“你要做疯狂的智者，还是健全的蠢货？”存在主义的治疗立场拒绝这种两难，托马斯・哈代说：“如果有变得更好的方法，就是彻底看一看最坏的情形。”这句话对我将要描述的治疗方法是个很好的写照。 – 有删改 至此，，好期待呢~]]></content>
      <categories>
        <category>Quote</category>
      </categories>
      <tags>
        <tag>存在主义心理治疗</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于 HashSet]]></title>
    <url>%2F2019%2F04%2F09%2Fabout_HashSet%2F</url>
    <content type="text"><![CDATA[HashSet 的 DOC 注释12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * This class implements the &lt;tt&gt;Set&lt;/tt&gt; interface, backed by a hash table * (actually a &lt;tt&gt;HashMap&lt;/tt&gt; instance). It makes no guarantees as to the * iteration order of the set; in particular, it does not guarantee that the * order will remain constant over time. This class permits the &lt;tt&gt;null&lt;/tt&gt; * element. * 该类是由 hash table(实际上是 HashMap 实例) 支持的 Set 接口的实现类。它不能保证 set 的迭代顺序；特别是，它不保证 set 内元素的顺序随着时间的变化不会改变。该类允许(添加) null 元素。 * &lt;p&gt;This class offers constant time performance for the basic operations * (&lt;tt&gt;add&lt;/tt&gt;, &lt;tt&gt;remove&lt;/tt&gt;, &lt;tt&gt;contains&lt;/tt&gt; and &lt;tt&gt;size&lt;/tt&gt;), * assuming the hash function disperses the elements properly among the * buckets. Iterating over this set requires time proportional to the sum of * the &lt;tt&gt;HashSet&lt;/tt&gt; instance's size (the number of elements) plus the * "capacity" of the backing &lt;tt&gt;HashMap&lt;/tt&gt; instance (the number of * buckets). Thus, it's very important not to set the initial capacity too * high (or the load factor too low) if iteration performance is important. * 该类的基本操作(add，remove，contains 和 size)提供O(1)的级别的性能表现，假设 hash 方法将元素均匀的分布在桶中。遍历整个 set 所需的时间与 HashSet 实例的 size(元素数量) * (底层 HashMap 实例的 capacity(桶的数量)) 成正比。 * &lt;p&gt;&lt;strong&gt;Note that this implementation is not synchronized.&lt;/strong&gt; * If multiple threads access a hash set concurrently, and at least one of * the threads modifies the set, it &lt;i&gt;must&lt;/i&gt; be synchronized externally. * This is typically accomplished by synchronizing on some object that * naturally encapsulates the set. * 参见 HashMap * If no such object exists, the set should be "wrapped" using the * &#123;@link Collections#synchronizedSet Collections.synchronizedSet&#125; * method. This is best done at creation time, to prevent accidental * unsynchronized access to the set:&lt;pre&gt; * Set s = Collections.synchronizedSet(new HashSet(...));&lt;/pre&gt; * 参见 HashMap * &lt;p&gt;The iterators returned by this class's &lt;tt&gt;iterator&lt;/tt&gt; method are * &lt;i&gt;fail-fast&lt;/i&gt;: if the set is modified at any time after the iterator is * created, in any way except through the iterator's own &lt;tt&gt;remove&lt;/tt&gt; * method, the Iterator throws a &#123;@link ConcurrentModificationException&#125;. * Thus, in the face of concurrent modification, the iterator fails quickly * and cleanly, rather than risking arbitrary, non-deterministic behavior at * an undetermined time in the future. * 参见 HashMap * &lt;p&gt;Note that the fail-fast behavior of an iterator cannot be guaranteed * as it is, generally speaking, impossible to make any hard guarantees in the * presence of unsynchronized concurrent modification. Fail-fast iterators * throw &lt;tt&gt;ConcurrentModificationException&lt;/tt&gt; on a best-effort basis. * Therefore, it would be wrong to write a program that depended on this * exception for its correctness: &lt;i&gt;the fail-fast behavior of iterators * should be used only to detect bugs.&lt;/i&gt; * 参见 HashMap * &lt;p&gt;This class is a member of the * &lt;a href="&#123;@docRoot&#125;/../technotes/guides/collections/index.html"&gt; * Java Collections Framework&lt;/a&gt;. * * @param &lt;E&gt; the type of elements maintained by this set * * @author Josh Bloch * @author Neal Gafter * @see Collection * @see Set * @see TreeSet * @see HashMap * @since 1.2 */public class HashSet&lt;E&gt; extends AbstractSet&lt;E&gt; implements Set&lt;E&gt;, Cloneable, java.io.Serializable HashSet 的类属性、构造方法及 add() 方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110private transient HashMap&lt;E,Object&gt; map;// Dummy value to associate with an Object in the backing Map// 由 Map 接口支持的虚拟对象private static final Object PRESENT = new Object();/** * Constructs a new, empty set; the backing &lt;tt&gt;HashMap&lt;/tt&gt; instance has * default initial capacity (16) and load factor (0.75). * 构造一个新的空的 set；提供底层支持的 HashMap 实例的 默认初始 capacity 为 16，负载因子为 0.75。 */public HashSet() &#123; map = new HashMap&lt;&gt;();&#125;/** * Constructs a new set containing the elements in the specified * collection. The &lt;tt&gt;HashMap&lt;/tt&gt; is created with default load factor * (0.75) and an initial capacity sufficient to contain the elements in * the specified collection. * 构造一个包含指定 collection 中的元素的新 set 实例。 * @param c the collection whose elements are to be placed into this set * @throws NullPointerException if the specified collection is null */public HashSet(Collection&lt;? extends E&gt; c) &#123; map = new HashMap&lt;&gt;(Math.max((int) (c.size()/.75f) + 1, 16)); addAll(c);&#125;/** * &#123;@inheritDoc&#125; * 该方法继承自 AbstractCollection(即，HashSet 没有重写 addAll()，直接指向的是 AbstractCollection.addAll()方法) * &lt;p&gt;This implementation iterates over the specified collection, and adds * each object returned by the iterator to this collection, in turn. * 该方法实现遍历整个指定的 collection，并且将 collection 的 iterator 返回的每个 对象按顺序添加到 set 中。 * &lt;p&gt;Note that this implementation will throw an * &lt;tt&gt;UnsupportedOperationException&lt;/tt&gt; unless &lt;tt&gt;add&lt;/tt&gt; is * overridden (assuming the specified collection is non-empty). * 需要注意的是，这个方法实现会抛出一个 UnsupportedOperationException 异常，除非 add() 被重写(假设指定的 collection 是非空的)。 * @throws UnsupportedOperationException &#123;@inheritDoc&#125; * @throws ClassCastException &#123;@inheritDoc&#125; * @throws NullPointerException &#123;@inheritDoc&#125; * @throws IllegalArgumentException &#123;@inheritDoc&#125; * @throws IllegalStateException &#123;@inheritDoc&#125; * * @see #add(Object) */public boolean addAll(Collection&lt;? extends E&gt; c) &#123; boolean modified = false; for (E e : c) if (add(e)) modified = true; return modified;&#125;/** * Adds the specified element to this set if it is not already present. * More formally, adds the specified element &lt;tt&gt;e&lt;/tt&gt; to this set if * this set contains no element &lt;tt&gt;e2&lt;/tt&gt; such that * &lt;tt&gt;(e==null&amp;nbsp;?&amp;nbsp;e2==null&amp;nbsp;:&amp;nbsp;e.equals(e2))&lt;/tt&gt;. * If this set already contains the element, the call leaves the set * unchanged and returns &lt;tt&gt;false&lt;/tt&gt;. * 添加指定元素到 set 中，如果 set 中还没有该元素。严谨来说，添加一个元素 e 到该 set 中，如果 set 中不存在一个满足这样条件的 (e2: e==null ? e2==null : e.equals(e2)).如果 set 中已经存在一个这样的元素，当次调用不会改变 set，并且放回 false。 * @param e element to be added to this set * @return &lt;tt&gt;true&lt;/tt&gt; if this set did not already contain the specified * element */public boolean add(E e) &#123; // map.put() 返回 null，说明添加新值成功；否则说明添加的元素发生哈希碰撞，或者是重复添加相同元素。 // 另外，需要注意到的是 PRESENT，即影子对象，没有实际意义，纯粹为了填充 value。 return map.put(e, PRESENT)==null;&#125; /** * Constructs a new, empty set; the backing &lt;tt&gt;HashMap&lt;/tt&gt; instance has * the specified initial capacity and the specified load factor. * 构建一个新的空的 set；指定构建由底层提供支持的 HashMap 实例时的初始容量，和负载因子。 * @param initialCapacity the initial capacity of the hash map * @param loadFactor the load factor of the hash map * @throws IllegalArgumentException if the initial capacity is less * than zero, or if the load factor is nonpositive */public HashSet(int initialCapacity, float loadFactor) &#123; map = new HashMap&lt;&gt;(initialCapacity, loadFactor);&#125;/** * Constructs a new, empty set; the backing &lt;tt&gt;HashMap&lt;/tt&gt; instance has * the specified initial capacity and default load factor (0.75). * 构建一个新的空 set；指定构建由底层提供支持的 HashMap 实例时的初始容量，负载因子默认为 0.75. * @param initialCapacity the initial capacity of the hash table * @throws IllegalArgumentException if the initial capacity is less * than zero */public HashSet(int initialCapacity) &#123; map = new HashMap&lt;&gt;(initialCapacity);&#125;/** * Constructs a new, empty linked hash set. (This package private * constructor is only used by LinkedHashSet.) The backing * HashMap instance is a LinkedHashMap with the specified initial * capacity and the specified load factor. * 构建一个新的空 Linked Hash set。(这个包级作用域私有的构造器只能被 LinkedHashSet 使用)。底层提供支持的 HashMap 实例是一个 由指定初始容量和指定负载因子的 LinkedHashMap。 * @param initialCapacity the initial capacity of the hash map * @param loadFactor the load factor of the hash map * @param dummy ignored (distinguishes this * constructor from other int, float constructor.) * @throws IllegalArgumentException if the initial capacity is less * than zero, or if the load factor is nonpositive */HashSet(int initialCapacity, float loadFactor, boolean dummy) &#123; map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor);&#125; remove()12345678910111213141516/** * Removes the specified element from this set if it is present. * More formally, removes an element &lt;tt&gt;e&lt;/tt&gt; such that * &lt;tt&gt;(o==null&amp;nbsp;?&amp;nbsp;e==null&amp;nbsp;:&amp;nbsp;o.equals(e))&lt;/tt&gt;, * if this set contains such an element. Returns &lt;tt&gt;true&lt;/tt&gt; if * this set contained the element (or equivalently, if this set * changed as a result of the call). (This set will not contain the * element once the call returns.) * * @param o object to be removed from this set, if present * @return &lt;tt&gt;true&lt;/tt&gt; if the set contained the specified element */public boolean remove(Object o) &#123; // 见 HashMap.remove() return map.remove(o)==PRESENT;&#125; iterator()123456789101112131415161718192021222324252627282930313233/** * Returns an iterator over the elements in this set. The elements * are returned in no particular order. * 返回 set 中元素的 iterator。(迭代器)返回的元素是无序的。 * @return an Iterator over the elements in this set * @see ConcurrentModificationException */public Iterator&lt;E&gt; iterator() &#123; return map.keySet().iterator();&#125;// 最终指向 HashMap 中的 KeyIteratorprivate final class KeyIterator extends HashIterator&lt;K&gt; &#123; public K next() &#123; return nextEntry().getKey(); &#125;&#125;// nextEntry 位于 HashIterator；// getKey() 是 Entry&lt;K,V&gt; 类中 key getter 方法。final Entry&lt;K,V&gt; nextEntry() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); Entry&lt;K,V&gt; e = next; if (e == null) throw new NoSuchElementException(); if ((next = e.next) == null) &#123; Entry[] t = table; while (index &lt; t.length &amp;&amp; (next = t[index++]) == null) ; &#125; current = e; return e;&#125; 其他方法12345678910111213141516171819202122232425262728293031323334// 以下方法都是对 HashMap 的方法的封装/** * Returns the number of elements in this set (its cardinality). * 返回 set 中元素的个数(它的基数???)。 * @return the number of elements in this set (its cardinality) */public int size() &#123; // map.size 为 map 中键值对的数量 return map.size();&#125;/** * Returns &lt;tt&gt;true&lt;/tt&gt; if this set contains no elements. * * @return &lt;tt&gt;true&lt;/tt&gt; if this set contains no elements */public boolean isEmpty() &#123; // return map.size==0 return map.isEmpty();&#125;/** * Returns &lt;tt&gt;true&lt;/tt&gt; if this set contains the specified element. * More formally, returns &lt;tt&gt;true&lt;/tt&gt; if and only if this set * contains an element &lt;tt&gt;e&lt;/tt&gt; such that * &lt;tt&gt;(o==null&amp;nbsp;?&amp;nbsp;e==null&amp;nbsp;:&amp;nbsp;o.equals(e))&lt;/tt&gt;. * 如果 set 中包含指定元素，则返回 true。严谨来说：当且仅当 (o==null ? e==null : o.equals(e))时，返回 true. * @param o element whose presence in this set is to be tested * @return &lt;tt&gt;true&lt;/tt&gt; if this set contains the specified element */public boolean contains(Object o) &#123; // return map.getEntry(key) != null; return map.containsKey(o);&#125;]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>源码</tag>
        <tag>HashSet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于 ArrayList]]></title>
    <url>%2F2019%2F04%2F03%2Fabout_ArrayList%2F</url>
    <content type="text"><![CDATA[包括之前的 HashMap 和 LinkedList, 都是基于 JDK 7的(应该全面拥抱JDK 8了)。 ArrayList 的 DOC 注释12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576/** * Resizable-array implementation of the &lt;tt&gt;List&lt;/tt&gt; interface. Implements * all optional list operations, and permits all elements, including * &lt;tt&gt;null&lt;/tt&gt;. In addition to implementing the &lt;tt&gt;List&lt;/tt&gt; interface, * this class provides methods to manipulate the size of the array that is * used internally to store the list. (This class is roughly equivalent to * &lt;tt&gt;Vector&lt;/tt&gt;, except that it is unsynchronized.) * (ArrayList) 通过 List 接口实现的容量可变数组。实现了 list 的所有可选操作(方法)，并且允许添加所有元素，包括 null。除了实现了 List 的接口，ArrayList 还提供了修改用来容纳 list 的数组的 size 的方法(ArrayList 是非线程安全的，除此以外大致上与 Vector 相同)。 * &lt;p&gt;The &lt;tt&gt;size&lt;/tt&gt;, &lt;tt&gt;isEmpty&lt;/tt&gt;, &lt;tt&gt;get&lt;/tt&gt;, &lt;tt&gt;set&lt;/tt&gt;, * &lt;tt&gt;iterator&lt;/tt&gt;, and &lt;tt&gt;listIterator&lt;/tt&gt; operations run in constant * time. The &lt;tt&gt;add&lt;/tt&gt; operation runs in &lt;i&gt;amortized constant time&lt;/i&gt;, * that is, adding n elements requires O(n) time. All of the other operations * run in linear time (roughly speaking). The constant factor is low compared * to that for the &lt;tt&gt;LinkedList&lt;/tt&gt; implementation. * size，isEmpty，get，set，iterator 方法和 listIterator 操作的时间复杂度是O(1)的(常数级)。add() 方法的时间复杂度是O(1)+的(amortized constant time)(因为涉及到list 扩容，扩容也需要时间，需要把这部分时间平均分摊到每次 add 操作中。)，也就是说，添加元素的时间复杂度为O(n)。其他操作的时间复杂度大致为O(n)，常量值 n 通常要比 LinkedList 的时间复杂度中常量值要小(即，其他操作要比 LinkedList 的其他操作要快一点)。 * &lt;p&gt;Each &lt;tt&gt;ArrayList&lt;/tt&gt; instance has a &lt;i&gt;capacity&lt;/i&gt;. The capacity is * the size of the array used to store the elements in the list. It is always * at least as large as the list size. As elements are added to an ArrayList, * its capacity grows automatically. The details of the growth policy are not * specified beyond the fact that adding an element has constant amortized * time cost. * 每一个 ArrayList 实例都有一个 capacity(容量)属性，该属性不小于 list 的 size。当向 ArrayList 中添加元素时，它的 capacity 会自动增长。除了添加一个元素具有固定的摊余时间成本之外，增长规则的细节没有被指定。 * &lt;p&gt;An application can increase the capacity of an &lt;tt&gt;ArrayList&lt;/tt&gt; instance * before adding a large number of elements using the &lt;tt&gt;ensureCapacity&lt;/tt&gt; * operation. This may reduce the amount of incremental reallocation. * 在程序中添加大量元素之前，可以调用 ensureCapacity() 方法来对 ArrayList 进行扩容。这样可以减少多次扩容所花费的时间(可以减少扩容的次数) * &lt;p&gt;&lt;strong&gt;Note that this implementation is not synchronized.&lt;/strong&gt; * If multiple threads access an &lt;tt&gt;ArrayList&lt;/tt&gt; instance concurrently, * and at least one of the threads modifies the list structurally, it * &lt;i&gt;must&lt;/i&gt; be synchronized externally. (A structural modification is * any operation that adds or deletes one or more elements, or explicitly * resizes the backing array; merely setting the value of an element is not * a structural modification.) This is typically accomplished by * synchronizing on some object that naturally encapsulates the list. * 需要注意的是，ArrayList 对 List 的实现是非同步的。如果多线程同时请求对 ArrayList 的访问，并且至少会有一个线程对 ArrayList 进行结构性修改(结构性修改是指添加或删除一个以上的元素，或者显式的修改了其数组的大小。仅仅修改元素值并非结构性修改)，那么务必在 ArrayList 外部进行 synchronized 修饰。这通常是通过 synchronized 修饰 封装了 list 的某个对象来实现的。 * If no such object exists, the list should be "wrapped" using the * &#123;@link Collections#synchronizedList Collections.synchronizedList&#125; * method. This is best done at creation time, to prevent accidental * unsynchronized access to the list:&lt;pre&gt; * List list = Collections.synchronizedList(new ArrayList(...));&lt;/pre&gt; * 如果(手头儿)没有这样的对象，那么应该用 Collections.synchronizedList 包裹 list。该操作最好在创建 list 时进行，以防意外的非同步访问 list。 * &lt;p&gt;&lt;a name="fail-fast"/&gt; * The iterators returned by this class's &#123;@link #iterator() iterator&#125; and * &#123;@link #listIterator(int) listIterator&#125; methods are &lt;em&gt;fail-fast&lt;/em&gt;: * if the list is structurally modified at any time after the iterator is * created, in any way except through the iterator's own * &#123;@link ListIterator#remove() remove&#125; or * &#123;@link ListIterator#add(Object) add&#125; methods, the iterator will throw a * &#123;@link ConcurrentModificationException&#125;. Thus, in the face of * concurrent modification, the iterator fails quickly and cleanly, rather * than risking arbitrary, non-deterministic behavior at an undetermined * time in the future. * 通过 ArrayList 的 iterator() 方法，或者 listIterator(int) 方法返回的 iterator 都是 fail-fast(快速失效)的：如果在创建 iterator 之后，任何对 list 的结构性修改，都会抛出 ConcurrentModificationException，除了 iterator 本身的 remove() 和 add() 方法。因此，在面临并发对 list 的修改时，iterator 会快速而干净的失效，而不是在未来不确定的时间冒着任意的、不确定的风险。 * &lt;p&gt;Note that the fail-fast behavior of an iterator cannot be guaranteed * as it is, generally speaking, impossible to make any hard guarantees in the * presence of unsynchronized concurrent modification. Fail-fast iterators * throw &#123;@code ConcurrentModificationException&#125; on a best-effort basis. * Therefore, it would be wrong to write a program that depended on this * exception for its correctness: &lt;i&gt;the fail-fast behavior of iterators * should be used only to detect bugs.&lt;/i&gt; * 另外，需要注意的是，，iterator 的 fail-fast 行为是不能被保证的，，通常来说，在并发非同步对 list 的修改时，任何硬性的保证都是不可能的。fail-fast 会让 iterator 尽可能抛出 ConcurrentModificationException。因此，在程序中通过依赖抛出 ConcurrentModificationException 异常来保证自身的正常运行是错误的：fail-fast 行为只应该用来 debug。 * &lt;p&gt;This class is a member of the * &lt;a href="&#123;@docRoot&#125;/../technotes/guides/collections/index.html"&gt; * Java Collections Framework&lt;/a&gt;. * * @author Josh Bloch * @author Neal Gafter * @see Collection * @see List * @see LinkedList * @see Vector * @since 1.2 */public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable ArrayList 的类属性及构造方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283/** * Default initial capacity. * 默认初始 capacity, 10 */private static final int DEFAULT_CAPACITY = 10;/** * Shared empty array instance used for empty instances. * 对所有由无参构造函数创建的空实例共享的空数组对象 */private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;/** * The array buffer into which the elements of the ArrayList are stored. * The capacity of the ArrayList is the length of this array buffer. Any * empty ArrayList with elementData == EMPTY_ELEMENTDATA will be expanded to * DEFAULT_CAPACITY when the first element is added. * 临时用来存储 ArrayList 中元素的数组。 ArrayList 对象的长度就是这个缓存数组的长度。任何空 ArrayList ，且 elementData == EMPTY_ELEMENTDATA，在添加第一个元素时，数组将被扩展到默认大小(DEFAULT_CAPACITY, 10)。 * (因为是临时的，所以用 transient 修饰，不会被序列化) */private transient Object[] elementData;/** * The size of the ArrayList (the number of elements it contains). * ArrayList 的 size(包含的元素的数量)。 * @serial */private int size;/** * The maximum size of array to allocate. * Some VMs reserve some header words in an array. * Attempts to allocate larger arrays may result in * OutOfMemoryError: Requested array size exceeds VM limit * 允许分配给数组的最大的容量。 * 一些虚拟机实现会在数组预留一些 header words。 * 视图分配更大的数组可能会造成 OOM：所需数组大小超出虚拟机限制。 */private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;/** * Constructs an empty list with the specified initial capacity. * 通过指定初始 capacity 大小来构造一个空 list * @param initialCapacity the initial capacity of the list * @throws IllegalArgumentException if the specified initial capacity * is negative */public ArrayList(int initialCapacity) &#123; super(); // 初始容量小于零时，会抛出 IllegalArgumentException if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); // 初始化指定大小的临时对象数组 this.elementData = new Object[initialCapacity];&#125;/** * Constructs an empty list with an initial capacity of ten. * 构造一个空 list，当向该 list 添加元素时，需先扩展数组到默认初始容量大小，即 10. */public ArrayList() &#123; super(); this.elementData = EMPTY_ELEMENTDATA;&#125;/** * Constructs a list containing the elements of the specified * collection, in the order they are returned by the collection's * iterator. * 按照 collection 迭代器返回元素的顺序构造包含指定 collection 的元素的 list。 * @param c the collection whose elements are to be placed into this list * @throws NullPointerException if the specified collection is null */public ArrayList(Collection&lt;? extends E&gt; c) &#123; // 如果 c 为 null，此处会抛 NPE elementData = c.toArray(); size = elementData.length; // c.toArray might (incorrectly) not return Object[] (see 6260652) // 如果 elementData 不是对象数组，还需要将其复制到新的对象数组中。 if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class);&#125; add()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899/** * Appends the specified element to the end of this list. * 添加指定元素到 list 末尾元素后边。 * @param e element to be appended to this list * @return &lt;tt&gt;true&lt;/tt&gt; (as specified by &#123;@link Collection#add&#125;) */public boolean add(E e) &#123; // 确保内部数组容量足够大，初始状态下 size 为 0。 ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125;private void ensureCapacityInternal(int minCapacity) &#123; // 如果 ArrayList 由无参构造方法构造，则 minCapacity 为 1。 if (elementData == EMPTY_ELEMENTDATA) &#123; minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; // 确保扩容到指定大小的容量 ensureExplicitCapacity(minCapacity);&#125;private void ensureExplicitCapacity(int minCapacity) &#123; // 结构修改次数 +1 modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;/** * Increases the capacity to ensure that it can hold at least the * number of elements specified by the minimum capacity argument. * 扩容，以容纳指定长度的最小数量的元素 * @param minCapacity the desired minimum capacity */private void grow(int minCapacity) &#123; // overflow-conscious code // 原容量 int oldCapacity = elementData.length; // 新容量 = oldCapacity * 1.5 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 如果新容量小于指定的最小容量，则新容量为指定的大小 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; // 如果新容量大于允许的最大容量值 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: // 通常 minCapacity = size + 1，所以大部分情况都是执行到这里 elementData = Arrays.copyOf(elementData, newCapacity);&#125;private static int hugeCapacity(int minCapacity) &#123; // 带符号二进制溢出，符号位为 1，小于零，，即 OOM。 if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125;/** * Inserts the specified element at the specified position in this * list. Shifts the element currently at that position (if any) and * any subsequent elements to the right (adds one to their indices). * 添加指定元素到指定位置。将当前索引位置的元素(如果有的话)及其后边的元素统一右移。 * @param index index at which the specified element is to be inserted * @param element element to be inserted * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public void add(int index, E element) &#123; // 检查 index 是否不小于零，且小于 size rangeCheckForAdd(index); // list 扩容 ensureCapacityInternal(size + 1); // Increments modCount!! // 调用 native 方法复制 插入索引位置之后部分的数组 到原数组中 System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++;&#125;/** * A version of rangeCheck used by add and addAll. * 为 add() 和 addAll() 方法准备的另一个版本的 rangeCheck 方法。 */private void rangeCheckForAdd(int index) &#123; if (index &gt; size || index &lt; 0) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125;/** * @param src the source array. * @param srcPos starting position in the source array. * @param dest the destination array. * @param destPos starting position in the destination data. * @param length the number of array elements to be copied. */public static native void arraycopy(Object src, int srcPos, Object dest, int destPos, int length); get()12345678910111213141516171819202122232425262728293031323334/** * Returns the element at the specified position in this list. * 返回 list 中指定位置的元素 * @param index index of the element to return * @return the element at the specified position in this list * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E get(int index) &#123; rangeCheck(index); // 如果索引合规，则至今返回数组相应索引位置的元素。 return elementData(index);&#125;/** * Checks if the given index is in range. If not, throws an appropriate * runtime exception. This method does *not* check if the index is * negative: It is always used immediately prior to an array access, * which throws an ArrayIndexOutOfBoundsException if index is negative. * 检查指定的索引是否在范围内。如果不在，将抛出合适的运行时异常。该方法不会检查索引是否为负：索引总是在访问数组之前立即使用，，如果在索引为负，会抛出 ArrayIndexOutOfBoundsException 异常。 */private void rangeCheck(int index) &#123; // 如果索引大于数组的实际大小，会抛出数组越界异常。 if (index &gt;= size) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125;/** * Constructs an IndexOutOfBoundsException detail message. * Of the many possible refactorings of the error handling code, * this "outlining" performs best with both server and client VMs. * 构建数组越界异常的详情信息。在很多错误处理代码可能的重构中，这个详情大纲一直在服务器模式和客户端模式中表现的一直很好。 */private String outOfBoundsMsg(int index) &#123; return "Index: "+index+", Size: "+size;&#125; set()12345678910111213141516171819/** * Replaces the element at the specified position in this list with * the specified element. * 用指定的元素替换 list 中指定位置的元素 * @param index index of the element to replace * @param element element to be stored at the specified position * @return the element previously at the specified position * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E set(int index, E element) &#123; // 是否大于数组的 size rangeCheck(index); // 记录数组中当前位置的元素 E oldValue = elementData(index); // 替换指定索引位置为新元素 elementData[index] = element; // 返回原索引位置的元素 return oldValue;&#125; remove()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374/** * Removes the element at the specified position in this list. * Shifts any subsequent elements to the left (subtracts one from their * indices). * 移除当前 list 中指定位置上的元素。将该位置后边的元素左移(当前索引减一) * @param index the index of the element to be removed * @return the element that was removed from the list * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E remove(int index) &#123; // 检查索引是否超出数组的 size rangeCheck(index); // list 结构性更改次数 +1 modCount++; // 记录数组当前索引原元素 E oldValue = elementData(index); // 计算要移动的数组的长度。 int numMoved = size - index - 1; // 如果删除的不是 list 的末尾元素，则将要删除的索引位之后的元素向左移动一位。 if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); // 数组长度-1，并将更新后的数组末尾元素置空 // 此处留坑，，在我的印象中，假如数组长度为10，那么即使是只有零索引处有值，其他位置的元素皆为空，其他对象还持有该数组对象的引用，那么GC时也不会将该数组对象回收。 elementData[--size] = null; // clear to let GC do its work // 返回索引位置原元素 return oldValue;&#125;/** * Removes the first occurrence of the specified element from this list, * if it is present. If the list does not contain the element, it is * unchanged. More formally, removes the element with the lowest index * &lt;tt&gt;i&lt;/tt&gt; such that * &lt;tt&gt;(o==null&amp;nbsp;?&amp;nbsp;get(i)==null&amp;nbsp;:&amp;nbsp;o.equals(get(i)))&lt;/tt&gt; * (if such an element exists). Returns &lt;tt&gt;true&lt;/tt&gt; if this list * contained the specified element (or equivalently, if this list * changed as a result of the call). * 从当前 list 中删除指定元素的第一个匹配项，如果 list 中存在指定元素的话。严谨来说是删除索引值最小的匹配项，像是满足这样的条件：(o==null?get(i)==null:o.equals(get(i)))，如果 list 中存在 o 的话。如果 list 中存在 o，则返回 true(或者说，本次调用导致了 list 改变) * @param o element to be removed from this list, if present * @return &lt;tt&gt;true&lt;/tt&gt; if this list contained the specified element */public boolean remove(Object o) &#123; // 遍历删除找到的第一个 o if (o == null) &#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; fastRemove(index); return true; &#125; &#125; else &#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false;&#125;/* * Private remove method that skips bounds checking and does not * return the value removed. * 私有删除方法，该方法跳过了索引是否越界的检查，且不返回删除的元素。精简版的 remove() */private void fastRemove(int index) &#123; // 结构性更改次数 +1 // ... modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work&#125; iterator1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374/** * Returns an iterator over the elements in this list in proper sequence. * 以正确的顺序返回该 list 中元素的迭代器 * &lt;p&gt;The returned iterator is &lt;a href="#fail-fast"&gt;&lt;i&gt;fail-fast&lt;/i&gt;&lt;/a&gt;. * 返回的 iterator 是 fail-fast 的 * @return an iterator over the elements in this list in proper sequence */public Iterator&lt;E&gt; iterator() &#123; return new Itr();&#125;/** * An optimized version of AbstractList.Itr * AbstractList.Itr 的优化版本 */private class Itr implements Iterator&lt;E&gt; &#123; // index of next element to return 要返回的下一个元素的索引 int cursor; // index of last element returned; -1 if no such 上一个返回元素的索引，如果该元素不复存在(调用iterator.remove()删除当前元素)，则赋值为 -1 int lastRet = -1; // 记录当前 list 结构性修改次数 int expectedModCount = modCount; // 是否还有未迭代过的元素 public boolean hasNext() &#123; // 如果下一个要返回的元素的索引值不等于(即，小于)数组长度，则说明未迭代完成 return cursor != size; &#125; // 返回下一个要迭代的元素 @SuppressWarnings("unchecked") public E next() &#123; // 检查记录 list 结构性更改次数后(即，私有内部类 Itr 初始化完成后)，是否有其他操作对 list 进行过结构性修改。如果有，则抛出 ConcurrentModificationException。 checkForComodification(); int i = cursor; // 如果要迭代的下一个元素的索引值不小于数组的长度，则抛出 NoSuchElementException if (i &gt;= size) throw new NoSuchElementException(); // 复制当前 list 的内部实现数组 elementData Object[] elementData = ArrayList.this.elementData; // 如果要迭代的下一个元素的索引不小于 elementData 的长度，则抛出 ConcurrentModificationException。 if (i &gt;= elementData.length) throw new ConcurrentModificationException(); // 将 cursor 指向要迭代的下一个(本次 next 方法调用完成之后)元素的索引 cursor = i + 1; // 更新返回的最后一个元素的索引值，同时返回本次要迭代的元素 return (E) elementData[lastRet = i]; &#125; public void remove() &#123; // 如果当前元素(next 方法中，int i = cursor；lastRet = i;)索引小于零，抛出 IllegalStateException，此时 list 处于非法状态。 if (lastRet &lt; 0) throw new IllegalStateException(); // 检查 iterator 初始化之后，是否有其他线程对 list 进行了结构性修改。 checkForComodification(); try &#123; // 调用 ArrayList 的 remove() 移除迭代器当前指向的元素 ArrayList.this.remove(lastRet); // 进行 remove 操作后，目标索引后边的元素左移，即目标索引指向新的(尚未迭代过)元素。将迭代器下次要返回的元素指向目标索引的元素 cursor = lastRet; // 本次迭代的元素已被删除，所以为 lastRet 赋值 -1 lastRet = -1; // 更新 list 结构性更改次数 expectedModCount = modCount; &#125; catch (IndexOutOfBoundsException ex) &#123; throw new ConcurrentModificationException(); &#125; &#125; final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125;&#125; 总结 ArrayList 是容量可以改变的非线程安全集合。内部实现使用数组进行存储，集合扩容时会创建更大的数组空间，把原有数据复制到新数组中。ArrayList 支持对元素的快速随机访问，但是插入与删除时速度通常很慢，因为这个过程很有可能需要移动其他元素。 – 码出高效 Java 开发手册 P155]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>源码</tag>
        <tag>ArrayList</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于 HashMap]]></title>
    <url>%2F2019%2F03%2F23%2Fabout_HashMap%2F</url>
    <content type="text"><![CDATA[Context关于 HashMap, 有一件事儿一直很困惑，，在『Redis 核心历险』中是这样被提到的: Redis 的字典相当于 Java 语言中的 HashMap，它是无序字典，内部存储了很多键值对。实现结构上与 Java 的 HashMap 也是一样的，都是”数组 + 链表”二维结构。第一维的 hash 的数组位置碰撞时，就会将碰撞的元素使用链表串接起来。 嗯，第一句没啥问题，，然而”数组 + 链表”什么鬼？还有 hash 碰撞。。作者并没有详细解释这儿，应该默认是每个 Java 开发者都知道的知识点了。然而我却在这儿卡壳了，心慌慌。。趁着周末赶紧补补课。事实证明，这波补课是很有效果的，在这本书后边的内容中，hash 还将会一直出现。 Hash在 Wiki 中的定义为: 散列函数（英语：Hash function）又称散列算法、哈希函数，是一种从任何一种数据中创建小的数字“指纹”的方法。散列函数把消息或数据压缩成摘要，使得数据量变小，将数据的格式固定下来。该函数将数据打乱混合，重新创建一个叫做散列值（hash values，hash codes，hash sums，或hashes）的指纹。散列值通常用一个短的随机字母和数字组成的字符串来代表。好的散列函数在输入域中很少出现散列冲突。在散列表和数据处理中，不抑制冲突来区别数据，会使得数据库记录更难找到。 用我自己的话来说就是，，为数据创建指纹摘要，通过该摘要就可以找到原始数据。我觉得更多的场景是为相对大的数据创建摘要。假如有个 hash()，可以为任意数据生成一个32位的摘要。那么我们在互联网下载文件的时候，有的网站会在下来链接处给出该文件的 hash 值，等用户下载完成之后，通过 hash() 对该文件提取摘要，将两个 hash 值，进行对比。如果结果一样，说明文件在下载过程中没有被篡改。 那倘若我们对数字 1 进行 hash()，那应该也会得到一个长度为 32 位的摘要，但这时候还能叫『摘要』么？我感觉是不太合适的。 HashMapOK，back to the point..关于 Hash 我们需要知道👇 所有散列函数都有如下一个基本特性：如果两个散列值是不相同的（根据同一函数），那么这两个散列值的原始输入也是不相同的。这个特性是散列函数具有确定性的结果，具有这种性质的散列函数称为单向散列函数。但另一方面，散列函数的输入和输出不是唯一对应关系的，如果两个散列值相同，两个输入值很可能是相同的，但也可能不同，这种情况称为“散列碰撞（collision）”。 按我之前不成熟的想法，，HashMap 中为什么要放链表？直接放数据对象不就够了么。。原因就是当我们通过 get(key) 方法从 HashMap 中获取对象的时候，理论上这个 key 对应的 hash 值和某个 whateverKey 对应的 hash 值是一样的(即，散列碰撞)，，因为『如果两个散列值相同，两个输入值很可能是相同的，但也可能不同(即，key 和 whateverKey)』。此时我们可以通过 key 和 whateverKey 都可以获取到对应的数据对象。如此，为了解决散列碰撞带来的问题，我们需要在 HashMap 中将两个‘key’都指向同一个数据对象，而在 HashMap 中的链表就是用来维护这些‘key’的。下面，我们试着读读 HashMap 源码。 HashMap 的 DOC 注释123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267/** * Hash table based implementation of the &lt;tt&gt;Map&lt;/tt&gt; interface. This * implementation provides all of the optional map operations, and permits * &lt;tt&gt;null&lt;/tt&gt; values and the &lt;tt&gt;null&lt;/tt&gt; key. (The &lt;tt&gt;HashMap&lt;/tt&gt; * class is roughly equivalent to &lt;tt&gt;Hashtable&lt;/tt&gt;, except that it is * unsynchronized and permits nulls.) This class makes no guarantees as to * the order of the map; in particular, it does not guarantee that the order * will remain constant over time. * 👆散列表也基于对 Map 接口的实现。HashMap 也是对是 Map 接口的实现，提供了所有对 Map 的可选操作(的方法)，并且允许 null 值和 null 键。HashMap 大致相当与 HashTable 相同，除了 HashMap 是非同步的，且接受 null。该类不保证数据对象在内部的顺序，同时也不保证内部的顺序是一成不变的。 * * &lt;p&gt;This implementation provides constant-time performance for the basic * operations (&lt;tt&gt;get&lt;/tt&gt; and &lt;tt&gt;put&lt;/tt&gt;), assuming the hash function * disperses the elements properly among the buckets. Iteration over * collection views requires time proportional to the "capacity" of the * &lt;tt&gt;HashMap&lt;/tt&gt; instance (the number of buckets) plus its size (the number * of key-value mappings). Thus, it's very important not to set the initial * capacity too high (or the load factor too low) if iteration performance * is important. * 👆HashMap 中 get 和 put 这两项基本操作提供复杂度为常数级别的性能表现，假定 hash 方法把元素均匀的分配到桶中。对整个集合视图进行迭代所需的时间与 HashMap 实例(桶的数量)乘以它的容量(键值对的数量)之积。所以，如果迭代性能很重要的话，不要在初始化 HashMap 的时候设置过高的容量，及太小的负载系数(负载因子) * * &lt;p&gt;As a general rule, the default load factor (.75) offers a good tradeoff * between time and space costs. Higher values decrease the space overhead * but increase the lookup cost (reflected in most of the operations of the * &lt;tt&gt;HashMap&lt;/tt&gt; class, including &lt;tt&gt;get&lt;/tt&gt; and &lt;tt&gt;put&lt;/tt&gt;). The * expected number of entries in the map and its load factor should be taken * into account when setting its initial capacity, so as to minimize the * number of rehash operations. If the initial capacity is greater * than the maximum number of entries divided by the load factor, no * rehash operations will ever occur. * 👆一般，默认的负载系数（0.75）在时间和空间成本之间提供了很好的平衡。更高的值会减少了空间开销，但同时会增加查找成本（反映在 Hashmap 的大多数操作中，包括 get 和 put）。在设置初始容量时，应考虑到 Map 中预期的条目数量及其负载系数，以尽量减少 rehash 的次数。如果初始容量大于最大条目数除以负载系数的值，则不会发生 rehash 操作。 * &lt;p&gt;If many mappings are to be stored in a &lt;tt&gt;HashMap&lt;/tt&gt; instance, * creating it with a sufficiently large capacity will allow the mappings to * be stored more efficiently than letting it perform automatic rehashing as * needed to grow the table. * 👆如果要在一个 HashMap 实例中存储多个键值对，那么创建实例时指定足够大的容量将比让它根据需要 rehash 以扩充容量的效率更高。 * &lt;strong&gt;Note that this implementation is not synchronized.&lt;/strong&gt; * If multiple threads access a hash map concurrently, and at least one of * the threads modifies the map structurally, it &lt;i&gt;must&lt;/i&gt; be * synchronized externally. (A structural modification is any operation * that adds or deletes one or more mappings; merely changing the value * associated with a key that an instance already contains is not a * structural modification.) This is typically accomplished by * synchronizing on some object that naturally encapsulates the map. * 👆需要注意的是，HashMap 是非线程安全的。如果多线程同时请求访问 HashMap，并且有至少一条线程改变了 HashMap 实例的结构，那么必须在 HashMap 外层对它添加 synchronized 修饰。（结构修改是指任何添加或删除一个或多个键值对的操作；仅更改实例已包含的键关联的值不是结构修改。）（这一句不太懂诶。。。） * If no such object exists, the map should be "wrapped" using the * &#123;@link Collections#synchronizedMap Collections.synchronizedMap&#125; * method. This is best done at creation time, to prevent accidental * unsynchronized access to the map:&lt;pre&gt; * Map m = Collections.synchronizedMap(new HashMap(...));&lt;/pre&gt; * 👆如果这样的对象不存在，则该 HashMap 应该被Collections.synchronizedMap()方法包裹起来。最好在对象初创建的时候就这样做，以免发生不可预知的对 HashMap 的访问。 * &lt;p&gt;The iterators returned by all of this class's "collection view methods" * are &lt;i&gt;fail-fast&lt;/i&gt;: if the map is structurally modified at any time after * the iterator is created, in any way except through the iterator's own * &lt;tt&gt;remove&lt;/tt&gt; method, the iterator will throw a * &#123;@link ConcurrentModificationException&#125;. Thus, in the face of concurrent * modification, the iterator fails quickly and cleanly, rather than risking * arbitrary, non-deterministic behavior at an undetermined time in the * future. * 👆HashMap 的迭代器返回的这个类的所有集合视图方法都是‘快速失效’的: 所有在迭代器创建之后对 HashMap 进行结构性修改，除了迭代器自己的 remove()方法外，会抛出 ConcurrentModificationException。在面对并发对 HashMap 的修改时，迭代器会快速彻底的失效，而不会选择在之后冒不确定的、未知的风险。 * &lt;p&gt;Note that the fail-fast behavior of an iterator cannot be guaranteed * as it is, generally speaking, impossible to make any hard guarantees in the * presence of unsynchronized concurrent modification. Fail-fast iterators * throw &lt;tt&gt;ConcurrentModificationException&lt;/tt&gt; on a best-effort basis. * Therefore, it would be wrong to write a program that depended on this * exception for its correctness: &lt;i&gt;the fail-fast behavior of iterators * should be used only to detect bugs.&lt;/i&gt; * 👆需要注意的是，迭代器的快速失效并不能被保证(一定发生)，，通常来讲，在非同步并发修改 HashMap 的情况下，无法(对快速失效)做出硬性保证。迭代器快速失效后会尽最大努力抛出 ConcurrentModificationException 异常。因此，不能依靠是否抛出该异常来确定写的程序是否是正确的：迭代器的快速失效行为只能被用来查明bug。 */public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable/** * The default initial capacity - MUST be a power of two. * HashMap 的默认初始容量--必须是 2 的 N 次方 */static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 (Also Known As, 即初始值为 16)/** * The maximum capacity, used if a higher value is implicitly specified * by either of the constructors with arguments. * MUST be a power of two &lt;= 1&lt;&lt;30. * 最大容量，在带参构造函数中隐式判断指定的容量是否超出最大容量时使用。 * 必须是 2 的 N 次方，且不大于 2^30 */static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;/** * The load factor used when none specified in constructor. * 构造器未指定负载系数时，使用该默认值 * (当 HashMap 的 size 大于 HashMap 的 capacity * loadFactor 时，HashMap 扩容，即 capacity *= 2，并 rehash()) */static final float DEFAULT_LOAD_FACTOR = 0.75f; /** * An empty table instance to share when the table is not inflated. * 在表还没有扩容之前，共享该空数组实例 */static final Entry&lt;?,?&gt;[] EMPTY_TABLE = &#123;&#125;;/** * The table, resized as necessary. Length MUST Always be a power of two. * 整个表的容量，如果有必要的话(键值对条数/负载系数 &gt;= table.length)会进行扩容。容量大小必须是 2 的幂次方 */transient Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPTY_TABLE;/** * The number of key-value mappings contained in this map. * map 中键值对的条数 */transient int size;/** * The next size value at which to resize (capacity * load factor). * @serial * 下一次扩容后的大小(容量*负载系数) */int threshold;/** * The load factor for the hash table. * table 的负载系数 * @serial */final float loadFactor;/** * 无参构造方法，使用默认初始容量(16)，默认负载系数(.75) */public HashMap() &#123; this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR);&#125;/** * 带参构造方法，指定初始容量为initialCapacity */public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;/** * 带参构造方法，指定初始容量和负载系数 * 最终所有构造函数都指向该构造函数 */public HashMap(int initialCapacity, float loadFactor) &#123; // 如果指定的初始容量 &lt;0，则抛出不合法参数异常 if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); // 如果指定的容量大于最大容量，则使用最大容量为初始容量 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; // 如果指定的负载系数不大于零或不是浮点数，则抛出不合法参数异常 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; threshold = initialCapacity; init();&#125;/** * 组建一个与指定 map 相同的 HashMap，使用默认负载系数，初始容量足以盛下该 Map。 */public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; // 如果初始容量大于允许的最大容量，则使用最大容量；否则初始容量为指定 Map 的大小除以负载系数后加一 this(Math.max((int) (m.size() / DEFAULT_LOAD_FACTOR) + 1, DEFAULT_INITIAL_CAPACITY), DEFAULT_LOAD_FACTOR); // HashMap扩容到指定容量 inflateTable(threshold); putAllForCreate(m);&#125;/** * Inflates the table. * 表扩容 */ private void inflateTable(int toSize) &#123; // Find a power of 2 &gt;= toSize // 找到大于 toSize 的最小的2的幂次方的值(因为容量只能为2的幂次方) int capacity = roundUpToPowerOf2(toSize); // 下次扩容时创建表的初始大小 threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); table = new Entry[capacity]; initHashSeedAsNeeded(capacity);&#125;// 寻找大于某个非负数的的最小的2的幂次方的值(eg. roundUpToPowerOf2(5)=8)private static int roundUpToPowerOf2(int number) &#123; // assert number &gt;= 0 : "number must be non-negative"; // 断言 number 为非负数 return number &gt;= MAXIMUM_CAPACITY ? MAXIMUM_CAPACITY : (number &gt; 1) ? Integer.highestOneBit((number - 1) &lt;&lt; 1) : 1; // 当 number 不小于允许的最大容量时，直接返回最大值； // 当 number = 1 时，直接返回 1。 // 否则返回 Integer.highestOneBit((number - 1) &lt;&lt; 1)： // (number - 1) &lt;&lt; 1) = (number - 1)*2 // Integer.highestOneBit(i): 取 i 这个数的二进制形式最左边的最高一位且高位后面全部补零，最后返回int型的结果。 // 假设 number 值为 5；那么十进制 5 减去 1 之后得 4，4 的二进制带符号左移一位，得十进制 8；8 的二进制为：1000；经过 Integer.highestOneBit 处理后值还是 8。 // 假设 number 值为 6，那么十进制 6 减去 1 之后得 5，5 的二进制带符号左移一位，得十进制 10；10 的二进制为 1010；取最高位 1，其余 3 位补零，得 1000，即十进制 8。&#125;// 再看看 HashMap 的静态内部类 Entry&lt;K,V&gt;static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final K key; V value; // 只有 next，没有 prev，即单向链 Entry&lt;K,V&gt; next; int hash; /** * Creates new entry. */ Entry(int h, K k, V v, Entry&lt;K,V&gt; n) &#123; value = v; next = n; key = k; hash = h; &#125; // key 的 getter 方法..略 // value 的 getter 方法..略 // value 的 setter 方法 public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; // Entry 的 key 和 value 与 o 的 key 和 value 都相等，则return true，否则return false public final boolean equals(Object o) &#123; if (!(o instanceof Map.Entry)) return false; Map.Entry e = (Map.Entry)o; Object k1 = getKey(); Object k2 = e.getKey(); if (k1 == k2 || (k1 != null &amp;&amp; k1.equals(k2))) &#123; Object v1 = getValue(); Object v2 = e.getValue(); if (v1 == v2 || (v1 != null &amp;&amp; v1.equals(v2))) return true; &#125; return false; &#125; public final int hashCode() &#123; return Objects.hashCode(getKey()) ^ Objects.hashCode(getValue()); &#125; public final String toString() &#123; return getKey() + "=" + getValue(); &#125; /** * This method is invoked whenever the value in an entry is * overwritten by an invocation of put(k,v) for a key k that's already * in the HashMap. */ void recordAccess(HashMap&lt;K,V&gt; m) &#123; &#125; /** * This method is invoked whenever the entry is * removed from the table. */ void recordRemoval(HashMap&lt;K,V&gt; m) &#123; &#125;&#125; put() 方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140public V put(K key, V value) &#123; // 如果这是空表，则首先为表进行扩容，threshold 初始值为 DEFAULT_INITIAL_CAPACITY，即 16 if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; // 如果 key 为 null if (key == null) // 该方法进行的操作与下面对非 null key值的操作逻辑基本一致，只不过是在 for 循环中的 判断条件改为了 e.key == null return putForNullKey(value); int hash = hash(key); // 通过 Hash 值找到在数组中的索引值 int i = indexFor(hash, table.length); // 遍历索引指向的单向链表，查看 key 在当前 Map 中是否存在 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; // 如果 当前 Entry 对象 e 的 hash 值与 key 的 hash 值相等，且 e.key 与 key 相等，则覆盖原有 e.value if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; // 如果要插入的 key 在 map 中不存在，， // 结构修改次数 ++ modCount++; // 在 HashMap 的 Entry 数组中添加新的 Entry 对象 addEntry(hash, key, value, i); return null;&#125;/** * Returns index for hash code h. * 找到 hash 值在 table 中的索引值 */static int indexFor(int h, int length) &#123; // assert Integer.bitCount(length) == 1 : "length must be a non-zero power of 2"; //Integer.bitCount(length) 用于计算十进制 length 值的二进制值中 '1' 的个数；Integer.bitCount(length) == 1，即断言 length 值(HashMap 中Entry&lt;?,?&gt;[]的length，即 HashMap capacity)为 2 的幂次方。 // 刚开始是没有看明白这行代码的，求助搜索引擎之后，才有些眉目。 // 首先，这是按位与操作，，因为 length 值为 2 的幂次方，所以 length - 1后，其二进制的值除高位外全为1(eg. 假设length 值为 8(二进制表现为 1000)， 减 1 得 7；7 的二进制为 0111) return h &amp; (length-1);&#125;/** * Adds a new entry with the specified key, value and hash code to * the specified bucket. It is the responsibility of this * method to resize the table if appropriate. * 通过指定的 key、value、hash code 向指定的 bucket 添加一个新的 entry 对象。在适当的时候扩容 table 也是该方法的主要责任。 * Subclass overrides this to alter the behavior of put method. * 子类重写该方法可以修改 put() 方法的行为。 */void addEntry(int hash, K key, V value, int bucketIndex) &#123; // 如果当前 HashMap 的 size 大于等于扩容临界值，且当前 Entry 不为 null 的时候 // 当 table 的 capacity 等于 Integer.MAX_VALUE时，int 类型的 size 最多与 threshold(此时 threshold = Integer.MAX_VALUE)相等，而且 null != table[bucketIndex] 肯定为 true。所以，当 table 达到最大容量后，再调用 put() 会一直覆盖原有的值。 if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; // 2 倍扩容 resize(2 * table.length); // key 为 null，则 hash 值为 0；否则 通过 hash() 方法计算 hash 值 hash = (null != key) ? hash(key) : 0; // 计算扩容之后 entry 将要被放在的 bucket 索引 bucketIndex = indexFor(hash, table.length); &#125; // 实际添加 entry 对象的方法 createEntry(hash, key, value, bucketIndex);&#125;/** * Rehashes the contents of this map into a new array with a * larger capacity. This method is called automatically when the * number of keys in this map reaches its threshold. * Rehash 当前 map 对象到一个新的更大的数组中去；该方法在 map.size() 达到临界值时自动调用 * If current capacity is MAXIMUM_CAPACITY, this method does not * resize the map, but sets threshold to Integer.MAX_VALUE. * This has the effect of preventing future calls. * 如果当前容量达到允许的最大容量时，该方法不会再进行扩容操作，而是直接将临界值设置为 Integer.MAX_VALUE。 * @param newCapacity the new capacity, MUST be a power of two; * must be greater than current capacity unless current * capacity is MAXIMUM_CAPACITY (in which case value * is irrelevant). */void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; // MAXIMUM_CAPACITY = 2^30，即 oldCapacity 最大值为 2^30 if (oldCapacity == MAXIMUM_CAPACITY) &#123; // Integer.MAX_VALUE = 2^31 - 1，之后不可能再进行扩容操作了 threshold = Integer.MAX_VALUE; return; &#125; Entry[] newTable = new Entry[newCapacity]; transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);&#125;/** * Like addEntry except that this version is used when creating entries * as part of Map construction or "pseudo-construction" (cloning, * deserialization). This version needn't worry about resizing the table. * 本方法与 addEntry() 类似，只不过是用于'伪构造方法时'(克隆、反序列化)，而且该方法不用担心扩容的问题~ * Subclass overrides this to alter the behavior of HashMap(Map), * clone, and readObject. */void createEntry(int hash, K key, V value, int bucketIndex) &#123; // 在未发生散列碰撞时，e 为 null；否则 e 为 entry 实例 Entry&lt;K,V&gt; e = table[bucketIndex]; // 构建新的Entry对象，并其属性 next 指向 e，，即在发生散列碰撞的情况下，每次添加 entry 实例时，都是 insert(添加到单向链开始位置)，而非 append。 table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++;&#125;/** * Transfers all entries from current table to newTable. * 将现在的 table 转移到新的 table中 */void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; // 遍历原 Entry 数组中所有对象 for (Entry&lt;K,V&gt; e : table) &#123; // 遍历每个槽位的 entry 单向链 while(null != e) &#123; // ① 👉 记录下 e.next 先 Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; // 计算 e.hash 在新 entry 数组中 bucket 索引 int i = indexFor(e.hash, newCapacity); // ② 👉 将原槽位的 entry 单向链添加到当前 e 的 next 属性中。 e.next = newTable[i]; // ③ 👉 将 新数组的指定索引的值 指向 拼接过的新的 entry 单向链。 newTable[i] = e; // ④ 👉 将之前记录下来的 e.next 值重新赋给 e，开始下一轮循环(类似 for 循环中的 i++)。 e = next; &#125; &#125;&#125;// 👆 transfer() 方法中 将while 循环转成 for 循环，①、④ 处可能会更好理解一点； ②、③ 位置不太好理解，我也是反复咀嚼了好多遍才大概明白一点。// eg. 我们假设在索引为 i 的槽位处有个 entry 对象 e0，它链接的 entry 对象结构大概为：e0 -&gt; e1 -&gt; e2 -&gt; e3；现在有个 entry 对象 e，e 的 hash 值在新数组中计算得到的索引值同样为 i(即，散列碰撞)；此时需将 e 添加到 e0 的单向链中，③、④ 操作执行过后，该槽位的单向链结构变为：e -&gt; e0 -&gt; e1 -&gt; e2 -&gt; e3。 get() 方法👇1234567891011121314151617181920212223242526272829303132333435363738394041424344public V get(Object key) &#123; if (key == null) return getForNullKey(); Entry&lt;K,V&gt; entry = getEntry(key); return null == entry ? null : entry.getValue();&#125;/** * Offloaded version of get() to look up null keys. Null keys map * to index 0. This null case is split out into separate methods * for the sake of performance in the two most commonly used * operations (get and put), but incorporated with conditionals in * others. * key 值为 null 的指向 map 中 Entry 数组 index 为 0 的 entry 对象。为了更高的性能表现，在 get 和 put 请求中，key 为 null 的情况被分支出单独的方法来处理，但在其他方法中并没有这样去做。 */ private V getForNullKey() &#123; if (size == 0) &#123; return null; &#125; for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) &#123; if (e.key == null) return e.value; &#125; return null;&#125;final Entry&lt;K,V&gt; getEntry(Object key) &#123; if (size == 0) &#123; return null; &#125; int hash = (key == null) ? 0 : hash(key); // 遍历指定 index 位置的的单项链 for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; return null;&#125; remove() 方法123456789101112131415161718192021222324252627282930313233343536373839404142public V remove(Object key) &#123; // 直接看关键方法 Entry&lt;K,V&gt; e = removeEntryForKey(key); return (e == null ? null : e.value);&#125;final Entry&lt;K,V&gt; removeEntryForKey(Object key) &#123; if (size == 0) &#123; return null; &#125; int hash = (key == null) ? 0 : hash(key); int i = indexFor(hash, table.length); // ①看到这儿时候我是有些懵哔的.. Entry&lt;K,V&gt; prev = table[i]; Entry&lt;K,V&gt; e = prev; while (e != null) &#123; Entry&lt;K,V&gt; next = e.next; Object k; // ③ 关键在这儿 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; modCount++; size--; // ②直到看到了这儿，我意识到我刚才懵逼早了... // 由 ① 很容易得出结论啊，妥妥相等 if (prev == e) table[i] = next; else prev.next = next; e.recordRemoval(this); return e; &#125; ④ prev = e; e = next; &#125; return e;&#125;// 👆在上面的代码中，如果只看①②，会蒙圈的，，关键在③的分支判断。// 在发生散列碰撞(由不同的 key，生成了相同的 hash 值)情况下，e.hash == hash 是成立的，但 (k = e.key) == key 或 key.equals(k)就不成立了。// eg. 如果要删除的单向链节点在链的开头，则直接走 (prev == e) 分支，将 table[i] 指向 其 next 属性的节点；如果要删除的单向链节点位于第二，则在直接将第一个节点的 next 属性指向第 3 个节点即可。 entrySet() 方法123456789101112131415161718192021222324252627282930313233/** * Returns a &#123;@link Set&#125; view of the mappings contained in this map. * The set is backed by the map, so changes to the map are * reflected in the set, and vice-versa. If the map is modified * while an iteration over the set is in progress (except through * the iterator's own &lt;tt&gt;remove&lt;/tt&gt; operation, or through the * &lt;tt&gt;setValue&lt;/tt&gt; operation on a map entry returned by the * iterator) the results of the iteration are undefined. The set * supports element removal, which removes the corresponding * mapping from the map, via the &lt;tt&gt;Iterator.remove&lt;/tt&gt;, * &lt;tt&gt;Set.remove&lt;/tt&gt;, &lt;tt&gt;removeAll&lt;/tt&gt;, &lt;tt&gt;retainAll&lt;/tt&gt; and * &lt;tt&gt;clear&lt;/tt&gt; operations. It does not support the * &lt;tt&gt;add&lt;/tt&gt; or &lt;tt&gt;addAll&lt;/tt&gt; operations. * 返回当前 map 键值对映射的 set 快照(??)。该集合由 map 支持，所以对 map 的修改会反映到 set中，反之亦然。 * 如果 map 在 set 迭代的过程中被修改(除了迭代器本身的remove()和迭代器返回的 map entry的 setValue()操作)话，其结果是未知(??)的。 * set 支持移除元素， Set.remove(),removeAll(), retainAll() 和 clear() 会直接影响到相关的 map。set 不知道 add()和 addAll() 操作。 * @return a set view of the mappings contained in this map */public Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() &#123; return entrySet0();&#125;(实测，在 for(Map.Entry&lt;String,String&gt; m:map.entrySet()) 循环中，通过 map.put() 方法放入新的值，会抛出 ConcurrentModificationException：👇Exception in thread "main" java.util.ConcurrentModificationException at java.util.HashMap$HashIterator.nextEntry(HashMap.java:922) at java.util.HashMap$EntryIterator.next(HashMap.java:962) at java.util.HashMap$EntryIterator.next(HashMap.java:960) at Test.main(Test.java:12)如果放入 map 中已存在的 key，不会抛出 ConcurrentModificationException。) private Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet0() &#123; Set&lt;Map.Entry&lt;K,V&gt;&gt; es = entrySet; return es != null ? es : (entrySet = new EntrySet());&#125; 到这里之后是有点儿懵的，，因为 entrySet0() 方法中第一行代码，entrySet在 HashMap 中是这样声明的：👇1private transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet = null; 之后在其他地方没有明确对其进行赋值的代码，然鹅我们在 Test 类进行 for(Map.Entry&lt;String,String&gt; m: map.entrySet()) 循环时，entrySet明明是有值的。那么 map.entrySet() 到底是在什么时候进行赋值的呢？！这个问题困扰了我很久，在 HashMap 显式继承的 AbstractMap 类和实现的 Map&lt;K,V&gt; 接口中，也没有找到答案。出门遛了一圈，突然想到了 Test 类被编译之后的 class 文件！！然后用 JD-JUI 反编译之后，终于有些发现了：👇12// class 文件反编译之后的 forEach 循环for (Iterator i$ = map.entrySet().iterator(); i$.hasNext(); localEntry = (Map.Entry)i$.next()) 👆我们可以看到，虽说用的是 forEach 循环，但在编译之后还是通过 Iterator 迭代器进行遍历的。首先初始条件 Iterator i$ = map.entrySet().iterator()，我们可以看到 map.entrySet() 返回的是一个 Set&lt;Map.Entry&lt;K,V&gt;&gt;，所以其 iterator() 是 Set 接口实现类的 iterator() 方法。我们继续看 entrySet0() 方法的第二行代码，在 entrySet 为空的情况下，会初始化一个新的 Set&lt;Map.Entry&lt;K,V&gt;&gt; 对象，即 new EntrySet()，我们看看 EntrySet 类：👇 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778private final class EntrySet extends AbstractSet&lt;Map.Entry&lt;K,V&gt;&gt; &#123; public Iterator&lt;Map.Entry&lt;K,V&gt;&gt; iterator() &#123; return newEntryIterator(); &#125; public boolean contains(Object o) &#123; if (!(o instanceof Map.Entry)) return false; Map.Entry&lt;K,V&gt; e = (Map.Entry&lt;K,V&gt;) o; Entry&lt;K,V&gt; candidate = getEntry(e.getKey()); return candidate != null &amp;&amp; candidate.equals(e); &#125; public boolean remove(Object o) &#123; return removeMapping(o) != null; &#125; public int size() &#123; return size; &#125; public void clear() &#123; HashMap.this.clear(); &#125;&#125;// EntrySet 类集成了 AbstractSet 类，而 AbstractSet 类又实现了 Set&lt;E&gt; 接口，那么 EntrySet 类中的 iterator() 方法就是我们要找的。我们继续顺着往下看 newEntryIterator ：👇Iterator&lt;Map.Entry&lt;K,V&gt;&gt; newEntryIterator() &#123; return new EntryIterator();&#125;private final class EntryIterator extends HashIterator&lt;Map.Entry&lt;K,V&gt;&gt; &#123; public Map.Entry&lt;K,V&gt; next() &#123; return nextEntry(); &#125;&#125;// 形式渐渐明朗，，再看 nextEntry()private abstract class HashIterator&lt;E&gt; implements Iterator&lt;E&gt; &#123; Entry&lt;K,V&gt; next; // next entry to return int expectedModCount; // For fast-fail int index; // current slot Entry&lt;K,V&gt; current; // current entry HashIterator() &#123; expectedModCount = modCount; if (size &gt; 0) &#123; // advance to first entry Entry[] t = table; while (index &lt; t.length &amp;&amp; (next = t[index++]) == null) ; &#125; &#125; public final boolean hasNext() &#123; return next != null; &#125; final Entry&lt;K,V&gt; nextEntry() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); Entry&lt;K,V&gt; e = next; if (e == null) throw new NoSuchElementException(); if ((next = e.next) == null) &#123; Entry[] t = table; while (index &lt; t.length &amp;&amp; (next = t[index++]) == null) ; &#125; current = e; return e; &#125; public void remove() &#123; if (current == null) throw new IllegalStateException(); if (modCount != expectedModCount) throw new ConcurrentModificationException(); Object k = current.key; current = null; HashMap.this.removeEntryForKey(k); expectedModCount = modCount; &#125;&#125;// 至此，所有问题解决~ 在 Iterator i$ = map.entrySet().iterator() 中，i$ 为 HashIterator，i$.hasNext() 调用的是 HashIterator.hasNext()，(Map.Entry)i$.next() 调用的是 EntryIterator.next()，而 EntryIterator.next() 最终还是调用了 HashIterator.nextEntry()。 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 2019-04-02.update 上个月末的时候，花了一个晚上更新了下简历，但并没有到处去投，只是对外可见。陆陆续续开始有公司接触，其中还接到一个电话面试，，是某外包公司的。突如其来的电话面试，有点仓促，但好在前端时间也一直在看书恶补。其中有个很基础的问题，，『简单说下 Java 集合框架各容器类之间的关系』。多亏了学习 『Redis 核心历险』时，对 LinkedList 多看了一眼，也经受住了超越妹妹的考验。当中面试官特地提到 Map 和 Collection 有没有关系? 可以确定是肯定有关系，但有什么关系呢？没有答上来。。那时还没有整理 HashMap 这篇文章，只有 LinkedList。其实在整理这篇文章时也没找到两者之间的关系，因为 interface Map&lt;K,V&gt; 与 interface Collection&lt;E&gt;并没有直接的继承关系。。这时候需要感谢的是『码出高效 Java 开发手册』了，平时把这本书放在了床头，睡前会翻一翻从此再无失眠，并没有从第一张开始读，而是直接挑了最薄弱的数据结构与集合这一章。 OK，下面来说说 Map 和 Collection 的关系！在书中是这样描述的: 👇 在数据元素的存储、查找、修改和遍历中，Java 中的 Map 类集合都与 Collection 类集合存在很大的不同。它是与 Collection 类平级的一个接口，在集合框架图上，它有一条微弱的依赖线月 Collection 类产生联系，那是因为部分方法返回 Collection 视图，比如 values() 方法返回的所有 values 的列表 我们先看 Map 接口的 values() 方法：👇12// Map 接口类Collection&lt;V&gt; values(); 非常明显，，说到values()方法，肯定会想到 keySet() 和 entrySet() ，毕竟这三个方法在 HashMap 迭代的时候可是肩并肩的~👇123// Map 接口类Set&lt;K&gt; keySet();Set&lt;Map.Entry&lt;K, V&gt;&gt; entrySet(); 我们再看看，这三个方法在 HashMap 中的实现~ 👇1234567891011121314151617181920212223242526272829303132333435363738394041424344// values 方法public Collection&lt;V&gt; values() &#123; Collection&lt;V&gt; vs = values; return (vs != null ? vs : (values = new Values()));&#125;// Values 类，AbstractCollection 类实现类了 Collection 接口private final class Values extends AbstractCollection&lt;V&gt; &#123; public Iterator&lt;V&gt; iterator() &#123; return newValueIterator(); &#125; public int size() &#123; return size; &#125; public boolean contains(Object o) &#123; return containsValue(o); &#125; public void clear() &#123; HashMap.this.clear(); &#125;&#125;// keySet 方法public Set&lt;K&gt; keySet() &#123; Set&lt;K&gt; ks = keySet; return (ks != null ? ks : (keySet = new KeySet()));&#125;// KeySet 类，abstract class AbstractSet&lt;E&gt; 继承了 AbstractCollection&lt;E&gt; 实现了 Set&lt;E&gt;，而抽象类 AbstractCollection 和 Set 接口 都继承了 Collection 接口。private final class KeySet extends AbstractSet&lt;K&gt; &#123; public Iterator&lt;K&gt; iterator() &#123; return newKeyIterator(); &#125; public int size() &#123; return size; &#125; public boolean contains(Object o) &#123; return containsKey(o); &#125; public boolean remove(Object o) &#123; return HashMap.this.removeEntryForKey(o) != null; &#125; public void clear() &#123; HashMap.this.clear(); &#125;&#125;// 至于 entrySet() 方法，我们在分析 HashMap 的 forEach 循环时已经挖过源码了。EntrySet 类与 KeySet 类一样，都继承了 AbstractSet 抽象类。 米一–Hash表的前世今生 追逐盛夏流年–HashMap中的indexFor方法分析 March@dhyin.top–hashmap的实现原理 数组 entry 哈希拉链法 贝壳风铃–Java遍历HashMap并修改(remove)]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>源码</tag>
        <tag>HashMap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018_12_week_1st]]></title>
    <url>%2F2019%2F03%2F17%2F2018_12_week_1st%2F</url>
    <content type="text"><![CDATA[好久好久之前的零碎知识点了… 关于Linux中的管道12// 列出当前目录下后缀为 conf 的文件ls -lh | grep *.conf Pipe：即 ls 和 grep 命令之间的|(⇧+\)，管道就是连接一个程序输出和另一个程序输入的通路！！！ node.js 项目中的 package.json 文件的作用— 摘自GitHub-PanJiaChen-webpack-and-spa-guide npm install的--save-dev 会把安装的包和版本号记录到 package.json 中的 devDependencies 对象中，还有一个 --save， 会记录到 dependencies 对象中，它们的区别，我们可以先简单的理解为打包工具和测试工具用到的包使用 --save-dev 存到 devDependencies， 比如 eslint、webpack。浏览器中执行的 js 用到的包存到 dependencies， 比如 jQuery 等。那么它们用来干嘛的？ 因为有些 npm 包安装是需要编译的，那么导致 windows / mac /linux 上编译出的可执行文件是不同的，也就是无法通用，因此我们在提交代码到 git 上去的时候，一般都会在 .gitignore 里指定忽略 node_modules目录和里面的文件，这样其他人从 git 上拉下来的项目是没有node_modules 目录的，这时我们需要运行npm install它会读取 package.json 中的 devDependencies 和 dependencies 字段，把记录的包的相应版本下载下来。]]></content>
      <categories>
        <category>周记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[关于 LinkedList]]></title>
    <url>%2F2019%2F03%2F17%2Fabout_LinkedList%2F</url>
    <content type="text"><![CDATA[LinkedList 的 DOC 注释12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * Doubly-linked list implementation of the &#123;@code List&#125; and &#123;@code Deque&#125; * interfaces. Implements all optional list operations, and permits all * elements (including &#123;@code null&#125;). * 该双向链表实现了 List 接口和 Deque 接口。实现了 list 的所有可选操作，并且允许(添加)所有元素(包括 null)。 * &lt;p&gt;All of the operations perform as could be expected for a doubly-linked * list. Operations that index into the list will traverse the list from * the beginning or the end, whichever is closer to the specified index. * 对于该双向链表，所有操作都是可预期的。如果对 list 的操作涉及到指定索引位置的元素，那么将判断指定的索引离 begin 更近，还是离 end 更近。这样能进行更少次数的迭代，性能更好。 * &lt;p&gt;&lt;strong&gt;Note that this implementation is not synchronized.&lt;/strong&gt; * If multiple threads access a linked list concurrently, and at least * one of the threads modifies the list structurally, it &lt;i&gt;must&lt;/i&gt; be * synchronized externally. (A structural modification is any operation * that adds or deletes one or more elements; merely setting the value of * an element is not a structural modification.) This is typically * accomplished by synchronizing on some object that naturally * encapsulates the list. * 需要注意的是 LinkedList 类并不是线程安全的。如果多线程同时访问 linked list，而且至少一个线程会修改 list 的结构，那么它的外部必须使用 synchronized 关键字。(结构性修改指的是 插入(add)或者删除(remove)操作，修改一个元素的值并不是结构性修改)。这通常通过同步(synchronized 修饰)一个 封装了 list 的对象来实现。 * If no such object exists, the list should be "wrapped" using the * &#123;@link Collections#synchronizedList Collections.synchronizedList&#125; * method. This is best done at creation time, to prevent accidental * unsynchronized access to the list:&lt;pre&gt; * List list = Collections.synchronizedList(new LinkedList(...));&lt;/pre&gt; * 如果手头儿没有这样的对象，list 应该被 Collections.synchronizedList() 包裹起来。最好在初始化 LinkedList 对象时候就这样去做，以免不可预知的对 list 的非同步访问。 * &lt;p&gt;The iterators returned by this class's &#123;@code iterator&#125; and * &#123;@code listIterator&#125; methods are &lt;i&gt;fail-fast&lt;/i&gt;: if the list is * structurally modified at any time after the iterator is created, in * any way except through the Iterator's own &#123;@code remove&#125; or * &#123;@code add&#125; methods, the iterator will throw a &#123;@link * ConcurrentModificationException&#125;. Thus, in the face of concurrent * modification, the iterator fails quickly and cleanly, rather than * risking arbitrary, non-deterministic behavior at an undetermined * time in the future. * 通过LinkedList 的 iterator() 方法，或者 listIterator(int) 方法返回的 iterator 都是 fail-fast(快速失效)的：如果在创建 iterator 之后，任何对 list 的结构性修改，都会抛出 ConcurrentModificationException，除了 iterator 本身的 remove() 和 add() 方法。因此，在面临并发对 list 的修改时，iterator 会快速而干净的失效，而不是在未来不确定的时间冒着任意的、不确定的风险。 * &lt;p&gt;Note that the fail-fast behavior of an iterator cannot be guaranteed * as it is, generally speaking, impossible to make any hard guarantees in the * presence of unsynchronized concurrent modification. Fail-fast iterators * throw &#123;@code ConcurrentModificationException&#125; on a best-effort basis. * Therefore, it would be wrong to write a program that depended on this * exception for its correctness: &lt;i&gt;the fail-fast behavior of iterators * should be used only to detect bugs.&lt;/i&gt; * 另外，需要注意的是，，iterator 的 fail-fast 行为是不能被保证的，，通常来说，在并发非同步对 list 的修改时，任何硬性的保证都是不可能的。fail-fast 会让 iterator 尽可能抛出 ConcurrentModificationException。因此，在程序中通过依赖抛出 ConcurrentModificationException 异常来保证自身的正常运行是错误的：fail-fast 行为只应该用来 debug。 * &lt;p&gt;This class is a member of the * &lt;a href="&#123;@docRoot&#125;/../technotes/guides/collections/index.html"&gt; * Java Collections Framework&lt;/a&gt;. * * @author Josh Bloch * @see List * @see ArrayList * @since 1.2 * @param &lt;E&gt; the type of elements held in this collection */public class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable LinkedList 的类属性及构造方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171transient int size = 0;/** * Pointer to first node. // 指向 LinkedList 的第一个节点 * Invariant: (first == null &amp;&amp; last == null) || * (first.prev == null &amp;&amp; first.item != null) */transient Node&lt;E&gt; first;/** * Pointer to last node. // 指向 LinkedList 的最后一个节点 * Invariant: (first == null &amp;&amp; last == null) || * (last.next == null &amp;&amp; last.item != null) */transient Node&lt;E&gt; last;/** * Constructs an empty list. * 构造一个空 list */public LinkedList() &#123;&#125;/** * Constructs a list containing the elements of the specified * collection, in the order they are returned by the collection's * iterator. * 通过指定的 collection 构造一个包含元素的 list，其顺序由 collection 的迭代器决定。 * @param c the collection whose elements are to be placed into this list * @throws NullPointerException if the specified collection is null */public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c);&#125;/** * Appends all of the elements in the specified collection to the end of * this list, in the order that they are returned by the specified * collection's iterator. The behavior of this operation is undefined if * the specified collection is modified while the operation is in * progress. (Note that this will occur if the specified collection is * this list, and it's nonempty.) * 将指定的 collection 的所有元素拼接到 list 的末尾元素之后，顺序由指定的 collection 的迭代器决定。在执行该操作(addAll())的时候，如果 collection 被修改了，该操作的行为将不可预知(请注意，如果指定的 collection 正好是该 list 对象自己，那么这种情况将会发生)。 * @param c collection containing elements to be added to this list * @return &#123;@code true&#125; if this list changed as a result of the call * @throws NullPointerException if the specified collection is null */public boolean addAll(Collection&lt;? extends E&gt; c) &#123; return addAll(size, c);&#125;/** * Inserts all of the elements in the specified collection into this * list, starting at the specified position. Shifts the element * currently at that position (if any) and any subsequent elements to * the right (increases their indices). The new elements will appear * in the list in the order that they are returned by the * specified collection's iterator. * 从指定的位置开始将指定 collection 中的所有元素插入到该 list 中。指定位置的元素(如果有的话)及其右边的元素将会右移(原索引值增大)。新的元素将会以指定 collection 的迭代器 返回的顺序出现在 list 中。 * @param index index at which to insert the first element * from the specified collection * @param c collection containing elements to be added to this list * @return &#123;@code true&#125; if this list changed as a result of the call * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; * @throws NullPointerException if the specified collection is null */public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; // 判断索引是否非法 checkPositionIndex(index); // 将 collection 转为数组 Object[] a = c.toArray(); int numNew = a.length; // 如果为空数组，返回 false if (numNew == 0) return false; Node&lt;E&gt; pred, succ; // 如果索引值与容器的大小相同，即当前 LinkedList 实例中无任何元素 if (index == size) &#123; succ = null; pred = last; &#125; else &#123; succ = node(index); pred = succ.prev; &#125; for (Object o : a) &#123; @SuppressWarnings("unchecked") E e = (E) o; // 构建 Node 节点对象 newNode Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, null); // 如果指定位置的元素位于列表头部，则 newNode 为 first 节点 if (pred == null) first = newNode; else // 否则，前一个节点的 next 属性指向 newNode pred.next = newNode; // pred 指向 newNode，开始下一轮遍历(相当于常规 for 循环的 i++) pred = newNode; &#125; // 如果原 list 为空列表，则经过遍历之后，last 指向 pred if (succ == null) &#123; last = pred; &#125; else &#123; // 如果指定索引位置有值，遍历添加 collection 中的元素之后，指定索引位置的元素及其右侧的所有元素统一右移，，将新增的所有元素中的最后一个元素的 next 指向 右移的元素中的第一个元素；右移的元素中的第一个元素的 prev 属性指向新增元素中的最后一个。 pred.next = succ; succ.prev = pred; &#125; // 原 size 加上 新增元素的数量 size += numNew; // list 的结构性更改次数 +1 modCount++; return true;&#125;private void checkPositionIndex(int index) &#123; if (!isPositionIndex(index)) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125;/** * Tells if the argument is the index of a valid position for an * iterator or an add operation. * 判断参数代表的索引位置在 iterator 或者 add() 中是否可用 */private boolean isPositionIndex(int index) &#123; // 不小于零，且不大于 size return index &gt;= 0 &amp;&amp; index &lt;= size;&#125;/** * Returns the (non-null) Node at the specified element index. * 返回指定位置的非空节点 * 此处遍历 list 查找指定位置的元素时，先判断 index 距离 begin 节点近还是 end 节点。如此可以减少遍历次数，有助于性能表现。大概这就是维护成双向列表而非单向列表的原因吧。 */Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); // 指定的索引值是否小于中位数(翻译成人话就是，判断索引是否在列表的前半段) if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; // 就是硬遍历，直到指定索引位置 // 因为 i &lt; index，所以会遍历到指定索引位置的前一个节点，这时取其 next 指向的节点即可。 for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125;// 私有静态内部类private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; // item 为当前节点的值 this.item = element; // next 指向当前节点的下一个节点 this.next = next; // prev 指向当前节点的前一个节点 this.prev = prev; &#125;&#125; 关于关键字 transient，，一个对象只要实现了 Serializable 接口，该对象就可以被序列化。然而在实际开发过程中，常常会遇到这样的问题，该类有些属性需要序列化，其他属性不需要被序列化。例如一个用户有一些敏感信息（如密码，银行卡号等），为了安全起见，不希望在网络操作（主要涉及序列化）中被传输，这些信息对应的变量就可以加上 transient 关键字，这样变量的生命周期仅存在于调用者的内存中而不会被写到磁盘里持久化。) 首尾节点的操作因为 first 和 last 属性的存在，所以在 LinkedList 中首尾节点的操作效率很高，以 getFirst() 和 removeFirst() 方法为例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// 查/** * Returns the first element in this list. * * @return the first element in this list * @throws NoSuchElementException if this list is empty */public E getFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return f.item;&#125;// 删 /** * Removes and returns the first element from this list. * * @return the first element from this list * @throws NoSuchElementException if this list is empty */public E removeFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return unlinkFirst(f);&#125;/** * Unlinks non-null first node f. * 首先 first 节点的 prev 肯定是 null，先复制它的 next 节点，然后将它的 item 和 next 置空，至此，，first 节点就是一个空的 Node 对象了，最终被 GC。然后判断 next 节点，如果它为null，则说明该 LinkedList 对象只有一个 Node，否则将 first 指向 刚才复制的 next 节点。最后 size 减 1，modCount 加 1。 */private E unlinkFirst(Node&lt;E&gt; f) &#123; // assert f == first &amp;&amp; f != null; // 断言 f 为 first 节点，且 f 不为空 final E element = f.item; final Node&lt;E&gt; next = f.next; f.item = null; f.next = null; // help GC first = next; if (next == null) last = null; else next.prev = null; size--; modCount++; return element;&#125;// '改'就不说了// '增'其实是 removeFirst() 反向操作，略。 关于 modCount 👇12345678910/** * The number of times this list has been structurally modified. * 该列表在结构上被修改的次数 */protected transient int modCount = 0;modCount 为 AbstractList(class LinkedList&lt;E&gt; extends AbstractSequentialList&lt;E&gt; implements List&lt;E&gt;, Deque&lt;E&gt;, Cloneable, java.io.Serializable =&gt;abstract class AbstractSequentialList&lt;E&gt; extends AbstractList&lt;E&gt; =&gt;abstract class AbstractList&lt;E&gt; extends AbstractCollection&lt;E&gt; implements List&lt;E&gt;)的属性 非首尾节点的操作1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889// 删/** * Removes the element at the specified position in this list. * 删除该列表指定位置的元素 */public E remove(int index) &#123; checkElementIndex(index); return unlink(node(index));&#125;/** * Returns the (non-null) Node at the specified element index. * 返回指定位置的非空node，，判断 index 在 LinkedList 的前半部分还是后半部分，然后取循环次数少的分支进行遍历。 */Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); // 保证不会抛出 IndexOutOfBoundsException 异常 // &gt;&gt;：带符号右移。正数右移高位补0，负数右移高位补1。 // 比如：4 &gt;&gt; 1，4 的二进制为 100，移位之后变为 10，即十进制 2。 if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125;/** * Unlinks non-null node x. */E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; // 如果要移除的元素位于头节点，则直接将头节点指向下一个节点。 // 否则将前一个节点的 next 属性指向下一个节点，并将当前节点的 prev 属性置空 if (prev == null) &#123; first = next; &#125; else &#123; prev.next = next; x.prev = null; &#125; // 如果要移除的元素位于尾节点，则直接将尾节点指向前一个节点。 // 否则将下一个节点的 prev 属性指向前一个节点，并将当前节点的 next 属性置空 if (next == null) &#123; last = prev; &#125; else &#123; next.prev = prev; x.next = null; &#125; // 将当前节点的 item 属性置空 x.item = null; // 长度 -1 size--; // 结构性修改次数 +1 modCount++; return element;&#125;// 增public void add(int index, E element) &#123; checkPositionIndex(index); if (index == size) linkLast(element); else linkBefore(element, node(index));&#125;// linkLast 与 linkBefore 方法类似，以 linkBefore 为例void linkBefore(E e, Node&lt;E&gt; succ) &#123; // assert succ != null; // succ 为插入前 index 位置的节点，需要做的是将新节点的 prev 属性指向 succ.prev，将新节点的 next 属性指向 succ。 final Node&lt;E&gt; pred = succ.prev; final Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, succ); succ.prev = newNode; if (pred == null) first = newNode; else pred.next = newNode; size++; modCount++;&#125; 另外值得注意的是，LinkedList 支持插入 null 值，原因在于 Node 的构造方法。插入 null 值时，其实是将 null 值给了 node 节点的 item 属性，node 节点的 prev 和 next 还是 非 null 的。 —- update@2019-03-18 22：23：47 下面—-发现个知识点，，今天点开 LinkedList 中实现的 Deque接口，DOC注释中这样写道：👇 A linear collection that supports element insertion and removal at both ends. The name deque is short for “double ended queue” and is usually pronounced “deck”.Deque 是支持双端插入和删除元素的线性集合，deque 是 double ended queue 的缩写，通常读作 deck。 总结 LinkedList 的本质是双向链表。与 ArrayList 相比，LinkedList 的插入和删除速度更快，但是随机访问速度则很慢。测试表明，对于 10 万条的数据，与 ArrayList 相比，随机提取元素时存在数百倍的差距。除继承 AbstractList 抽象外，LinkedList 还实现了另一个接口 Deque，即 double-ended-queue。这个接口同时具有队列和栈的性质。LinkedList 包含 3 个重要的成员：size、first、last。size 是双向链表中节点的个数。first 和 last 分别指向第一个和最后一个节点的引用。LinkedList 的优点在于可以将零散的内存单元附加引用的方式关联起来，形成按链路顺序查找的线性结构，内存利用率较高。 码出高效 Java 开发手册 P156 清浅池塘—LinkedList 初探 何柄融—ArrayList 和 LinkedList 的区别和使用场景(有删改)]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>源码</tag>
        <tag>LinkedList</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[先行发生原则]]></title>
    <url>%2F2019%2F03%2F13%2FJava_happens_before%2F</url>
    <content type="text"><![CDATA[Context果然，『深入理解Java虚拟机』这本书读一遍是远远不够的，温故总能知新~今天要写的是先行发生原则，说来惭愧，，好像读第一遍的时候并没有太深刻的印象，昨晚再读的时候就拍大腿了：醍醐灌顶啊！！所以，今天还真得扮演搬运工的角色。 啥是先行发生原则说到先行发生原则，还得再往前倒倒，说下 Java 内存模型的特征。Java内存模型是围绕着在并发过程中如何处理原子性、可见性和有序性这个3个特征来建立的。 原子性(Atommicity): 由 Java 内存模型来直接保证原子性变量的操作，包括 read、load、use、assign、store、write, 大致可以认为基本数据类型的访问读写是具有原子性的(long、double 的非原子性协定除外)。如果场景需要更大范围的保证原子性，则需要 lock 和 unlock 操作。反映到 Java 代码中就是同步块– synchronized 关键字。因此，所以 synchronized 块之间的操作也具备原子性。 可见性(Visibility): Java 内存模型是通过在变量修改后将新值同步回主存，在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式来实现可行性的，无论是普通变量还是 volatile 变量都是如此。只不过，volatile 关键字能保证新值被立即同步回主内存，以及每次使用前从主内存刷新，普通变量则不能保证这一点。 除此之外，synchronized 和 final 关键字也可以保证变量的可见性。同步快的可见性是由『对一个变量执行 unlock 操作之前，必须先把此变量同步回主内存中(执行 store 和 write 操作)』这条规则获得的。而 final 关键字的可见性是指: 被 final 修饰的字段在构造器中一旦初始化完成，并且构造器没有把 this 的引用传递出去^1，那么在其他线程中就能看见 final 字段的值。(最初以为是因为 final 修饰的变量不能被修改，所以导致所有线程读到的值都是一样的，不变的，，然鹅并不是[^2])。 有序性(Ordering): Java 程序中天然的有序性可以总结为一句话：如果在本线程内观察，所有操作都是有序的；如果在一个线程中观察另外一个线程，所有的操作都是无序的。前半句是指“线程内表现为串行的语义(Within-Thread As-If Serial Semantics)”，后半句是指“指令重排序”和“工作内存和主内存同步延迟”线程。 volatile 关键字本身就含有禁止指令重排的语义，而 synchronized 则是由『一个变量在同一时刻只允许一条线程对其进行 lock 操作。』这条规则获得的，这条规则决定了持有同一个锁( lock 操作的变量)的两个同步块只能串行的进入。 好像 synchronized 关键字在需要这3种特性的时候都可以作为其中一种解决方案，于此同时其万能的属性导致了被我们程序员滥用。。 逼逼叨半天，还是没提到啥是先行发生原则。。别急，马上。。如果 Java 内存模型中所有的有序性都靠 volatile 和 synchronized 来完成，那么有一些操作将变得非常繁琐，然鹅我们在写代码的过程中并没有感受到这一点，这就是因为『先行发生原则』。它是判断数据是否存在竞争、线程是否安全的主要依据。先行发生是在 Java 内存模型中定义两项操作之间的偏序关系，如果说操作 A先行发生于操作 B，则说明发生操作B之前，操作 A 产生的影响能被操作 B 观察到，“影响”包括修改了内存中共享变量的值、发送了消息、调用了方法等。 12345678// 以下操作在线程 A 中执行i = 1;// 以下操作在线程 B 中执行j = i;// 以下操作在线程 C 中执行i = 2; 👆 假设线程 A 中的操作”i = 1”先行发生于线程 B 的操作”j = i”, 那么可以确定的是线程 B 的操作执行后，变量 j 一定等于 1，得出这个结论的依据有两个： 根据先行发生原则，”i = 1”的结果可以被观察到； 线程 C 还没”登场”, 线程 A 操作结束之后没有其他线程会修改变量 i 的值。现在再来考虑线程 C，我们依然保持线程 A 和线程 B 之间的先行发生关系，而线程 C 出现在线程 A 和线程 B 的操作之间，但是线程 C 与线程 B 没有先行发生关系，那 j 的值就无法确定了。 下面是 Java 内存模型中一些”天然”的先行发生关系，它们无须任何同步器的协助就已经存在，可以在编码中直接使用。如果两个操作之间的关系不在此列，并且无法从下列规则中推导出来的话，他们就没有顺序性保障，虚拟机可以对它们随意地进行重排序。 程序次序原则(Program Order Rule): 在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于写在后面的操作。准确来说是程序流顺序而不是代码顺序，因为要考虑分支和循环。 管程锁定原则(Monitor Lock Rule): 一个 unlock 操作先行发生于后面对同一个锁的 lock 操作。这里必须强调的是同一个锁，而”后面”是指时间上的先后顺序。 volatile 变量规则(Volatile Variable Rule): 对于一个volatile 变量的写操作先行发生于后面对这个变量的读操作，这里的”后面”同样是指时间上的先后。 线程启动规则(Thread Start Rule): Thread 对象的 start() 方法先行发生于此线程的每一个动作。 线程终止规则(Thread Termination Rule): 线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过 Thread.join() 方法结束、Thread.isAlive() 的返回值等手段检测到线程已经终止运行。 线程中断原则(Thread Interruption Rule): 线程中的所有操作都先行发生于被中断线程的代码检测到中断事件的发生，可以通过 Thread.interrupted() 方法检测到是否有中断发生。 对象终结原则(Finalizer Rule): 一个对象的初始化完成(构造函数执行结束)先行发生于它的 finalize()[^3]法的开始。 传递性(Transitivity): 如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，则操作 A 先行发生于操作 C。 举个栗子：👇123456789private int value = 0;public void setValue(int value)&#123; this.value = value;&#125;public int getValue()&#123; return value;&#125; 上面👆的代码为最普通的 getter/setter 方法。假设存在线程 A 和 B，线程 A 先(时间上的先)调用了”setValue(1)”，然后线程 B 调用了同一个对象的”getValue()”，那么线程 B 收到的返回值为多少？ 由两个方法分别为线程 A 和线程 B 调用，不在同一个线程中，所以程序次序规则在这里不适用；由于没有同步块，自然不会发生 lock 和 unlock 操作，所以管程锁定规则也不适用；由于 value 变量没有被 volatile 修饰，所以 volatile 变量规则在这里也不适用；后面的线程启动、终止、中断规则和对象终结规则也和这里完全没有关系。因为没有一个适用的先行发生规则，所以最后一条传递性也无从谈起。因此，我们可以判定：尽管线程 A 在操作时间上先于线程 B，但是无法确定线程 B 中 getValue() 方法的返回值，即这里的操作不是线程安全的。 解决方式也很简单，要么把 getter/setter 方法都定义为 synchronized 方法，这样就可以适用于管程锁定规则；要么把 value 定义为 volatile 变量，由于 setter 方法对 value 值的修改不依赖 value 的原值，满足 volatile 关键字使用场景，这样就可以套用 volatile 变量规则来满足先行发生原则。通过上面的例子，，我们可以得出一个结论：一个操作”时间上的先发生”不代表这个操作会是”先行发生”，那如果一个操作”先行发生”是否就能对导出这个操作必定是”时间上的先发生”呢？很遗憾，同样也不能，一个典型的例子就是”指令重排序”。👇123// 下面操作在同一个线程中执行int i = i;int j = 2; 👆根据程序次序规则，int i = 1;先行发生于int j = 2;但是int j = 2;的代码完全可能先被处理器执行，这并不影响先行发生原则的正确性，因为我们在这条线程中是无法感知到这点的。 [^2]: Java的Final 关键字的内存语义 [^3]: Java 禁止使用 finalizer 方法]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>线程安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于微观下i++的并发执行]]></title>
    <url>%2F2019%2F03%2F08%2Fabout_java_microcosmic_i%2B%2B%2F</url>
    <content type="text"><![CDATA[Context最近一直没有更新文章是因为过得很充实，，一方面，现在在做小程序的线上商城，小程序这边倒没什么难的，难的是服务器端怎么设计架构，涉及到不同的客户,不同的客户门店组织架构又不一样，硬件条件也不一样，商品也不一样，还需要跟 ERP 的同事进行沟通。。另一方面，一直计划在房子合同到期(2019-04-04)之后换工作，所以积极准备面试，查漏补缺什么的。去年12月份时候，买了『深入理解Java虚拟机』和『Java并发编程的艺术』。前者全是干货，干到没法儿写博客做笔记，否则就是在照搬书上的内容了。后者，，额，有点晦涩，没有读下去的欲望，然后就放在省图计算机科学分类下的书架上了，嗯，上周末去省图发现那本书已经不见了🤣。对了，与此同时，，发现了 vue-element-admin 框架，一直想试试 webpack，然后就在不忙的时候慢慢重构现有的后台页面。用封装好的组件写页面真省心，爽的飞起~ 嗯，，今天的主要内容来自『深入理解Java虚拟机』的第五部分第一章–Java内存模型与线程。 这是第二次读这一部分了，，第一次读的时候大水漫灌囫囵吞枣，全局把握(大误)。这次读的时候主要的是抠细节，温故知新，受益匪浅！下面进入正题儿~ Java内存模型与线程硬件的效率与一致性 由于计算机的存储设备与处理器的运算速度有几个量级的差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高速缓存(Cache)来作为内存与处理器之间的缓冲：将运算需要使用的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步回内存之中，这样处理器就无须等待缓慢的内存读写了。 基于高速缓存的存储交互很好的解决了处理器与内存之间的速度矛盾，但是也为计算机系统带来更高的复杂度，因为它引入了一个新的问题：缓存一致性(Cache Coherence)。在多处理器系统中，每个处理器都有自己的高速缓存，而他们又共享同一主存。 – Page 361 Java内存模型 Java 虚拟规范试图定义一种 Java 内存模型 (Java Memory Model, JMM) 来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让 Java 程序在各种平台下都能达到一致的内存访问效果。 Java 内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。 Java 内存模型规定了所有的变量都存储在主内存(Main Memory)中，每条线程还有自己的工作内存(Working Memory)，线程中保存了被该线程使用到的变量的主内存的副本拷贝，线程对变量的所有操作(读取、赋值等)都必须在工作内存中进行，而不能直接读写主内存中的变量。不同线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成。– Page 362-363 关于主内存和工作内存之间具体的交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步回主内存之类的实现细节，Java 内存模型中定义了一下 8 种操作来完成，虚拟机实现时必须保证下面提及的每一种操作都是原子的、不可再分的( double 和 long 例外)。 lock(锁定)：作用于主内存的变量，它把一个变量标识为一条线程独占的状态。 unlock(解锁)：作用于主内存的变量，它把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。 read(读取)：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便随后的 load 动作使用。 load(载入): 作用于工作内存的变量，它把read操作的从主内存中得到的变量值放入工作的变量副本中。 use(使用)：作用于工作内存的变量，它把工作内存中的一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作。 assign(赋值)：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存中的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。 write(写入)：作用于主内存的变量，它把 store 操作从工作内存中得到的变量的值放入主内存的变量中。 – Page 365 需要注意的是，上面👆提及的每一种操作都是原子的，，而不是『从内存中读取变量，然后修改变量，然后回写到内存』这整个过程是原子的。这意味着多线程情况下，不加干预时上面8种操作在线程间是交替进行的。如对主内存中的变量a、b 进行访问时，一种可能出现的顺序是 read a, read b, load b, load a.. volatile关键字 当一个变量定义为 volatile 之后，它将具备两种特性，第一是保证此变量对所有线程的可见性，这里“可见性”是指当一条线程修改了这个变量的值，新值对于其他线程来说是立即得知的。而普通变量无法做到这一点，普通变量的值，在线程间传递均需要通过主内存来完成。例如，线程 A 修改一个普通变量的值，然后向主内存进行回写，另外一条线程 B 在线程A回写完成之后再从主内存进行读取操作，新变量的值才会对线程 B 可见。 – Page 366 不得不说的是，读到这里的时候很困惑，，volatile 是如何让被修改后的变量值立即被其他线程得知的呢？？？这就不得不提到MESI协议，MESI协议使用四个状态位描述每一个缓存行(Cache Line)。关于缓存行，在这篇文章中只需要知道它是 cache 和 RAM 交换数据的最小单位,通常为 64 Byte就可以了。 ok，下面简单说说MESI协议。 M(Modified)：表示当前 Cache 行中包含的数据与内存中的数据不一致，而且它仅在本 CPU 的 Cache 中有效，其他 CPU 的 Cache 中不存在拷贝，即这个 Cache 行的数据是当前处理器系统中最新的数据拷贝。当 CPU 对这个 Cache 行进行替换操作时，必然会引发系统总线的写周期，将 Cache 行中数据与内存中的数据同步。 E(Exclusive)：与 Modified 状态类似，唯一的区别是 Modified 状态表示当前 Cache Line 中的数据与内存中的数据不一致，而 Exclusive 状态下的 Cache 与内存中的数据一致。 S(Shared)：表示缓存行中包含的数据有效，而且在当前 CPU 和其他 CPU 中至少存在一个副本。在该缓存行中的数据是当前处理器系统中最新的数据拷贝，而且与内存中的数据一致。I(Invalid)：表示当前缓存行中数据无效。 在 MESI 缓存一致性协议下，我们看看在Java中 i++ 操作是怎么执行的。 两个 CPU A、B(即多核多线程)同时执行 i++ 的操作，假设 i 初始值为0： CPU A 从主内存中读入(read) i 到工作内存，并载入(load)到副本，此时其他 CPU 的缓存中并不存在变量 i，所以 CPU A 中缓存行状态为 Exclusive。 CPU B 从主内存中读入(read) i 到工作内存，并载入(load)到副本，发现 CPU A 的缓存中已经存在变量 i 了，那么CPU B 中工作缓存的相关缓存行设置为 Shared，CPU A 中的相关缓存行也设置为 Shared。 CPU A 开始执行 i++，i 值加一等于一，但是只是在寄存器中，并未写入缓存，此时状态还是 Shared。 CPU B 开始执行 i++，i值加一等于一，同上，还是 Shared。 CPU A 将计算后的值重新赋值(assign)给缓存中的副本，i 值为1，缓存行状态改为 Modified，此时 CPU B 的缓存行状态改为 Invalid。 CPU B 准备比赋值给缓存中 i 的副本时，发现缓存行已处于无效(Invalid)状态，需要从内存中重新读取(read)，又因为 CPU A 中相关缓存行中有变量 i 且为 Modified 状态，那么要求CPU A 将计算后的 i 值回写入(write)内存，内存中的 i 值为1，CPU A的缓存行状态为 Exclusive，CPU B 将内存中的 i 值读入(read+load)自己的缓存中的变量i的副本，此时CPU A、B 的缓存行都为 Shared，i 值都为1。 CPU B 将 工作内存中的 i 值副本写入(write)到内存中，i 值副本此时为1，内存中的 i 值亦为1，即把1赋值给1，CPU B 中缓存行的状态变为 Modified，CPU A中的缓存行值变为Invalid。 以上👆即为不加人为干预情况(使用volatile、synchronized关键字)下 i++ 在多核多线程架构中可能产生的执行结果。所以 MESI 缓存一致性协议并不能保证内存一致性。另外，在上面的例子中，表述并不算太严谨，，比如关于提到的『工作内存』，在『深入理解Java虚拟机』中是这么说的： 为了获取更好的运行速度，虚拟机(甚至是硬件系统本身的优化措施)可能会让工作内存优先存储于寄存器和高速缓存中，因为程序运行时主要访问读写的是工作内存。– Page 364 还有，在1、2中，CPU A、B read 并 load i 到工作内存中的副本中，在书中是这样说的： Java 内存模型只要求read、load和store、write操作必须按顺序执行，而没有保证是连续执行。也就是说，read与Load之间、stire与write之间是可插入其他质量的。如对内存中的变量a、b进行访问时，一种可能出现的顺序是read a、read b、load b、load a。– Page365 👆诸如此类，，所以，嗯，注意领会精神。 OK，进行下一话题..倘若此时我们使用 volatile 关键字修饰变量 i。因为 volatile 表示不使用寄存器的值，每次都从内存读(不包括缓存)。所以，在上边例子中的第三步，assign 工作内存中 i 的副本之后，立即将值回写到主内存中。书中的表述为： 有 volatile 修饰的变量，在编译成汇编语言之后，比不使用 volatile 修饰变量多了一行lock addl $0x0,(%esp),查询 IA32 手册得知，它的作用是使得本 CPU 的 Cache 写入了内存，该写入动作也会引起别的 CPU 或者别的内核无效化(Invalidate)其 Cache，这种操作相当于对 Cache 中的变量做了一次前面介绍Java内存模式中所说的“store”和“write”操作。所以通过这样一个操作，可让前面 volatile 变量的修改对其他 CPU 立即可见。 写到这里，我们可能会觉得 i++ 被 volatile 修饰过之后，就可得到期望的 i 值。然而即使这样，我们得到的 i 值依然比期望值要小。 问题就出在自增运算“i++”之中，我们用 javap 反编译这段代码后会发现只有一行 i++ 的代码在 Class 文件中是由4条字节码指令构成的。123456// i 为静态变量0: getstatic3: iconst_14: iadd5: putstatic&gt; 从字节码层面上很容易就分析出并发失败的原因了：当 getstatic 指令把 i 值取到操作栈时，volatile 关键字保证了 i 的值在此时是正确的，但是在执行 iconst_1、iadd 这些指令的时候，其他线程可能已经把 i 的值加大了，而在操作栈顶的值就变成了过期的数据，所以 putstatic 指令执行后就可能把较小的 i 值同步回主内存之中。(PS: 一条字节码指令，也并不意味着执行这条指令就是一个原子操作。一条字节码指令在解释执行时，解释器将要运行许多行代码才能实现它的语义，如果是编译执行，一条字节码指令也可能转化为若干条本地机器码指令。) 由于 volatile 变量只能保证可见性，在不符合一下两条规则的运算场景中，我们仍要通过锁(使用synchronized和java.util.conrurrent中的原子类)来保证原子性。 运算结果并不依赖变量的当前值，或者能够确保只有单一线程修改变量的值。 变量不需要与其他的状态变量共同参与不变约束 所以，，此时如果要解决 i++ 的问题，靠 volatile 关键字是不行的，要么将 volatile 关键字改为 synchronized 关键字上锁(lock 作用于主内存，它把一个变量标识为一条线程独占的状态。)；要么，将 i++ 替换为 Java 并发工具包中的 AtomicInteger 类:123AtomicInteger i = new AtomicInteger(0);...AtomicInteger.incrementAndGet(); 参考链接： 不可不说的Java“锁”事 缓存一致性协议 mesi volatile实现可见性的原理 cache一致性协议，MESI和MOESI 周志明-深入理解Java虚拟机 一针见血系列[8]: 什么叫内存可见性？什么叫寄存器可见性？ MESI与内存屏障]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>线程安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[普鲁斯特问卷-2018]]></title>
    <url>%2F2018%2F12%2F31%2FProustQA_2018%2F</url>
    <content type="text"><![CDATA[🕯🕯🕯我上小学，你出差；之后我开始住校，初中两周回家一次，每次两天；高中四周回家一次，每次不到36小时；我上大学了，你退休了，我半年回家一次。如果你还在.. 你认为最完美的快乐是怎样的？内心的平静 你最希望拥有哪种才华？还是将问题抽象成代码的能力 你最恐惧的是什么？变老 你目前的心境怎样？邻居不懂事儿，挪动椅子和桌子的时候硬扯，发出刺耳的声音，，MMP这一年过得真特么快！！ 还在世的人中你最钦佩的是谁？由埃隆马斯克临时改为『丁香医生』，，不会删稿，对每一个字负责，欢迎来告。 你认为自己最伟大的成就是什么？大概是全马323吧 你自己的哪个特点让你最觉得痛恨？亲密关系里把握不好度？ 你最喜欢的旅行是哪一次？2018年端午节的苏州之旅，，准确来说是喜欢苏州 你最痛恨别人的什么特点？不知何为个人边界！ 你最珍惜的财产是什么？个人信用 你最奢侈的是什么？很幸运，，如此幸运 你认为程度最浅的痛苦是什么？浅的都不痛苦，痛苦都不浅 你认为哪种美德是被过高的评估的？这个话题一两句说不清楚，，容易引战。 你最喜欢的职业是什么？还是程序员，，能用技术改变世界的职业都是我喜欢的 你对自己的外表哪一点不满意？右边的眉毛，，为什么你不能听话一点.Smile. 你最后悔的事情是什么？大学时太混沌，而且当时完全不自知.. 还在世的人中你最鄙视的是谁？杠精们，，Love&amp;Peace 你最喜欢男性身上的什么品质？能为自己说过的话、做过的事负责 你使用过的最多的单词或者是词语是什么？Clear?(PS: 跟别人沟通时，不确定对方是否完全接收到自己想传达的信息，会问一句Clear？Clear = 我表达清楚了么？+你GET到了么？) 你最喜欢女性身上的什么品质？真∙男女平等 你最伤痛的事是什么？形同陌路 你最看重朋友的什么特点？言行一致，，不整那些片儿汤话 你这一生中最爱的人或东西是什么？Macbook Pro 15’’ (Especially 32G)，，心心念 你希望以什么样的方式死去？安乐死，或者一场猝不及防的意外 何时何地让你感觉到最快乐？写了一大段代码，一次就能跑起来，不用调试的那种 如果你可以改变你的家庭一件事，那会是什么？早点让我知道电脑不光可以玩游戏..大家身体健康就好，别的真不奢求 如果你能选择的话，你希望让什么重现？小我：早上被我爸的录音机(装磁带的那个)叫醒，我该起床吃饭上学了。大我：太阳系重回三维宇宙。 你的座右铭是什么？生命的过程，无论是阳春白雪，青菜豆腐，我都得尝尝是什么滋味，才不枉来走这么一遭。 Extra..2018年的 Keyword 是？？ 『焦虑』，，最焦虑的时候会在公交车上用手机学习廖雪峰老师的Python教程 😔 除了两点一线，你最常去的地方是？？周五下班在北国商城下车，去勒泰溜一圈，步行回家。周日没什么事儿就去省图待一会儿。 为什么要去省图？？保持焦虑。。在省图，年长的人在学习，年幼的人在学习，同龄人也在学习。 所以，这一年你都学了些啥？？ 小程序爆发，想给自己做个小程序，用来收集自己的位置信息。所以看文档学习了小程序，中间还必须学 Vue.js。然后刚好公司也要准备做小程序，，所以，这一年大部分时间都在做与小程序相关的项目，对微信公众号和小程序的 API 熟悉了很多，中间爬过的坑都在博客中记录下来了。 重读『哲学家都干了些什么』 重读『三体』 学习『鸟哥的 Linux 私房菜(基础学习篇)』: 计算机概论、Linux 是什么、首次登陆与在线求助 man page、Linux 的文件权限与目录配置、Linux 文件与目录管理、Linux 磁盘与文件系统管理(认识Ext2文件系统)、文件与文件系统的压缩与打包(Linux 系统常用压缩命令、打包命令tar)、Vim 编辑器、认识与学习Bash、正则表达式与文件格式化处理、学习Shell Script、例行性工作、程序管理与 SELinux 初探(工作管理（job controller）、进程管理)。全书778页，只选修了部分章节，，嗯，一边学一边忘，一边忘一边学。。 买了 Linux 服务器，主要用来部署自己做的小程序服务端和linux相关的技术验证练习(Tomcat MySql Redis Nginx https)；顺便搭了梯子。 粗读一遍『码农翻身』，第二遍正在精读中.. 为了缓解焦虑，正在抄『飞鸟集』，目前抄到了第122首。 廖雪峰老师的 Python 教程前10章断断续续看了3遍，，因为工作中用不到，真是一边学一边忘。。12月初，用 Python 的开源框架 Scrapy 写了超市商品图片爬虫，感觉还不错~嗯，现在正在学第四遍。。 学会了拒绝，学会了独处。(大概就是这样，，期间也读了其他书，暂时没有读第二遍的兴趣，略过不表。) 明年准备学啥？争取在4月份前读完『深入理解Java虚拟机』和『Java并发编程的艺术』，然后再读一遍『Java编程思想』，，把剩下的『人类简史』和『宇宙简史』收个尾。。 还有什么想说的没？？ 不会的东西越来越多，我可能会一直焦虑下去。。 讨好自己总归是最容易的 没那么喜欢老罗了，对他的期待只剩下自传了。 Talk is cheap, show me your code phone. 以前总盼着接私活儿，现在完全没这种感觉了。个人项目一般价格敏感；公司项目一般有坑，大概率背锅。而且，接私活儿是对八小时工作制的严重亵渎！有时间多看会儿书，点点技能树多好~ 坚持看人民日报。]]></content>
      <categories>
        <category>ProustQA</category>
      </categories>
      <tags>
        <tag>普鲁斯特问卷</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018年11月第三周]]></title>
    <url>%2F2018%2F11%2F20%2F2018_11_week_3rd%2F</url>
    <content type="text"><![CDATA[shadowssocks日志级别配置Context这个，，闲得无聊，看了看shadowsocks.log文件👇123456# 江湖险恶啊，，请求IP地址处理了下下。2018-11-20 07:45:21 INFO connecting mtalk.google.com:5228 from 1*4.2*6.2*0.10:423732018-11-20 07:46:21 INFO connecting mtalk.google.com:5228 from 1*4.2*6.2*0.10:423762018-11-20 07:46:39 INFO connecting notifications.google.com:443 from 1*4.2*6.2*0.10:423772018-11-20 07:47:22 INFO connecting mtalk.google.com:5228 from 1*4.2*6.2*0.10:422392018-11-20 07:47:58 INFO connecting clients4.google.com:443 from 1*4.2*6.2*0.10:42346 日志信息中没啥特别有用的信息，，关键是这么长时间了，日志文件已经很大了👇12[root@host ~]# ls -lh /var/log/shadowsocks.log-rw-r--r-- 1 root root 56M Nov 20 08:21 /var/log/shadowsocks.log 已然55M了，既然目前没有时间精力去搞输出更详细的日志，，那么只好想办法把这些日志信息要么按日期时间分割下，要么提高下日志输出级别(正常请求信息不输出，只输出WARN级别以上的信息)。 开搞很用力地翻了文档，没找到什么关于日志的信息。只知道日志文件在/var/log/shadowsocks.log，然并卵。只好自己动手翻源码了，好可怕。。。 这个Python，，零零星星翻过两遍，在廖雪峰的博客网站上，并没有实际深入去了解，更别说做项目了(关键是工作中暂时用不到..)，有点怂。打开项目之后，并不知道从哪儿开始看…不过，我们可以搜索关键字信息啊，哈哈…笑得一点底气都没有…直接搜『/var/log/shadowsocks.log』，我们可以看到在⁨shadowsocks-2.8.2⁩/⁨shadowsocks⁩/shell.py文件中👇12345678910111213141516171819# 日志文件配置路径 R224config['log-file'] = config.get('log-file', '/var/log/shadowsocks.log')## config？难道是我想的那种config么？？？继续往下看 R245logging.getLogger('').handlers = [] logging.addLevelName(VERBOSE_LEVEL, 'VERBOSE') if config['verbose'] &gt;= 2: level = VERBOSE_LEVEL elif config['verbose'] == 1: level = logging.DEBUG elif config['verbose'] == -1: level = logging.WARN elif config['verbose'] &lt;= -2: level = logging.ERROR else: level = logging.INFO verbose = config['verbose'] logging.basicConfig(level=level, format='%(asctime)s %(levelname)-8s %(message)s', datefmt='%Y-%m-%d %H:%M:%S')## 看到这儿好像问题解决了。。 原来配置文件中可以通过 verbose 来设置日志的输出级别，结合脚本代码和日志信息，可以看到默认级别为 INFO，那么接下来我们只需要在/etc/shadowsocks.conf中添加&quot;verbose&quot;: -1就可将日志级别提升至WARN了~别忘了重启服务噢1234[root@host ~]# ssserver -c /etc/shadowsocks.json -d restartINFO: loading config from /etc/shadowsocks.jsonstoppedstarted 亲测有效~但是！WARNING日志也很多，，无奈直接改成了&quot;verbose&quot;:-2。关于其他配置，有兴趣的同学可以查阅下shell.py文件中的config对象的具体信息。 另外日志输出信息是在⁨shadowsocks-2.8.2⁩/shadowsocks⁩/tcprelay.py文件中12# R293logging.info('connecting %s:%d from %s:%d' %(common.to_str(remote_addr), remote_port, self._client_address[0], self._client_address[1])) 看样子我们可以控制日志具体输出哪些内容的，，对python比较了解的同学可以尝试修改下，可以试着添加上请求用户的信息~ 微信防盗链Context微信公众号使用开发模式后，部分功能就只能使用API接口去实现了，，比如『自定义菜单』功能。所以这个时候，需要在后台实现类公众号后台的自定义菜单功能。这其中就会涉及到素材引用的问题，，倘若直接在自己服务器中的后台中引用，就会出现如下图片👇 但如果直接在浏览器中输入图片地址就可以正常访问。后来得知是referrerPolicy在作怪。 meta标签我们需要做的是在请求图片资源的时候隐藏自己的referrer，避免腾讯识别出我们的服务器不是自己人。具体做法是添加meta标签(详细信息参考MDN-Referrer-Policy)👇12# content值也可以是no-referrer&lt;meta name="referrer" content="same-origin"&gt; 倘若，，引用的图片是通过CSS中background-color引用的，那就悲催了。。想办法将div元素转为img元素，通过src属性引用图片，这样也是可以的。 img.referrerPolicy如果不想用meta标签，也可以在img元素中添加referrerPolicy属性，也可以正常引用(详见HTMLImageElement-referrerPolicy)。如果无效，请尝试清空缓存之后重新请求，亲测有效~ link.referrerpolicy如果是引用外部样式，，可以在link标签中添加referrerpolicy属性，，详见Element-link。 需要注意的是，，img.referrerPolicy和link.referrerpolicy属于实验功能，使用前务必检查自己的浏览是否支持！另外，，不能通过ducument.referrer=&#39;no-referrer&#39;去修改，因为ducument.referrer是只读属性..详见ducument.referrer 其他text-overflow样式用来控制文字溢出盒子之后的处理逻辑，，值为clip，则直接裁切(即隐藏)值为ellipsis，则显示溢出省略标记… white-space: nowrap 文本不换行 word-wrap用来控制文本超出元素边界后的对英文单词换行的处理逻辑，适用于块元素，行元素需设置width、height。值为break-word，则以单词为单位换行；值为break-all，则以字母为单位换行。]]></content>
      <categories>
        <category>周记</category>
      </categories>
      <tags>
        <tag>shadowscoks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于 nginx 日志分析]]></title>
    <url>%2F2018%2F11%2F10%2Fabout_nginx_log_analyse%2F</url>
    <content type="text"><![CDATA[Context这次是自己的需求，刚好周六，闲来无事来公司加班，好好总结下。 自己做了个小程序，用来收集平时的位置信息，还有微信步数什么的，租的国外的服务器，，翻墙和部署项目两不误，顺便做做linux的练习，完美~ 在初期，部署项目以及一些静态资源时，经常404，肯定nginx哪里配置错了，，直接在linux服务器上用命令行翻日志又很麻烦，ssh还总断(扶额)。把nginx日志文件当静态资源访问好啦，这样直接在浏览器就可以访问，完美~这一步并不难，好好配置nginx.conf中的location属性就好，略过不表。 但我担心的是访问路径暴露了怎么办。。有必要加上基础的访问限制，验证用户名密码什么的。还要自己写个页面？在数据库配置用户名密码？太不优雅了。还好有nginx的auth_basic模块，完美解决问题~ 这之后，有一次闲来没事，翻翻nginx日志，，呦，被吓一跳！👇12345678910&#123;"timestamp":"2018-11-09T19:58:25-05:00","host":"66.98.120.58","client":"180.180.243.223","size":162,"requestlengh":195,"requesttime":0.000,"responsetime":"-","domain":"66.98.120.58","url":"/dbadmin/index.php","referer":"-","agent":"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:59.0) Gecko/20100101 Firefox/59.0","status":"404","x_forwarded_for":"-"&#125;&#123;"timestamp":"2018-11-09T19:58:26-05:00","host":"66.98.120.58","client":"180.180.243.223","size":162,"requestlengh":202,"requesttime":0.000,"responsetime":"-","domain":"66.98.120.58","url":"/web/phpMyAdmin/index.php","referer":"-","agent":"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:59.0) Gecko/20100101 Firefox/59.0","status":"404","x_forwarded_for":"-"&#125;&#123;"timestamp":"2018-11-09T19:58:26-05:00","host":"66.98.120.58","client":"180.180.243.223","size":162,"requestlengh":197,"requesttime":0.000,"responsetime":"-","domain":"66.98.120.58","url":"/admin/pma/index.php","referer":"-","agent":"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:59.0) Gecko/20100101 Firefox/59.0","status":"404","x_forwarded_for":"-"&#125;&#123;"timestamp":"2018-11-09T19:58:26-05:00","host":"66.98.120.58","client":"180.180.243.223","size":162,"requestlengh":197,"requesttime":0.000,"responsetime":"-","domain":"66.98.120.58","url":"/admin/PMA/index.php","referer":"-","agent":"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:59.0) Gecko/20100101 Firefox/59.0","status":"404","x_forwarded_for":"-"&#125;&#123;"timestamp":"2018-11-09T19:58:26-05:00","host":"66.98.120.58","client":"180.180.243.223","size":162,"requestlengh":199,"requesttime":0.000,"responsetime":"-","domain":"66.98.120.58","url":"/admin/mysql/index.php","referer":"-","agent":"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:59.0) Gecko/20100101 Firefox/59.0","status":"404","x_forwarded_for":"-"&#125;&#123;"timestamp":"2018-11-09T19:58:26-05:00","host":"66.98.120.58","client":"180.180.243.223","size":162,"requestlengh":200,"requesttime":0.000,"responsetime":"-","domain":"66.98.120.58","url":"/admin/mysql2/index.php","referer":"-","agent":"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:59.0) Gecko/20100101 Firefox/59.0","status":"404","x_forwarded_for":"-"&#125;&#123;"timestamp":"2018-11-09T19:58:27-05:00","host":"66.98.120.58","client":"180.180.243.223","size":162,"requestlengh":204,"requesttime":0.000,"responsetime":"-","domain":"66.98.120.58","url":"/admin/phpmyadmin/index.php","referer":"-","agent":"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:59.0) Gecko/20100101 Firefox/59.0","status":"404","x_forwarded_for":"-"&#125;&#123;"timestamp":"2018-11-09T19:58:27-05:00","host":"66.98.120.58","client":"180.180.243.223","size":162,"requestlengh":204,"requesttime":0.000,"responsetime":"-","domain":"66.98.120.58","url":"/admin/phpMyAdmin/index.php","referer":"-","agent":"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:59.0) Gecko/20100101 Firefox/59.0","status":"404","x_forwarded_for":"-"&#125;&#123;"timestamp":"2018-11-09T19:58:27-05:00","host":"66.98.120.58","client":"180.180.243.223","size":162,"requestlengh":205,"requesttime":0.000,"responsetime":"-","domain":"66.98.120.58","url":"/admin/phpmyadmin2/index.php","referer":"-","agent":"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:59.0) Gecko/20100101 Firefox/59.0","status":"404","x_forwarded_for":"-"&#125;&#123;"timestamp":"2018-11-09T19:58:27-05:00","host":"66.98.120.58","client":"180.180.243.223","size":162,"requestlengh":198,"requesttime":0.000,"responsetime":"-","domain":"66.98.120.58","url":"/mysqladmin/index.php","referer":"-","agent":"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:59.0) Gecko/20100101 Firefox/59.0","status":"404","x_forwarded_for":"-"&#125; 👆以上是今天nginx日志中的一部分，，谢谢来自IP180.180.243.223(泰国)朋友的问候，，嗯，访问的路径都是/mysqladmin/index.php、/admin/mysql/index.php、/admin/PMA/index.php什么的，太暴力了！！我还是个孩子呀。。啥都别说了，nginx必须配置动态黑名单！ basic_auth直接看nginx官方文档就好ngx_http_auth_basic_module，教程也很多，比较简单，，也是略过不表。123456# 关于配置访问用户名和密码，，# 第一次需要创建密码文件，加 -c 参数htpasswd -c 密码文件路径 用户名# 生成密码文件之后，再添加用户名密码htpasswd 密码文件路径 用户名 添加动态ip黑名单这一块，最早是想用ELK的，，然后服务器崩溃了。嗯，1G内存，放弃了。还是用awk吧，之前看到 awk 的时候，命令那么长，看都没看直接略过了。后来拖太久又没找到好的解决方案，硬着头皮上吧，，花点时间读一读文档，其实也没太难(至少实现本节内容不算太难)。这儿主要参考了 Hjqjk’s Blog-Nginx动态黑名单，这位仁兄的博客看样子也是用的HEXO框架，哈哈同道中人~ 需要说明的是，，因为还想过用Java IO将日志持久化到数据库，这样就可以用语句分析访问行为了，生成图表也方便。想想，工程量有点大，，后期日志数据可能比较收集到的位置信息和微信步数数据还要大，嗯排期吧先(笑哭)。所以，将nginx日志格式配置成了json格式👇12345678910111213141516# json 格式配置log_format logstash_json '&#123;"timestamp":"$time_iso8601",' '"host":"$server_addr",' '"client":"$remote_addr",' '"size":$body_bytes_sent,' '"requestlengh":$request_length,' '"requesttime":$request_time,' '"responsetime":"$upstream_response_time",' '"domain":"$host",' '"url":"$request_uri",' '"referer":"$http_referer",' '"agent":"$http_user_agent",' '"status":"$status",' '"x_forwarded_for":"$http_x_forwarded_for"&#125;';# 启用logstash_json日志格式配置access_log /var/log/nginx/access.log logstash_json; 以下是我筛选IP的脚本👇12345678910111213141516171819202122232425262728293031323334#!/bin.bash# (每天)对用户真实ip访问量做统计，粗略统计每天大于20次的加入 nginx 黑名单# @latest_date 2018-11-2# @author Shang# 黑名单文件conf_path=/pathToBlockips/blockips.conf# nginx 日志文件log_path='/pathToAccessLog/access.log-'$(date +%Y%m%d)# nginx 命令绝对路径nginx_command=/usr/sbin/nginx# 过滤掉正常的蜘蛛访问 grep -i -v -E $&#123;spider&#125;|# spider="Google|Baidu|msnbot|FeedSky|Sogou|360|bing|yahoo"# 因为我的nginx使用yum安装的，会自动按日期切割日志，文件也不大，所以一次性全部读入日志文件cat $&#123;log_path&#125;| \# 指定','为分割符(认按空格分割)，输出第三个field，即 "client":"180.180.243.223"awk -F'[,]' '&#123;print $3&#125;' | \# 指定':'为分割符，将第二个field(即"180.180.243.223")去掉首尾'"'后输出awk -F: '&#123;print substr($2,2,length($2)-2)&#125;'| \# 计数，类SQL中的count(ip) group by ipuniq -c| \# 倒叙排列，类SQL中的order by count(ip) descsort -rn| \# 如果计数大于20次，以apeend的方式添加到ip黑名单文件中awk '&#123; if($1 &gt; 20) print "deny "$2 ";"&#125;' &gt;&gt; $&#123;conf_path&#125;# 检查nginx.conf是否正确$&#123;nginx_command&#125; -tif [ $? -eq 0 ]then # 如果返回结果正常，则重新载入nginx.conf文件 $&#123;nginx_command&#125; -s reloadfi 创建好该脚本(auto_add_nginx_blockips.sh)，，记得赋予它可执行的权限，，123456789101112# 添加 x 权限chmod u=rwx pathToAuto_add_nginx_blockips.sh# 测试下先./auto_add_nginx_blockips.sh# 如果一切正常的话，就可以添加定时任务了~# 编辑当前用户下的定时任务文件crontab -e# 然后添加定时任务，每天23:50执行脚本(顺便将正常执行之后的输出内容重定向到'无底洞'中，否则每天一封邮件，受不鸟..)50 23 * * * /bin/sh /path/to/auto_add_nginx_blockips.sh 1&gt;/dev/null# :wq后会自动保存到`/var/spool/cron/$user`中 刚开始，制定的执行计划并不是在23:50，，唉，都是因为自动切割日志，切割也就算了，关键还有压缩成.gz文件，这样脚本的复杂度就上升了，又一直搞不明白logrotate什么时候执行切割任务，，费解。所以，最初一直blockips.conf一直没反应，后来开始查/var/log/cron，发现任务也执行了👇1234567Nov 9 23:01:01 host run-parts(/etc/cron.hourly)[6988]: starting 0anacronNov 9 23:01:01 host run-parts(/etc/cron.hourly)[6997]: finished 0anacron## auto_add_nginx_blockips 脚本已执行Nov 9 23:50:01 host CROND[9407]: (root) CMD (/bin/sh /etc/nginx/conf.d/auto_add_nginx_blockips.sh)Nov 10 00:01:02 host CROND[9975]: (root) CMD (run-parts /etc/cron.hourly)Nov 10 00:01:02 host run-parts(/etc/cron.hourly)[9975]: starting 0anacron... 后来也不记得在哪看到的，如果定时任务执行的执行情况，会发送到mail，，可以去/var/spool/mail/当前用户名中查看👇123456789101112131415161718192021222324252627From root@host.localdomain Tue Nov 6 01:30:02 2018Return-Path: &lt;root@host.localdomain&gt;X-Original-To: rootDelivered-To: root@host.localdomainReceived: by host.localdomain (Postfix, from userid 0) id 0CF4D4E1C; Tue, 6 Nov 2018 01:30:02 -0500 (EST)From: "(Cron Daemon)" &lt;root@host.localdomain&gt;To: root@host.localdomainSubject: Cron &lt;root@host&gt; /bin/sh /etc/nginx/conf.d/auto_add_nginx_blockips.shContent-Type: text/plain; charset=UTF-8Auto-Submitted: auto-generatedPrecedence: bulkX-Cron-Env: &lt;XDG_SESSION_ID=567&gt;X-Cron-Env: &lt;XDG_RUNTIME_DIR=/run/user/0&gt;X-Cron-Env: &lt;LANG=en_US.UTF-8&gt;X-Cron-Env: &lt;SHELL=/bin/sh&gt;X-Cron-Env: &lt;HOME=/root&gt;X-Cron-Env: &lt;PATH=/usr/bin:/bin&gt;X-Cron-Env: &lt;LOGNAME=root&gt;X-Cron-Env: &lt;USER=root&gt;Message-Id: &lt;20181106063002.0CF4D4E1C@host.localdomain&gt;Date: Tue, 6 Nov 2018 01:30:02 -0500 (EST)# 日志文件路径出问题了，，估计是已经压缩成.gz文件了。。cat: /var/log/nginx/access.log-20181106: No such file or directorynginx: the configuration file /etc/nginx/nginx.conf syntax is oknginx: configuration file /etc/nginx/nginx.conf test is successful 如果你也遇到了类似的问题，可以尝试去mail中找找线索~ Done！]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于微信开放平台账号管理权限]]></title>
    <url>%2F2018%2F10%2F30%2FAbout_WeChat_Open_account_manage_auth%2F</url>
    <content type="text"><![CDATA[Context最近在为客户部署小程序时遇到一个问题，通过日志定位到问题是，，没有获取到小程序用户的UnionID，导致无法对小程序用户和卡包(公众号)用户形成有效的映射，bulabula…总之，翻到日志才想起来，应该通过微信提供的接口创建微信开放平台，然后绑定另一个appid即可。 想想也没啥，之前也为其他客户部署过，无非是调用两次接口：一次创建，一次绑定，，齐活~ BUT！！！但！！！这次搞的格外艰辛，微信服务器一直返回1234&#123; "errcode":40013, "errmsg":"invalid appid hint: [iAEcfA03241959]"&#125; 日狗，真心日狗！确定一定以及肯定，两个appid都没问题，，因为通过创建 开放平台帐号并绑定公众号/小程序接口，两个appid都可以创建开放平台。搞到这儿也想到一个问题，， 我想通过接口，把客户的小程序和公众号绑在同一个开放平台，，无疑，小程序肯定是授权给第三方平台的。倘若，我用小程序的appid，创建开放平台，然后将公众号的appid绑到小程序创建的开放平台上。那么问题来了，，公众号需要将开放平台账号管理权限授权给第三方平台么？？？ 为了赶紧绑定成功先，暂时将公众号的开放平台账号管理权限授权给第三方平台了。 Succeed？？我疯了，成功疯了。。最后找之前没接触过这块儿的同事从阅读文档开始，慢慢review代码。刚开始也是不行，，后来他要静静，然后闷头搞。…一会儿，，诶？我好像创建成功了？！ 稀里糊涂的 创建成功了，，然后我要求他复盘整个流程。 分别用两个appid都创建开放平台； 然后在小程序后台解绑开放平台； 通过接口将小程序的appid绑定到公众号创建的开放平台账号上。 前两步都没啥，但是第三步！我在调用接口的地址上发现点端倪，跟我之前调用时写的不一样，然后就提醒他这儿应该写公众号的appid，而不是小程序的。他突然也想到了些什么，很肯定的说，上次绑定成功的时候就是这样写的！ 终于找到问题所在，，验证，成功！！！在这儿详细复盘下，给大家伙儿做个参考，， 我将文档中将 公众号/小程序绑定到开放平台帐号下的接口封装成我们自己的接口，，伪代码如下👇1234567891011/** * 将 公众号/小程序绑定到开放平台帐号下 * @Attention 该API用于将一个尚未绑定开放平台帐号的公众号或小程序绑定至指定开放平台帐号上。二者须主体相同。 */public void bindOpen() &#123; String appid = getPara("appId"); String open_appid = getPara("open_appid"); String target_appid = getPara("target_appid"); final String BIND_OPEN = "https://api.weixin.qq.com/cgi-bin/open/bind?access_token=" + getAuthorizerAccessToken(appid); String result = HttpUtils.post(BIND_OPEN, Kv.set("appid", target_appid).set("open_appid", open_appid).toJson());&#125; 失败：我之前的绑定方式，， 通过小程序appid创建开放平台； 调用接口http://IP:Port/path/bindOpen?appId=小程序APPID&amp;open_appid=开放平台账号&amp;target_appid=公众号APPID。 👆In a word，，使用 A 创建开放平台，然后使用 A 的access_token绑定 B。报错{&quot;errcode&quot;:40013,&quot;errmsg&quot;:&quot;invalid appid hint: [iAEcfA03241959]&quot;} 成功：同事的绑定方式，， 使用公众号的appid创建开放平台账号； 调用接口http://IP:Port/path/bindOpen?appId=小程序APPID&amp;open_appid=开放平台账号&amp;target_appid=小程序APPID。 👆In a word，，使用 A 创建开放平台，然后使用 B 的access_token绑定 B。 至此，，问题解决！另外，之前的问题也迎刃而解：公众号和小程序都需要将开放平台账号管理权限授权给第三方平台。 想想也是，当初将小程序和公众号的权限授权给第三方平台时也是这样，，标的主动绑定平台，而不是平台主动绑定标的。 One more thing嗯，希望微信开放平台帐号管理完档越来月完善，，意味深长的微笑 🙂。]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>微信</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于『该公众号提供的服务出现故障，请稍后再试』]]></title>
    <url>%2F2018%2F10%2F11%2Fmistake_in_Wechat-public-account_passvely_reply_text_message%2F</url>
    <content type="text"><![CDATA[Context按照惯例先说上下文环境，，是这样，，公司需要做个功能: 对ERP用户和公司公众号用户做映射，然后向该用户推送相应角色的经营日报模板消息。 实现流程:1.通过微信接口生成带参二维码;2.用户用微信扫一扫功能扫描生成的带参二维码;3.获取二维码中的客户识别码和用户的openid;4.被动回复用户文本消息(附超链接),引导用户完成绑定过程。 Tips总的来说是没啥难度的，，过程还算顺利。有两点值得一提，， 关于授权流程最开始的时候，是想让用户扫码之后直接跳转到绑定页面，完美~然鹅，事实并非这样，，正常我们用浏览器、相机等APP扫描二维码的时候，如果二维码内容是链接的话，有的会直接访问，有的会提示是否访问这个链接。然而，在微信中扫描二维码分为两种情况，， scancode_push：扫码推事件用户点击按钮后，微信客户端将调起扫一扫工具，完成扫码操作后显示扫描结果（如果是URL，将进入URL），且会将扫码的结果传给开发者，开发者可以下发消息。 scancode_waitmsg：扫码推事件且弹出“消息接收中”提示框用户点击按钮后，微信客户端将调起扫一扫工具，完成扫码操作后，将扫码的结果传给开发者，同时收起扫一扫工具，然后弹出“消息接收中”提示框，随后可能会收到开发者下发的消息。 scancode_push倘若我们使用 scancode_push 的方式，，OK，如果二维码内容是URL的话，可以直接访问。但如此，，我们就不能使用微信生成带参二维码的接口生成二维码了，，因为，这种方式生成的二维码内容本质上是微信的链接:123456&#123; "ticket":"gQH47joAAAAAAAAAASxodHRwOi8vd2VpeGluLnFxLmNvbS9xL2taZ2Z3TVRtNzJXV1Brb3ZhYmJJAAIEZ23sUwMEmm3sUw==", "expire_seconds":60, "url":"http://weixin.qq.com/q/kZgfwMTm72WWPkovabbI"&#125; ticket: 获取的二维码ticket，凭借此ticket可以在有效时间内换取二维码。expire_seconds: 该二维码有效时间，以秒为单位。 最大不超过2592000（即30天）。url: 二维码图片解析后的地址，开发者可根据该地址自行生成需要的二维码图片 访问 URL 的链接无论如何是不能指向我们的绑定页面的。PASS！那如果用其他工具把指向绑定页面的链接做成二维码呢？如此就可以访问页面了，，但是！！我们就获取不到用户的OpenID了。。因为，亲测这种方式是用户先访问页面(页面已然渲染好了)，然后下发通知(获取到openid)，，这样，页面还是无法获取到openid。。 scancode_waitmsg看样子只能使用 scancode_waitmsg，这种方式既可以获取客户识别码，又可以获取到用户openid，，然鹅，之后只能下发消息，不能直接跳转到指定页面。在一堆汉字文本中显示链接真的好吗？！就在这时，，【花点时间】给我推送消息了(其实我更喜欢『花加』,笑哭)。同样是文本消息，但是有超链接！！ 文本消息中的链接优雅的显示方式对，，就是超链接，而不是赤果果的将网址堆在一堆汉字中。 实现起来很简单，，就是把链接放在 a 标签的 href 属性中，剩下的就是拼接字符串儿了。。 终于到正题儿了终于，，然而，为什么每次收到文本消息前总是报错？ 本以为是ngrok不稳定的原因，，但报错问题出现的太规律了，应该不是它(事实上它太稳定了，感谢开源！)。直到看到了微信开发出现“该公众号暂时无法提供服务，请稍后再试”的坑，虽然最终遇到的问题不一样，但还是收到启发了，，那就是『第三方平台授权』的问题。因为我司之前做模板小程序的时候真的有将『北京众阳软件』公众号授权给『众阳宜商信息技术有限公司』第三方平台，，做授权测试嘛。但我记得后来改为只授权公众号的『开放平台账号管理权限』，其他权限都取消了呀？！咦，，登陆公众号微信后台之后，在『功能』-&gt;『自动回复』&gt;&gt;『被关注回复』中看到有第三方平台授权管理。哦，原来还有其他第三方平台，，唤作『魔盒』什么的。其中就将公众号的『消息回复』权限。怪不得，，每次被动回复前，先向『魔盒』服务器下发消息，失败后再向公众号服务器地址下发消息。所以，，每次所谓的服务器出现故障，是魔盒的问题！ Binggo！！取消授权之后，一切都那么清净~]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>微信</tag>
        <tag>微信公众号</tag>
        <tag>被动回复用户消息</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微信第三方平台]]></title>
    <url>%2F2018%2F09%2F25%2FWeChat_third_platform%2F</url>
    <content type="text"><![CDATA[时至今日，，作为第三方平台开发的小程序已经上线有一段时间了，第一次经历整个开发流程。再回首，尝试着从宏观上梳理下『当我们谈微信第三方平台时我们在谈什么』。同样，，不涉及代码级的具体实现。 BTW，关于微信开放平台顺便聊聊微信开放平台先，，登陆微信开放平台后，进入『管理中心』Tab。我们可以看到页面中有5个二级Tab，分别是『移动应用、网站应用、公众账号、小程序、第三方平台』。OK，微信开放平台，顾名思义，，是将微信体系下的服务接入其他互联网应用的平台。这5个tab代表了目前可以接入的互联网应用类型(准确来说是4个，，第三方平台应该算业务实现类型，不算互联网应用类型。再严谨一点，应该是两种，，web应用和客户端应用，微信公众号和小程序本质上还是客户端应用。再无聊一点，，就只有一种client-server了，笑哭)。 要了解微信开放平台，我们必须深刻理解微信的UnionID机制： 获取用户基本信息(UnionID机制)在关注者与公众号产生消息交互后，公众号可获得关注者的OpenID（加密后的微信号，每个用户对每个公众号的OpenID是唯一的。对于不同公众号，同一用户的openid不同）。公众号可通过本接口来根据OpenID获取用户基本信息，包括昵称、头像、性别、所在城市、语言和关注时间。请注意，如果开发者有在多个公众号，或在公众号、移动应用之间统一用户帐号的需求，需要前往微信开放平台（open.weixin.qq.com）绑定公众号后，才可利用UnionID机制来满足上述需求。 UnionID机制说明：开发者可通过OpenID来获取用户基本信息。特别需要注意的是，如果开发者拥有多个移动应用、网站应用和公众帐号，可通过获取用户基本信息中的unionid来区分用户的唯一性，因为只要是同一个微信开放平台帐号下的移动应用、网站应用和公众帐号，用户的unionid是唯一的。换句话说，同一用户，对同一个微信开放平台下的不同应用，unionid是相同的。 – 详见获取用户基本信息(UnionID机制) 我们现在代入场景想象下： 每个微信用户对『移动应用、web应用、公众号、小程序』都有唯一OpenID；假如我有个商城卖卖零食什么的，客户遍布各个平台，，这样，让客户在Android、IOS客户端 Web网站 公众号菜单中的商城 小程序分别注册一个账号无疑是反人类的。这时候微信说了，，那你在我的微信开放平台注册个账号，然后把移动客户端 web网站 公众号 小程序什么的统统绑定(开放平台中的创建)到开放平台的这个账号主体上。那么新用户就可以在上述所有应用通过微信授权登陆了，无需注册(当然，登陆功能是实现了，，其实只是从微信那获取了几个无关痛痒的几个基本字段信息,实际操作过成功，一般都会要求用户重新绑定手机号或者邮箱什么的，以及其他用户信息。)~当然，统一微信授权登陆功能只是其中一个场景，还有微信支付接口什么的，具体看文档啦。 OK，，假设现在所有应用都可以通过微信授权登陆了。那么在获取用户额外信息之前，我们如何将所有应用的用户体系打通呢？换句话说，我们如何判断在移动客户端授权的OpenID A 与 在小程序端(或Web网站、公众号)的OpenID B是同一个现实世界中的同一个用户呢？这个时候就需要 UnionID 了。当我们把所有端的应用全部绑定在微信开放平台的同一个账号主体上，这时候就可以获取 UnionID 了，因为对同一个微信开放平台下的不同应用，unionid是相同的。即我们可以通过在不同端获取到的 UnionID 进行比对，，如果相同，则为同一个账号主体下的用户。务必注意是同一主体。 开放平台就是这样，说的有些啰嗦了都。。 微信开放平台的第三方平台之前一直称呼『第三方平台』，也总是困惑第三方平台和开放平台是什么关系。后来在开放平台的『管理中心』Tab找到了答案，，原来一直都没注意。。 第三方平台是干嘛的呢？是为了实现什么？？？最开始了解『第三方平台』是公司要做小程序，同一个小程序要给很多客户用，类似套用模板一样，，但又怕微信有审核，怕相似度太高不给审核通过什么的(事实证明我想多了。。)，然后了解到了『第三方平台』。那个时候对第三平台并不了解，只是看文档，开发接口，实现业务。知其然不知其所以然，，直到有一天小程序开发基本完成，面临上传审核的问题。这个时候，诸多疑问赶到一块儿。其中，又以这两个问题最为棘手，， 第三方平台的小程序模板怎么上传？需要审核么？？ 这个全网发布什么鬼？也要审核？？？ 小程序审核发布什么的我基本想得通，像在应用分发平台(各应用市场)上传App一样的道理，，但这个『全网发布』有点太抽象了，，领导问起来，我也有点心虚，只能硬着头皮一点点试。好在领导给力，说 大不了微信不给审核通过，我们再按着未通过理由改呗。其实也看了全网发布接入检测说明，要检查一些文档中的接口是否可用。但是总有一层很模糊的东西没想明白，，Why？后来全网发布检测，一遍过，，(因为最初是为了发布小程序，所以小程序的接口全部实现了，公众号的接口没怎么做，，因此有两项测试失败，但还是提示检测通过了。) 然后检测通过后，就是等待微信审核(大概两个工作日)。这个时候还是不太确定全网发布是什么鬼，，直到审核通过。审核通过之后，，在上图中原『全网发布』按钮所在的那个 section(就是灰背景色那部分，，不知道怎么形容。。) 中灰字部分，会变成『全网发布的审核已通过，已允许公众号来进行授权托管。』。看到这行小字的时候好像突然明白了，，原来全网发布监测是为了保证基本服务可用(因为access_token获取方式变了，其他接口绝大部分需要通过传递access_token来实现业务)。检测通过之后，就可以面向所有客户(在测试阶段只测试白名单中应用可以使用第三方平台的接口实现业务)。 其实，在第三方平台概述中，已经提到了，，只不过最开始开发的时候，不明所以，就略过了，， 四、第三方平台授权后如何帮助旗下公众平台帐号实现业务请根据本文档目录中的“代公众号实现业务”文件夹中的相关文档，来了解如何帮助旗下公众号调用接口，实现业务。也可根据本文档目录中的“代小程序实现业务”文件夹中的相关文档，来了解如何帮助旗下小程序帐号调用接口，实现业务。 关键字 -&gt; 『代公众号实现业务』。这几个字就是第三方平台的作用。当然，不光是公众号，还有小程序，，因为公众号业务比小程序实现的要早，文档维护不及时。。以公众号为例，，公众号的开发首先是面向大众的，有微信公众号后台页面，图形化页面中也可以个性化定制一些功能，比如自定义消息回复什么的。但如果深度定制的话，就需要开发者通过调用微信接口实现了，接口的令牌就是access_token，既可以通过它识别公众号身份，又可以控制请求次数 频率什么的。那第三方平台呢，为了免去为多个客户重复开发相同业务麻烦，一套接口，一个项目实现所有用户的业务(当然，需要参数来区分每个请求属于哪个公众号)。同理，小程序。 这就是第三方平台存在的价值。客户具体怎么授权第三方平台实现业务，可以授权流程技术说明，也可以参考我之前的博客微信第三方平台小程序爬坑。 另外，公众号或小程序授权给第三方平台时，可以自定义要授权的权限。潜台词就是，将相关权限授权给第三方平台后，那么相应的权限就由第三方平台实现，未授权的权限还是由自己开发开发实现。有些权限是互斥的，有些则是可以同时授权给多个平台的，，比如微信开放平台账号管理权限。其中就有提到，， 小程序只可将此权限集授权给一个第三方平台，即授权互斥。 其余的互斥权限倒没怎么注意到。]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>微信</tag>
        <tag>微信第三方平台</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[邮件报警的简单实现]]></title>
    <url>%2F2018%2F09%2F20%2Fsimple_implementation_of_email_early_warning%2F</url>
    <content type="text"><![CDATA[其实，log4j就可以实现邮件报警功能，只需要简单的配置即可。其实，不光可以发邮件，还可以通过sockets将日志文件发送到网络中的指定地址。具体查看log4j的各个appender就好啦。error级别的日志发送邮件配置👇123456789101112131415# Error级别的日志发送邮件log4j.appender.MAIL=org.apache.log4j.net.SMTPAppenderlog4j.appender.MAIL.Threshold=ERRORlog4j.appender.MAIL.BufferSize=10log4j.appender.MAIL.From=189********@163.comlog4j.appender.MAIL.SMTPHost=smtp.163.comlog4j.appender.MAIL.Subject=Error Message from *** Project# 可以发送多个用户中间用,去分隔log4j.appender.MAIL.To=destination0@qq.com,destination1@qq.com# 邮箱帐号log4j.appender.MAIL.SMTPUsername=189********@163.com# 邮箱密码log4j.appender.MAIL.SMTPPassword=authcodelog4j.appender.MAIL.layout=org.apache.log4j.PatternLayoutlog4j.appender.MAIL.layout.ConversionPattern=%-d&#123;yyyy-MM-dd HH\:mm\:ss&#125; [%c]-[%p] [%t] (%F\:%L) %X&#123;merchant_id&#125; -&gt;%m %n (PS：本篇内容无具体实现，只有实现思路) (PPS: PS 是 postscript 的缩写，笑哭) Context我司主力项目托管在阿里云服务器，有些业务需要调用客户服务器的一些接口(以HTTP请求的方式，，理论上效率并不是非常好，传说使用netty会好一些，挖坑待实现)。主力项目主要做统筹工作，类似微信开放平台中的第三方平台，然后客户授权相关权限给我司，然后我司代实现其业务逻辑，，但商品数据存放在用户服务器的数据库中，倘若将所有用户的商品数据同步到阿里云线上，一则是没必要，二则所有客户的商品数据也是不小的体量，三则也可能会有客户不希望将自己的数据代托管，，种种。所以采用的这种方式。 于是，需求出现了，，为了保证阿里云服务器中的项目与客户服务器通讯的可靠性，需保证调用出现异常时，开发人员及时知晓并fix bug。所以异常报警势在必行。 有点意思，，让我来~ 开头难于是，开始网上了解相关解决方案，，得到的大部分都服务器状态监测相关，比如zabbix、nagios(虽然不知道这俩货具体是啥。。待我用自己的服务器练练手先)。看上去比较『重』，，因为我目前只需要邮件报警的功能，，主要是我司服务器是 Windows 的。。 好吧，这条路暂时走不通了。 想想其他办法异常报警，，那肯定是捕捉到异常之后的处理，所以应该在 catch 块儿中实现相关报警代码就行。按照java 使用JavaMail 做异常邮件报警 ，支持163邮箱、outlook邮箱中代码实现即可。后来发现项目框架中有相关的 MailUtil 工具类，倒是省事儿。虽然上面博客中的代码并未复用，但至少让我看到了成功的希望。然而，，实现RuntimeException，然后捕捉到异常后抛出新实现的异常类，，真的有必要么??我在捕捉到异常之后，为什么不直接发送邮件，反而继续向上层抛异常？上层还有未捕获异常的处理？？至少我的项目中没有；另外，，如果在每个方法中去try{}catch(e){}，需要改动每个相关接口代码，太不优雅了。。 有没有一种一劳永逸的方法，，一处设置，处处生效？？我首先想到的是过滤器，，12345678try&#123; doFilter();&#125;catch(Exception e)&#123; e.printStackTrace(); // 邮件报警 // 短信报警 // bulabula&#125; 但实现之后，发现异常并没有被抛出到过滤器中，，直接被其他逻辑catch捕捉处理了，，额。那就在 Route(或Controller) 级别的拦截器中处理，，12345try&#123; invocation.invoke();&#125;catch(Exception e)&#123; // 报警bulabula&#125; 完美！！然鹅，，业务中调用客户服务器中的接口需返回值，丫的！！ 另外，所有与客户服务器交互的方法全被写在了 API.java 中，，其他业务中直接静态调用相应的方法即可。所以，用 Controller 级别的拦截器还不行。。 权衡之下，最终以 action 为单位，自定义 catch 逻辑，返回相应的错误代码调用封装好的发送报警邮件的方法。同理，短信报警及其他报警形式。具体实现其实没什么难的，这里梳理下思路。 参考链接：java 使用JavaMail 做异常邮件报警 ，支持163邮箱、outlook邮箱]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>邮件预警</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理想的生活]]></title>
    <url>%2F2018%2F07%2F27%2Fideal_life%2F</url>
    <content type="text"><![CDATA[今天在小龙女的微博中发现这样一段转发的话，， 关于亦舒的『理想的生活』我是完全同意的，，毕竟理想的生活嘛，也是向往的生活。只是看到小猫咪的评论，我能理解 TA 为什么做出这样的评论，但不能完全认同。点开评论想稍微分(反)享(驳)下自己的看法。但写到一半，意识到一个很严重问题。。分(反)享(驳)的前半截是这样的👇 我们实在没有办法让孩子选择自己的出身，但是假如可以选择话，， 我后边还想写一些体验世界，体验未知之类的话(🤦‍♀️)，但是写到但是的时候，发现这个『假如』实在有太多东西可以讲，脑洞大开，，放弃评论了，三言两语实在无法准确表达出自己想表述的东西。买完吃的，赶紧回到公司试着把自己想到的东西记下来，，就像现在。 如果我们可以选择自己的出身(生)首先，，如果我们可以选择自己的出身(生)，那么这意味着，在我们出生之前，我们的意识已然存在了。那么问题来了，这个先验的不依靠人间(目前想不到更好词..)存在的意识是怎样产生的？？这算不算某种程度上的 意识不灭论 ？？？肉身会枯萎 化作泥土，意识却永远存在某个独立的空间(这个空间内有没有时间的概念?时间对意识会产生怎样的影响？？)。这些意识会不会『意识』到其他意识的存在，如果可以『意识』到，那这些意识存在的空间内会不会也有类似人类的『社会』的概念，他们可以互相交流，做信息交换。他们怎么做信息交换？像三体人一样，靠思维直接对话？？我甚至想象不出『思维』对『意识』来说是怎样一种存在… 其次，，如果可以选择，那么肯定应该有某种机制高于他们做出的选择，类似人类社会中的『法律』、『规范』、『道德』之类的存在，我们姑且叫做『规约』。『规约』之所以存在，是为了解决意识之间争夺『出身选择』的解决机制。且先不考虑『规约』是怎样产生的，，意识是怎样做出『出身选择』的？靠某种更高力量的存在分配(类似于之前的高校负责就业分配)，还是靠意识个体的能力去抢夺资源(出身选择)？如果是分配的话，，如何保证『意识社会』的公平正义？？如果是靠个体能力抢夺资源的话，如果解决抢夺过程中存在的选择权争议？靠类似人类社会法庭一样的存在？会不会太低效。。那像程序中的锁问题？新的出身选择出现，某个意识抢到读取这个选择权的权利，，然后了解这个选择，然后做出选择要不要做这对夫妻孩子，，这期间其他意识个体是不能重复争夺这个出身选择的。等之前抢到的那个意识做出决定，，如果选择『投胎』(怪怪的..)，那么这个选择消失。如果放弃这个出身选择，那么其他意识才可以再去争夺这个选择权的读取权利。 再其次，，如果有的意识个体能力很弱，总是抢不到『出身选择』，TA会不会被『规约』淘汰，强制『报废』？如果有的意识能力并不弱，只是一直不能做出投胎的选择，，那TA会不会『变老』？？TA的能力会不会随做出选择次数的增长而衰减？？？如果意识在意识的世界不会消亡，那么意识世界会不会像人类一样面临『人口问题』(『资源问题』)，不会也有灭霸吧？！！ OK，，别的都特么不管了。如果意识做出投胎的选择之后，来到『人间』，那 TA 能为自己的选择负责么？TA 会不会后悔做出当初的选择？父母还有必要对这个『意识』负责么？哎呦，当初是你做出的选择要做我们的孩子，我们又没有逼你诶。。怎么又有点像自动驾驶发生事故时的伦理问题。。。日，，又想到一个严重的问题！自杀会不会变成一种权利(从某种程度上讲，一直都是)？每当有意识不满现状的时候，就会做出自杀的选择 来达到重新选择出身的目的。那这样，，『人间』会不会变成『地狱』。。那频繁『自杀』的意识会不会被拉黑，某段时间内禁止投胎(🤦‍♀️)？？丫丫，，午休的时候又想到一个严重的后果！！这个世界会因此变得无趣，严重破坏了人类基因库的多样性！！试想一下，全世界只剩下几大家族以及他们的亲戚、朋友。。倒是没穷人了，大家都那么有钱，对我们而言，壹佰亿和一亿又有什么区别呢，反正一个人能同时占用的资源也就那么多。。 诶？？意识投胎之前应该会忘记自己『意识社会』中的生活吧？？？诶，，那这样，现在再说自己当初没得选择好像不太合理诶。。。 关于无知之幕无知之幕最早是在迈克尔∙桑德尔的『公正-该如何做是好』(中信出版社)看到的一个概念。它出现在&lt;设想完美的契约&gt;中，， 让我们来想象一种在那些拥有平等的，而非不平等的权利和知识的人们之间所达成的协议：他们处于同样的境况，而并非不同的境况。同时也设想一下，这份契约的对象并不是管道铺设或其他的普通交易，而是那些治理我们的生活的、分配我们作为公民所具有的权利与义务的各种原则。在这样的各方中所达成的这样一个契约，就不会有压迫、欺骗或其他不公平的缺点。它的各项条款由于同意本身，就必然是公正的，而无论它们是什么。…无知之幕通过保证没有人知道他在社会中的地位，他的优点或缺点，他的价值或目的，从而保证了没有人能够(即使是无意的)利用一种更好的交易地位。 如此，，我们不能选择自己的出身(生)，这不就是『无知之幕』么？ 记得在之前的某一个冬天，和一个很要好的朋友去龙泉寺，半山腰休息的时候，讨论类似的话题。朋友提到『我觉的人这一生是不完整的，我们没办法决定自己的出生，也没办法清醒的经历自己的死亡。』。深以为然，掐头去尾，我们只能清醒的体验活着的这段时间。出生之前，包括出生这个过程，以及出生后的很长一段时间，我们并不能对外界的刺激做出合理的反应(大概就是『无知』『未开化』的那段时间，这里不知道怎么表述了..)，死亡亦是如此。但如果我们可以选择出身的话，那一切都不一样了，我们拥有了完整的人生，人生所有的阶段都有意识存在，甚至还有另外一个世界的体验，虽然我们可能会不记得，，这里有bug。。人类为什么要有刚出生那段时间的无知、未开化，记忆和认知能力为什么不可以遗传？！？这里也可以好好开下脑洞，， 以前也会因为自己不能选择出身而耿耿于怀，，请不要误会，我非常爱我的爸妈，我只是想不明白为什么不可以，而不是可以选择出身的话，我可能会拥有更好的人生。但是经过这个『思维游戏』后，我好像明白了，也庆幸无知之幕的存在。 最后读过的书的确会忘记，但冥冥中还是对会改变一些什么，，像『无知之幕』，若非读过『公正』，可能还不知道什么时候会意识到这样一种存在。书是13年寒假买的，在重庆待的那一个月，第一次在亚马逊买书。想来那时候就对这种东西感兴趣，书竟然也读下去了一半，冰糕棍儿还夹在203页🤦‍♀️。那时候还没接触哲学，书中的笔记也很幼稚，，想来现在该重读了。温故知新，，以前不是很明白这句话，书上的硬知识点就那些，跟什么时候看有什么关系。。现在想来，温故知新确是有道理的，，很多书读不懂，千万不要硬啃，放一放，再经历一些事情，回过头重读，总能读到新的感受。总之呢，读的书必须跟自己的阅历相匹配，每个人在书中，在电影中读到的大抵还是自己的故事。 晚安~]]></content>
      <tags>
        <tag>出身</tag>
        <tag>无知之幕</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于微信卡券预览接口]]></title>
    <url>%2F2018%2F07%2F13%2FWeChat-card-coupons-preview-interface-%2F</url>
    <content type="text"><![CDATA[最近在做微信卡券接口相关的功能，，妈耶，相当于复制一个微信公众平台的卡券模块！光字段就能反4屏，简直就是惩罚性编程，搞的我很焦虑。。花了两周的时间，终于仿照微信原版在自己后台完成了创建卡券的功能，，当在微信公众平台看到新创建的折扣券，长舒一口气，终于看见了正反馈！！接下来，，得预览下吧？不能直接投放呀。OK，预览接口，，今天的主角儿。要知道，卡券预览接口做的很顺利的话，也就没这篇文章了。。 OK，进入正题儿。 创建完卡券之后，我们按照逻辑，可以应该继续往下进行，在文档中可以找到管理卡券的模块。直接在这个页面搜索关键字『预览接口』，，即👇 ###4.6 预览接口支持开发者调用该接口下发卡券。订阅号不可用，服务号认证后可用。详情见 预览接口 按理儿说，这就成了呀，，照预览接口做就得了呗。但是！！！点开预览接口，我们看到的是啥？丫丫，空的，空页面，啥玩意儿没有？！🙃(问候一下微信写文档的同学) 冷静一下，，既然做了链接，这说明极有可能在别的模块中，否则就没必要做链接了对吧；另外，预览接口，那得把消息推送到手机上呀，事件推送，消息管理？~那找吧，，loding.. 诶！还真在消息管理的群发接口和原创校验模块中给找着了！ 预览接口【订阅号与服务号认证后均可用】 文档有了，nèng! 卡券：123456789&#123;"touser": "OPENID", "wxcard": &#123; "card_id": "123dsdajkasd231jhksad", "card_ext": "&#123;"code": "","openid": "","timestamp": "1402057159","signature": "017bb17407c8e0058a66d72dcc61632b70f511ad"&#125;" &#125;, "msgtype": "wxcard"&#125;// 请注意，上述JSON数据中的touser字段都可以改为towxname，这样就可以针对微信号进行预览（而非openID），towxname和touser同时赋值时，以towxname优先。 参数说明就不放了，文档中有说明，，但是这个card_ext什么鬼？！！没听说过呀都，忒眼生。。另外，这个字段里，别的参数还好说。但，，signature是怎么计算出来的？这是关键呀。得，这真难倒我了，而且这页面中只有这一个地方出现了这一属性。搁哪儿找呀，，百度先行，关键字[微信 卡券 card_ext] 顺藤摸瓜，找到了微信网页开发模块中的微信JS-SDK说明文档看上去怎么那么不靠谱？消息推送跟网页开发有嘛关系？！！但在这个页面中还真就找到了card_ext字段，，👇 附录4-卡券扩展字段及签名生成算法卡券 api_ticket卡券扩展字段cardExt说明签名说明 剩下的一切按文档来就成了，，需要注意的是👇 ######签名说明1.将 api_ticket、timestamp、card_id、code、openid、nonce_str的value值进行字符串的字典序排序。 这个字典序排序，第一次看见还真有点懵，，但好在通过搜索引擎可以解决~我参考了这篇博客，，TreeMap按照value进行排序实现代码如下👇123456789101112131415161718192021222324252627Map&lt;String, String&gt; wxMap = new TreeMap&lt;String, String&gt;();//参数封装wxMap.put("api_ticket", wxJsApiTicket);wxMap.put("timestamp", wxTimestamp);wxMap.put("card_id", cardId);wxMap.put("code", "");// 视实际情况wxMap.put("openid", "");// 视实际情况wxMap.put("noncestr", wxNoncestr);// 将 api_ticket、timestamp、card_id、code、openid、nonce_str的value值进行字符串的字典序排序。List&lt;Entry&lt;String, String&gt;&gt; list = new ArrayList&lt;Entry&lt;String, String&gt;&gt;(wxMap.entrySet()); Collections.sort(list,new Comparator&lt;Map.Entry&lt;String,String&gt;&gt;() &#123; //升序排序 public int compare(Entry&lt;String, String&gt; o1, Entry&lt;String, String&gt; o2) &#123; return o1.getValue().compareTo(o2.getValue()); &#125; &#125;);// 将排序后的值依次取出，并拼接为字符串。StringBuilder wxBaseString = new StringBuilder();for (Entry&lt;String, String&gt; param : list) &#123; wxBaseString.append(param.getValue());&#125;log.info(wxBaseString.toString());// 加密获取signatureString wxSignature = HashKit.sha1(wxBaseString.toString()); 这剩下的就是调用微信卡券预览接口了，自己来吧~ PS: 这昨儿个看了姜文儿的『邪不压正』，，本篇分享的风格就这样了，多包涵。哭笑 参考链接： 群发接口 https://mp.weixin.qq.com/wiki?t=resource/res_main&amp;id=mp1481187827_i0l21 微信JS-SDK说明文档 https://mp.weixin.qq.com/wiki?t=resource/res_main&amp;id=mp1421141115 字典序排序 http://www.cnblogs.com/Berryxiong/p/6240514.html debug https://mp.weixin.qq.com/debug/cgi-bin/sandbox?t=cardsign]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>微信</tag>
        <tag>卡券</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对马斯洛需要层次理论的简单抽象]]></title>
    <url>%2F2018%2F07%2F12%2FAbstraction_Maslow's-hierarchy-of-needs%2F</url>
    <content type="text"><![CDATA[中午十二点，太饿了，，心里又总想着前阵子读到的一句话。噢？突然觉得马斯洛的需求层次理论刚好可以抽象一下~ ↑ ++++++++++++++++++++++++++++++++↑ +++++++++++++&nbsp;++++++++++++++&nbsp;&nbsp;++++↑ +++++++++++&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;++++++++++++&nbsp;&nbsp;&nbsp;&nbsp;++++↑ +++++++++&nbsp;自我实现&nbsp;+++++++++→人与内心++++↑ +++++++&nbsp;&nbsp;&nbsp;尊重需要&nbsp;&nbsp;&nbsp;++++++++&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+++++↑ +++++&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;归属与爱&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+++++→人与社会&nbsp;&nbsp;&nbsp;++++++↑ +++&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;安全需要&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;++++&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;++++++↑ +&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;生理需要&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+→人与物质&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+++++++↑ ++++++++++++++++++++++++++++++++++++++++++++++++++ 简单来说，，『生理需要』和『安全需要』是人与物质的关系，『归属与爱的需要』和『尊重需要』是人与人或人与社会的关系，『自我实现』是人与内心或人与自己关系。 毫无违和感！年龄越大，越发的喜欢跟年长的人接触，，好像突然就知道原因了。]]></content>
      <categories>
        <category>呓语</category>
      </categories>
      <tags>
        <tag>马斯洛需求层次理论</tag>
        <tag>抽象</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[真随机]]></title>
    <url>%2F2018%2F07%2F08%2Ftruly_random%2F</url>
    <content type="text"><![CDATA[是这样么？@(2018-06-28 09:30)]]></content>
      <categories>
        <category>呓语</category>
      </categories>
      <tags>
        <tag>随机</tag>
        <tag>自由意志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于局部性原理]]></title>
    <url>%2F2018%2F06%2F25%2Fbranch_prediction%2F</url>
    <content type="text"><![CDATA[因为之前一直在关注『码农翻身』公众号，作者以很基础的文字构建关于计算机关于编程的小故事，由浅入深，，其中的知识点可以自己延伸阅读，还是非常不错的，很适合入门~后来，作者出书了，支持了一波，，毕竟纸质书翻起来比较方便。OK，进入正题，，在『CPU阿甘』中有提到『局部性原理』，，有必要延伸阅读下。网上找到了Stack Overflow中一篇文章-Why is it faster to process a sorted array than an unsorted array?-本文是对这篇文章的简单翻译，四级水平，还请多包涵 哈哈。 为什么排序后的数组比乱序的数组执行起来要快？这是一段看起来非常奇怪的C++代码，因为某些原因，将数组排序之后奇迹般的将运行速度提高了将近六倍。 1234567891011121314151617181920212223242526272829303132#include &lt;algorithm&gt;#include &lt;ctime&gt;#include &lt;iostream&gt;int main()&#123; // 生成数据(数组) const unsigned arraySize = 32768; int data[arraySize]; for (unsigned c = 0; c &lt; arraySize; ++c) data[c] = std::rand() % 256; // !!! 因为这一行代码，下边的循环运行的更快了 std::sort(data, data + arraySize); // 测试 clock_t start = clock(); long long sum = 0; for (unsigned i = 0; i &lt; 100000; ++i)&#123; // Primary loop for (unsigned c = 0; c &lt; arraySize; ++c)&#123; if (data[c] &gt;= 128) sum += data[c]; &#125; &#125; double elapsedTime = static_cast&lt;double&gt;(clock() - start) / CLOCKS_PER_SEC; std::cout &lt;&lt; elapsedTime &lt;&lt; std::endl; std::cout &lt;&lt; "sum = " &lt;&lt; sum &lt;&lt; std::endl;&#125; 如果没有std::sort(data, data + arraySize);(即数组数据大小乱序), 代码运行11.54秒。 数组元素排序之后，运行只用了1.93秒。 起初，我以为这种现象与编程语言或者编译器什么的有关系，，所以，我把代码移植到Java中试了一下👇 1234567891011121314151617181920212223242526272829303132import java.util.Arrays;import java.util.Random;public class Main&#123; public static void main(String[] args)&#123; // Generate data int arraySize = 32768; int data[] = new int[arraySize]; Random rnd = new Random(0); for (int c = 0; c &lt; arraySize; ++c) data[c] = rnd.nextInt() % 256; // !!! With this, the next loop runs faster Arrays.sort(data); // Test long start = System.nanoTime(); long sum = 0; for (int i = 0; i &lt; 100000; ++i)&#123; // Primary loop for (int c = 0; c &lt; arraySize; ++c)&#123; if (data[c] &gt;= 128) sum += data[c]; &#125; &#125; System.out.println((System.nanoTime() - start) / 1000000000.0); System.out.println("sum = " + sum); &#125;&#125; 运行结果有点类似，但没有像在C++中差很多。 我刚开始想到的是把数组排序之后，将数组载入到内存中了，，转念一想，这忒蠢了，数组明明是刚生成的(一直在内存中)。 到底发生了神马？ 为什么排序后的数组比乱序时处理速度快很多？ 代码中求和项是相对独立的，应该跟数组数据没什么关系。。(存疑) 高票回答你可能是分支预测失败的受害者。。 那么什么是分支预测呢？？ 想象铁路的岔口，，👇@(Image by Mecanismo, via Wikimedia Commons. Used under the CC-By-SA 3.0 license.) 现在为了方便讨论，假想我们回到了19世纪，那时候还无法进行远距离无线通讯。 你作为这个岔路口的操作员，听到一辆货车正在驶来，但又完全不知道它想去哪条分支路线。这时，你示意货车停下来，问他你想去哪个方向，然后将开关设置为正确的位置。 火车很笨重，因为惯性的原因，它们在启动和停下来的时候通常要花很长时间。 有没有更好的办法嗫？(办法是)猜测它会去往哪个方向！ 如果你猜对了，它继续行驶~ 如果你猜错了，火车司机会向你大喊大叫，让你重置开关，，然后TA重新启动，驶向另一方向。 如果你每次都猜对，火车就永远不需要停下来~如果你总是都猜错，火车会花费很长时间停下来，后退，重新启动。。 把它看做一个 if 代码块：在芯片级别，这是一个分支指令👇作为一个处理器，你看到一个分支结构，，完全不知道它将要怎么运行？你怎么做？等判断条件先运行结束，然后根据正确的结果选择合适的分支运行。 现代处理器(通常)很复杂，有很长的流水线级数。所以，会像火车一样话很长的时间『启动』和『刹车』。 有没有更好的办法嗫？(答案是)猜测程序会运行哪个分支的代码。 如果猜对了，程序继续执行~ 如果猜错了，需要清空流水线(的所有任务)，回滚到分支结构开始的位置。然后重新启动执行另一个分支。 如果每次都猜对，你永远不需要被迫停下~如果总是猜错，你会花费很长时间减速，回滚，重启。。 这就是分支预测，，我承认这不是最好的比喻，因为火车可以用旗子作为指示方向的信号。但是在计算机中，处理器直到最后一刻才知道最终会运行哪个分支(的代码)。 那么，你如何策略性地猜测，以尽量减少火车必须后退才能才能驶向正确的方向的次数？观察过去的执行历史！如果99%的情况，火车都向驶向左侧，那么你(肯定)猜测(下一次)火车(同样)驶向左侧。如果它(驶向左侧或者右侧的情况)交替出现，那么你(根据情况)交替改变你的猜测。如果每三次就会驶向某一特定的方向，那么你也会据此作出合理的猜测.. 换句话说，你试图抽象出一个模型并据此作出猜测。这或多或少是分支预测器的工作原理。 大多数应用程序具有良好表现(well-behaved 具体指什么??)的分支。所以现代分支预测器通常会达到大于90％的命中率。但是当面对不可识别的模型时，我们无法预测将要执行的分支，这时分支预测器实际上是毫无用处的。 正如上边我们猜测的那样，罪魁祸首是这个if代码块👇 12if (data[c] &gt;= 128) sum += data[c]; 我们可以注意到，数据均匀分布在0和255之间。数组中的所有元素排序之后，大致前半部分元素迭代时不会进入if语句。剩下后半部分的元素，它们将全部进入if语句。 分支连续多次走向相同的方向时，这对于分支预测器非常友好。即使是简单的饱和计数器也能正确预测分支，除了饱和后改变方向后的少数迭代。 快速预览： 1234567T = branch takenN = branch not takendata[] = 0, 1, 2, 3, 4, ... 126, 127, 128, 129, 130, ... 250, 251, 252, ...branch = N N N N N ... N N T T T ... T T T ... = NNNNNNNNNNNN ... NNNNNNNTTTTTTTTT ... TTTTTTTTTT (easy to predict) 但是，当数据是完全随机的时，分支预测器将无法发挥作用，因为它无法预测随机数据。因此，可能会有大约50％的预测失误。(比随机乱猜好不到哪而去..)。 1234data[] = 226, 185, 125, 158, 198, 144, 217, 79, 202, 118, 14, 150, 177, 182, 133, ...branch = T, T, N, T, T, T, T, N, T, N, N, T, T, T, N ... = TTNTTTTNTNNTTTN ... (completely random - hard to predict) 那么，我们能做些什么呢？ 如果编译器无法将分支优化为条件转移(conditional move???)，那么如果您愿意为了提高性能而牺牲可读性，则可以尝试一些风骚的操作。👇 1234567if (data[c] &gt;= 128) sum += data[c]; // 将上面👆的代码修改为下面👇的，，int t = (data[c] - 128) &gt;&gt; 31;sum += ~t &amp; data[c]; 这样，用一些位操作代替分支(判断)。(PS:需要注意的是，这种风骚的操作并不完全等同于原始的if语句。但在这个例子中，它对数据的所有输入值都有效[])。 基于: Core i7 920 @ 3.5 GHz C++ - Visual Studio 2010 - x64 Release 👇 1234567891011// Branch - Randomseconds = 11.777// Branch - Sortedseconds = 2.352// Branchless - Randomseconds = 2.564// Branchless - Sortedseconds = 2.587 Java - Netbeans 7.1.1 JDK 7 - x64 1234567891011// Branch - Randomseconds = 10.93293813// Branch - Sortedseconds = 5.643797077// Branchless - Randomseconds = 3.113581453// Branchless - Sortedseconds = 3.186068823 分支：排序后的数组与乱序的数组之间(执行速度)有巨大的差异。 风骚の操作：排序后的数组与乱序的数组之间(执行速度)无明显差异。 在C++中，排序后的数组用风骚的位操作甚至比分支预测有些慢。。 一般情况下应该避免 data-dependent branching in critical loops. (such as in this example)]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>计算机系统</tag>
        <tag>branch prediction</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微信第三方平台小程序爬坑]]></title>
    <url>%2F2018%2F06%2F06%2FWeChat-third-party-platform-mina%2F</url>
    <content type="text"><![CDATA[紧接上篇文章-关于获取微信第三方平台的 component_verify_ticket 和 component_access_token-之后，， 我以为…在上篇中，获取 component_access_token 之后，看看下边的步骤好像跟自己没什么太大关系了，直接跳过『授权流程技术说明』之后的步骤，，开始准备『代小程序实现业务』中的微信登陆，，没想到步子迈的有点大，终究还是扯着 * 了。。 顺着这个思路走，，在做 微信登陆 时，对于开发者来讲，也没有什么太大违和感呀，，👇 下边的参数也都有了呀，， 参数 是否必须 说明 appid 是 小程序的AppID js_code 是 登录时获取的 code grant_type 是 填authorization_code component_appid 是 第三方平台appid component_access_token 是 第三方平台的 component_access_token 然而，在请求接口的时候，报如下错误👇1&#123;"errcode":40001,"errmsg":"invalid credential, access_token is invalid or not latest, hints: [ req_id: MNHl9a0063th42 ]"&#125; 这时候首先是很费解，，为什么会报不合法的调用凭证错误？access_token 有问题，， component_access_token 有问题？不能啊，刚刚获取的，还热乎呢。。 但是参数中只传了这一个包含 access_token 的参数呀。。 为了验证 component_access_token 是否有效，紧接着去以步骤 3 的方法获取预授权码 pre_auth_code了，，事实证明，完全没问题。这就有点蹊跷了，， 去小程序官方社区找相关帖子，比如微信开放平台 用户微信登录失败 invalid credential，，下边有官方回复是 👇 应该是login换取的code失效或者已经被消费了，导致获取到了错误的access_token，请检查后端login的逻辑的确有可能，，因为 调用接口wx.login() 获取临时登录凭证（code）是有时效限制的，目前有效期为5分钟，，而且测试之后发现，Code 是一次性的！！！就像发帖的哥们儿回复的那样，，Code 复用之后，的确会报 41063 的错误。 至此，，哥们儿彻底在这儿趴窝了。。。带着”BUG”下班了，不好。 乖乖看文档吧根据以往的经验，， 网上找不到类似的问题，，乖乖看文档 找到了类似的问题，根据别人提供的解决方案，还是解决不了，，乖乖看日志，检查上下文 实在没辙了，，抄一遍文档，从头儿开始！ 我决定乖乖看文档，，从『代小程序实现业务』中的开发简介开始。 第一步：绑定开发小程序Done！ 第二步：小程序模版的开发和上传Done！ 第三步：添加到小程序模版库，获得模版IDDone！ 第四步：调用接口，为旗下授权的小程序部署代码？？？ 可能我错过了些什么。。。赶紧去看『代码管理』 1、为授权的小程序帐号上传小程序代码调用接口所需参数中的 access_token，需要使用第三方平台获取到的该小程序授权的authorizer_access_token，，到这儿，明了了。还是需要按『授权流程技术说明』的流程来。。 还得按流程来步骤1：第三方平台方获取预授权码（pre_auth_code）这个真没啥说的，测试一遍过，，这儿要出啥问题，极有可能是 component_access_token 的问题。 步骤2：引入用户进入授权页这一步之前也看过，，当时想到的场景只有公众号的，觉得这个跟小程序没啥关系呀。总不能让用户在小程序中以这种方式进行所谓的授权的？！ (PS:事实证明，的确不会让用户在小程序中以这种方式授权，naive!!在这儿，我对整个第三方平台的作用，以及授权流程还不清晰，，以为像 oauth 2.0 一样，naive!!! 这里的授权其实是公众号或者小程序授权给第三方平台，就像第三方平台文档中菜单说的那样『代公众号实现业务』、『代小程序实现业务』。在这里，还没有面向终端用户，面向的是使用第三方平台的客户，客户的公众号或者小程序面向终端用户。) 看这个接口的时候有一丢丢费解，，梳理之后大概是这样 👇12345获取预授权码（pre_auth_code）=&gt; 引导用户进入一静态页面，页面中有一链接或一按钮，用户点击=&gt; 进入微信授权页=&gt; 用户确认要授予第三方平台的权限，决定是否授权=&gt; End 大概解释下，，我觉得，获取预授权码（pre_auth_code）和引导用户进入授权页这两个关系很紧密，某种程度上是一个步骤，，因为预授权码只能用在引导用户跳转向授权页面的链接中。所以，，我直接把这两步合并了：获取预授权码（pre_auth_code），返回引导授权页面。 步骤3：用户确认并同意登录授权给第三方平台方EASY~ 步骤4：授权后回调URI，得到授权码（authorization_code）和过期时间授权流程完成后，授权页会自动跳转进入回调URI，并在URL参数中返回授权码和过期时间(redirect_url?auth_code=xxx&amp;expires_in=600)^1 在第二步中，有个参数redirect_uri，这个参数其实是以接口的形式指向了一个我们自身定义的回调函数，，在这个接口中我们可以通过 request.getParameter()获取到auth_code和expires_in两个参数。 步骤5：利用授权码调用公众号或小程序的相关API剩下的就简单了，， 使用授权码换取公众号或小程序的接口调用凭据和授权信息接口调用请求说明 http请求方式: POST（请使用https协议）https://api.weixin.qq.com/cgi-bin/component/api_query_auth?component_access_token=xxxx POST数据示例: 1234&#123; "component_appid":"appid_value", "authorization_code": "auth_code_value"&#125; 在返回结果中，在 authorization_info 对象中可以获取到 authorizer_appid、authorizer_access_token、authorizer_refresh_token三个重要参数。但是，有一点还不算太确定，，authorizer_access_token和authorizer_refresh_token是否与authorizer_appid相关。换句话说，，authorizer_appid不同，其他两个值是不是也不一样？？根据官方对authorizer_refresh_token的解释👇 接口调用凭据刷新令牌（在授权的公众号具备API权限时，才有此返回值），刷新令牌主要用于第三方平台获取和刷新已授权用户的 access_token，只会在授权时刻提供，请妥善保存。 一旦丢失，只能让用户重新授权，才能再次拿到新的刷新令牌。 我觉得应该是不一样的。总不能有新用户授权给第三方之后，之前已经授权的用户的刷新令牌就失效了吧。。后期可以分析下日志确定下这个问题。 到这儿，，我们就可以回到最初为授权的小程序帐号上传小程序代码的步骤了，现在上传应该就不会有问题了~上传成功后，『微信登陆』也是一遍过~ 完美！！！ 公众号授权，只需要运营者权限即可；但小程序授权，必须得是管理员！！！另外，，如果在没有授权的情况下，去调用相应公众号或小程序的接口时会得到{&quot;errcode&quot;:48001,&quot;errmsg&quot;:&quot;api unauthorized},或{&quot;errcode&quot;:61003,&quot;errmsg&quot;:&quot;component is not authorized by this account}。此时应该先检查是否授权，可以利用公众号第三方平台的权限说明接口。如果，已经公众号或者小程序授权给第三方，，此时应该检查授权时的权限；可以重新走一遍授权流程，在授权页检查权限集；如果是小程序的话，可以去小程序后台 =&gt; 设置 =&gt; 第三方服务查看。]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>微信</tag>
        <tag>小程序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于获取微信第三方平台的 component_verify_ticket 和 component_access_token]]></title>
    <url>%2F2018%2F05%2F31%2Fabout-wechat-authorize3rd-component_verify_ticket%26component_access_token%2F</url>
    <content type="text"><![CDATA[独立的小程序已经满足不了我司的需求了，继而准备做微信第三方平台，，今天主要想总结下获取微信授权第三方平台流程中遇到的一些问题，，主要是Java代码(用php开发的朋友可以 Command + W 了..)。 推送 component_verify_ticket 协议这一部分，官方文档真心惜墨。。对首次进行开发第三方授权开发的程序员来说真心不友好，在此提出批评(白天已经骂过无数次娘了🙂)！ 关于 POST 数据示例123456&lt;xml&gt; &lt;AppId&gt;&lt;/AppId&gt; &lt;CreateTime&gt;&lt;/CreateTime&gt; &lt;InfoType&gt;&lt;/InfoType&gt; &lt;ComponentVerifyTicket&gt;&lt;/ComponentVerifyTicket&gt;&lt;/xml&gt; 👆上边的 XML 其实是解密之后的格式。。推送过来时候我们获取到的数据是经过加密的，，像这样👇 1234&lt;xml&gt; &lt;AppId&gt;&lt;![CDATA[wx5a062835463d1c61]]&gt;&lt;/AppId&gt; &lt;Encrypt&gt;&lt;![CDATA[3KAGFTaD32rFYsXMmjK/6Hk7nfJzrgIqQs4tqlFA5ORsuMhFvMM9P0cUKEoW9v+2oJztVFRI/OV09szzN7QqqxgapTGLYcyKnbViqs+uSnVkwc5YBM4YkAKGU2Yyp89/6tXU0FloSfUvM8bHZteed44Wo3B3diuhA3JIOK/viBfdfgODTZCe/q/JFt7yYc2Cr3ojtmR1n2M+PdQTfs3bf7tLlR4yURD5kXYrJkZPK7giNzE+uEgn52SUAAhLnAc68hWm0rnPhvPgVARSqL3sHK5xtxihoXcX0h15j8Al3KbZ3IqIdM/SIJrB0mnDx8hOnoI8UaBmChVWS8iz/Ygp/lr8mT37WK0bVeFKm2PkNBG91/icsxOacEJCuXdj/yD+rthlB2OQbmbdFPXw/8QPCNjHdj2RmEL78flwrRQeoNOHYvmMBtoU9jm0WAix6db8siyCA2CNFsC/QxD84p0N/Q==]]&gt;&lt;/Encrypt&gt;&lt;/xml&gt; 那么加密后的数据是怎样获取到的呢？？最开始的时候百思不得其解，要崩溃，都做噩梦了。。其实在后边的消息加解密接入指引提到了一些，，总之呢，我们可以通过request.getParameter(paraName)获取到四个参数，分别是👇 时间戳 timestamp 随机数 nonce 加密类型 encrypt_type(值为aes) 消息体签名 msg_signature(用于验证消息体的正确性) 这四个参数呢主要用来解密 经过加密的 xml 数据，即所谓的 postdata。 // 说到这儿，，不得不提下官方给出的加解密示例代码。其实，这5种语言的示例代码的场景是用来加解密微信公众号与用户互动的消息的，所以xml结构中有ToUserName标签。而实际上在本文的场景中，是不存在ToUserName标签的，取而代之的是AppId标签，，这一点，在官方文档中的消息加解密接入指引也有提到，只不过比较隐晦。。👇 公众号第三方平台可能会接收到两种类型的消息： 用户发送给公众号的消息（由公众号第三方平台代收）。此时，消息XML体中，ToUserName（即接收者）为公众号的原始 ID（可通过《接口说明》中的获取授权方信息接口来获得）。 微信服务器发送给服务自身的事件推送（如取消授权通知，Ticket 推送等）。此时，消息XML体中没有 ToUserName 字段，而是 AppId 字段，即公众号服务的 AppId。这种系统事件推送通知（现在包括推送 component_verify_ticket 协议和推送取消授权通知），服务开发者收到后也需进行解密，接收到后只需直接返回字符串“success”。 (PS: 这个 postdata 在官方给的解密加密示例代码中(Java版)的体现即 replyMsg) OK, 那么问题来了 postdata 又是怎么获取的嘞？？？文档中好像并没有提到(难道是我没看到？！？) 😤，，无力吐槽，直接甩代码👇 1234567891011121314151617181920212223242526272829// 获取加密后的 postdataString encodedPostdata = HttpKit.readData(getRequest());// readData()方法实现public static String readData(HttpServletRequest request) &#123; BufferedReader br = null; try &#123; StringBuilder ret; br = request.getReader(); String line = br.readLine(); if (line != null) &#123; ret = new StringBuilder(); ret.append(line); &#125; else &#123; return ""; &#125; while ((line = br.readLine()) != null) &#123; ret.append('\n').append(line); &#125; return ret.toString(); &#125; catch (IOException e) &#123; throw new RuntimeException(e); &#125; finally &#123; if (br != null) &#123; try &#123;br.close();&#125; catch (IOException e) &#123;LogKit.error(e.getMessage(), e);&#125; &#125; &#125;&#125; 至此，，我们就获得了加密后的 postdata 数据了，剩下的就是进行解密了，，解密之后，需要把 xml 格式的数据转为 Map，这样就可以愉快的get(&quot;ComponentVerifyTicket&quot;)了~ 贴下核心代码 👇 1234567891011121314151617181920212223242526272829303132333435// 部分引入的包import javax.xml.parsers.DocumentBuilder;import javax.xml.parsers.DocumentBuilderFactory;import org.w3c.dom.Document;import org.w3c.dom.Element;import org.w3c.dom.Node;import org.w3c.dom.NodeList;try &#123; WXBizMsgCrypt pc = new WXBizMsgCrypt(String token, String encodingAesKey, String component_appid); String result = pc.decryptMsg(msg_signature, timestamp, nonce, encodedPostdata); Map&lt;String, String&gt; data = new HashMap&lt;String, String&gt;(); DocumentBuilderFactory documentBuilderFactory = DocumentBuilderFactory.newInstance(); DocumentBuilder documentBuilder = documentBuilderFactory.newDocumentBuilder(); InputStream stream = new ByteArrayInputStream(result.getBytes("UTF-8")); Document doc = documentBuilder.parse(stream); doc.getDocumentElement().normalize(); NodeList nodeList = doc.getDocumentElement().getChildNodes(); for (int idx = 0; idx &lt; nodeList.getLength(); ++idx) &#123; Node node = nodeList.item(idx); if (node.getNodeType() == Node.ELEMENT_NODE) &#123; Element element = (Element) node; data.put(element.getNodeName(), element.getTextContent()); &#125; &#125; // 至此 通过 data.get("ComponentVerifyTicket") 就可以获取 component_verify_ticket 了~ try &#123; stream.close(); &#125; catch (Exception ex) &#123; // do nothing &#125;&#125; catch (Exception e) &#123; e.printStackTrace();&#125; 获取第三方平台 component_access_token这一步相对来说就没那么复杂了，，只遇到一个问题，就是appid参数缺失，微信返回信息如下👇 1&#123;"errcode":41002,"errmsg":"appid missing hint: [M07502974]"&#125; 这里需要注意的是，，官方文档中是这样写的 POST数据示例: {“component_appid”:”appid_value” ,“component_appsecret”: “appsecret_value”,“component_verify_ticket”: “ticket_value”} 请求参数说明| 参数 | 说明 ||:———————-|:——————:||component_appid | 第三方平台appid ||component_appsecret | 第三方平台appsecret||component_verify_ticket| 微信后台推送的ticket，此ticket会定时推送，具体请见本页的推送说明| 所以，，post请求的数据为 json 格式的字符串，f**k。。。代码实现接上文component_verify_ticket部分👇 123456789101112131415161718192021222324252627282930313233if("component_verify_ticket".equals(data.get("InfoType"))) &#123; // 以下涉及到Redis部分，为伪代码，，领会精神即可 // TODO 把component_verify_ticket保存到 Redis 中 redis.set("component_verify_ticket", data.get("ComponentVerifyTicket")); // TODO 检查 component_access_token 是否存在(过期)(有效期为两小时，过期前提前申请) 。如果过期，则重新向微信服务器申请。 if(!redis.exists("component_access_token")) &#123; final String url = "https://api.weixin.qq.com/cgi-bin/component/api_component_token"; Map&lt;String, String&gt; params = new HashMap&lt;String, String&gt;(); params.put("component_appid", component_appid; params.put("component_appsecret", component_appsecret); params.put("component_verify_ticket", data.get("ComponentVerifyTicket")); // json格式的字符串，mmp String para = JsonKit.toJson(params); // ApiResult 为 JFinal-weixin 框架工具类 ApiResult apiResult = new ApiResult(HttpUtils.post(url, para)); logger.debug(apiResult.getJson()); if (!apiResult.isSucceed()) &#123; logger.info("微信返回的错误码 &gt;&gt;" + apiResult.getErrorMsg()); &#125; if(StrKit.notBlank(apiResult.get("component_access_token")+"")) &#123; // 提前十分钟失效(默认两个小时(7200s)有效)，申请新的~ redis.setex("component_access_token", (Integer.parseInt(apiResult.get("expires_in")+"")-600), apiResult.get("component_access_token")+""); logger.info("component_access_token 加入 Redis 成功~"); &#125;else &#123; logger.debug('wtf?!'); // renderError(apiResult.getErrorMsg()); &#125; &#125;&#125;else &#123; // 未知错误.. // renderCommonError(9999);&#125;// 至此，以后需要 component_access_token 的时候，直接从 Redis 中取就是啦~ 明天修改下小程序模板中登陆部分的代码就好啦，，以上如果有更好的实现方式，欢迎指教~]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>微信</tag>
        <tag>小程序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于语码转换]]></title>
    <url>%2F2018%2F05%2F04%2Fabout_code_switch%2F</url>
    <content type="text"><![CDATA[关于语码转换最近发现自己有一个习惯，就是在聊天的时候总是『不经意间』在普通话中夹杂着英语『表达式(expression)』或者单词什么的。其实，以前也在别人身上遇到过这种情况，当时可能只感觉到『挺装哔』的吧，没往多了想。但是，如今自己身上也出现了这个现象，不免忍不住自省：『我真的只是在装哔么？』 What.语码转换-（Code Switching）是指说话者在对话或交谈中，从使用一种语言或方言转换到使用另一种语言或方言。 Why？？？– 以前为什么没有这个习惯，为什么是最近？ 认真想了下，，可能是『职业病』。程序员，平时编码时都是用各种高级计算机编程语言，绝大部分以英语为主(目前所知，除『易语言』用汉语之外)。所以工作中时时刻刻都在写英语单词/表达式，不光是写，，编程环境也是英语。比如主力写 Java 用的 Eclipse，还有最近写微信小程序用的 Sublime Text，，当然这些也有汉化版的，但总感觉怪怪的，，所以除了写英文，还好读(识记)英文。因为大家都在同样的环境下写代码，所以沟通起来经常会这样『你把 Tomcat clean 一下』、『把这个 jar 包 build path 一下』、『把这个 maven 项目重新 update project 一下』诸如此类。还有各种异常 NullPointerException、ClassNotFoundException 等等,,要想 debug 只能逼自己去识记这些 expression (包括英文单词、短语、短句..)。时间久了，英文大家都是这样过来的，所以用这些英文 expression 丝毫不影响沟通，而且某种程度上比(强行)翻译过来的汉语表达更『准确』。以前也学英语，但是并没有这样高频的使用场景，，除了上英语课，还有英语考试。。。论英语语境的重要性(敲黑板 knock, knock..)。 And..我觉得，，大部分时候，一种语言被翻译成另一种语言的时候，多多少少会有些信息上的损耗。这也是『译事三难(信达雅-严复【天演论】:内容忠实于原文谓信，文辞畅达谓达，有文采谓雅。)』中的信之难。比如，『4』在某种语言中对应的表达方式是『1 + 3』，OK，那么我们现在需要把『4』这样一种东西翻译成另外一种语言。倘若，这种语言中刚好也存在『1』和『3』这样的expression，OK，那么我们直接翻译成对应语言中的『1 + 3』就好。若是不存在『1』和『3』，只存在『2』这种expression，那我们只能先保证『信』，把『4』翻译成『2 + 2』。抑或，对应语言中不存在『+』这种expression，只存在『×』，那只好翻译成『2 × 2』咯。以这个例子来看，虽然最后都表达了『4』，但显然达成『4』的方式是不一样的。 我想说的是，很多时候有那么一种场景，对应语言中并没有很合适的expression，，这个时候，倘若对方刚好知道你想表达的是什么，或者说能 get 到，总感觉比硬生生解释更有趣。像是讲(冷)笑话，直接将笑点讲出来，可能会非常无聊，完全失去了『笑话』的意义。但倘若，将笑点包装在『笑话』中，对方听了可以 get 到那个点，这时候才有『会心一笑』(捧腹大笑，，总之是笑了)。这个思考 translate/convert 的过程，或者说转得那弯儿才是最有趣儿的~事实上，我非常喜欢 enjoy 这个单词，但我真的想不到汉语语境中与之对应的expression。。 或者，，像上边提到过的『4』一样，我们再谈论的『4』的时候，我们不直接谈论『4』，，而是，我说『1 + 3』的时候，你可以 get 到我在谈『4』，你在说『2 + 2』的时候，我也可以 get 到。这个『4』就像白马非马中的马，像 Java 中的抽象类，，而『1 + 3』和『2 + 2』就像白马非马中的白马，Java 中的实例化对象。总之，，有时候，抽象的东西的确比具象的东西更美~ 另外，，语码转换也是有成本的，需要花额外的时间去 translate，找到对应语言中的 expression。而且，还不一定能找到。。 What’s more~姑且再发散一下，，有时候聊天中会夹杂很多『(专业)术语』。看上去是纯装哔，但其实有可能只是想降低沟通成本。也可能是对方这样表述惯了，一时并未 switch 过来。举个稍微极端一点的例子，，我们都知道椅子是什么，所以我们在谈到椅子的时候，不需要按照百度百科中词条解释那样去说：『一种日常生活家具，一种有靠背、还有扶手的坐具。』，，直接说椅子就好，准确、高效~ The end有一天和同事去吃饭，地下的美食广场，各种档口的那种。饭点儿，人巨多，桌子长凳密密麻麻，我们在里边找到一空位。…吃完了，起身准备离开，，我在前，同事在后。没走几步，我望着出口的方向顿了一下，，然后离开。从美食广场出来之后，我问同事，，Me –『晓得刚才我为什么顿一下么？』同事 – 『？？？』Me – 『因为我刚才在【规划路径】，哈哈』同事– 『好冷..』]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>沟通</tag>
        <tag>术语</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018_03-第3周]]></title>
    <url>%2F2018%2F03%2F16%2F2018_03_week_3rd%2F</url>
    <content type="text"><![CDATA[2018-03-第三周又到周五了，，今天手头的工作差不多告一段落了，趁着热乎劲儿赶紧把这两天遇到的问题记录一下~ jQuery中$.load()动态加载页面脚本调试you know，我是一个写前端的Java程序员。。最近在做后台的数据表格页面时遇到一个问题，，大家应该都见过类似的后台点击白色框选地方的菜单项，右侧动态加载相应的内容，，每一个菜单项有一个点击事件，像这样👇1&lt;a href="javascript:clickMenu('#(menu.url)')"&gt; 12345// url为相对路径地址，最终指向某个html页面// #mainContent指向右侧主页面function clickMenu(url)&#123; $('#mainContent').load(url);&#125; 正常来说，如果我们想要调试页面中的JavaScript代码，只需要 Cmd+Alt+I 调出Chrome DevTools，选择 source，找到相应的代码段，添加断点即可。但是，，以$.load()的方式动态加载的页面在Source中根本无法找到。。这 就尴尬了！！！难道只能在页面javaScript代码段中手码debugger？！惨无人道！一点也不优雅！！ 一番求索，终于看到了希望，，在Stack Overflow[^1]找到了类似的问题，，顺藤摸瓜，找到了一个唤作sourceURL的东东，,只需要在要载入的页面中javascript代码添加一句//# sourceURL=jsName.js即可，然后就可以在 source 中找到了，接下来就可以愉快的打断点啦~👇 另外，，我们可以再深入挖掘一下下，比如了解下阮一峰老师写的JavaScript Source Map 详解，看到日期着实尴尬了下，2013年就有了，而我2018年才第一次见到，，介，也许就是传说中的差距。。 jqGrid中将导航栏复制到表格上方在jQuery中$.load()动态加载页面脚本调试中的第一张偏中，主页面表格左下角的导航栏是一些常见的操作，比如添加、删除、编辑、搜索和刷新，，但是放在左下角的话，着实不太方便。控制好表格的高度还好一些，不用像下滑动直接就能在左下角找到这些操作入口。但是，如果控制不好高度的话，还要将页面滑到底部，，这体验，相当不好，，如果用户首次登陆后台的话，可能会懵『卧槽，怎么添加数据？！！咋操作？？？』。我一直觉得不需要产品使用说明的设计才是好设计，，这样，把常用操作放在表格左上角，效果马上不一样了~ 在导航栏的设置项中，找到了cloneToTop选项，但是设置为true后，导航栏并没有cloneToTop..在初始化设置项中找到了toppager，将值改为true之后，呦，的确上去了，，像这样 唯独导航栏没有上去！！！可恶，，于是又是一番求索，有成果~原来，，设置cloneToTop的前提是toppager的值为true，，所以，接下来变成了这样👇 然后只需将分页和统计相关的div remove()就可以了1234$("#merchantTable_toppager_center").remove();$("#merchantTable_toppager_right").remove();// 我将这两行代码放在了 loadComplete 回调函数中。 完美~ 参考链接： 关于Source Map动态调试 https://stackoverflow.com/questions/9092125/how-to-debug-dynamically-loaded-javascript-with-jquery-in-the-browsers-debugg https://www.html5rocks.com/en/tutorials/developertools/sourcemaps/#toc-sourceurl http://www.ruanyifeng.com/blog/2013/01/javascript_source_map.html 关于jqGrid导航栏复制到表格上方 https://stackoverflow.com/questions/3929896/adding-jqgrid-custom-navigation-to-top-toolbar https://stackoverflow.com/questions/3552855/add-toolbar-in-the-bottom-of-the-header-using-jqgrid/3557663#3557663]]></content>
      <categories>
        <category>周记</category>
      </categories>
      <tags>
        <tag>Source Map</tag>
        <tag>jqGrid</tag>
        <tag>Chrome DevTools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2018-01 小结]]></title>
    <url>%2F2018%2F01%2F30%2Fsummary_of_2018_1st%2F</url>
    <content type="text"><![CDATA[2018年1月份小结最近一直在忙小程序的事情，也是公司的新项目。因为之前小程序的入口一直很深，使用起来比较麻烦，所以也没重视起来，，但是今年1月份，微信突然更新之后，有了『社交』小游戏–跳一跳，在朋友圈好一波刷屏。但对于我们来说，，最惹眼球的莫过于微信首页下拉呼出recent小程序。如此一来，小程序的使用场景顿时多了起来，公司也开始重视起来。 其实之前自己也一直想做一个小程序的，用来收集自己的位置信息，，当然位置数据是自己主动提交的。如此，就可以做阶段性的总结了，比如生成个全年范围内的热力图什么的，看看自己过去一年中都在什么地方消耗时间了~ 其实，还想用小程序做另外一个项目的，关于LBS的，，已经把后台框架搭起来了，使用的Spring + Spring MVC + Mongodb；Spring 和 Spring MVC已经好久没用过(好吧，，Spring和Spring MVC第一次用，在学校时老师还没教，就出来找工作了)了，Mongodb更是从来没有接触过，所以一切从头开始。做完上个用纯Servlet搭的项目，感觉思维已经被禁锢了。。不过，这个框架也挺有意思的，好像做游戏开发的都这样做，，整个项目只有一个Servlet，每个请求都带有一个messageId参数，不同的 messageId 代表不同的 Controler (中的不同的业务)，message中包含了所有的请求信息和用户的session，然后将message实例注入到相应messageId对应的接口所在的Controler中进行操作。 用户请求 -》装配message -》将message以动态代理的方式注入相应的Controler -》根据message中的messageId，找到对应的接口 -》执行业务逻辑代码 第一次见到这种『框架』，还是蛮受启发的。因为是某前辈程序员自己搭的，就是坑多了点儿，耦合也比较严重。。 关于Mongodb，，当初学 MySQL 的时候，老师提到这是一种关系型数据库，与之相对的还有『非关系型数据库』，即NoSQL(全称Not Only SQL)。当时提到了Mongodb，觉得这个数据库名字特别好听，印象还挺深刻。。但具体它是什么，完全没概念。本来计划继续用 MySQL 的，但是中间想到一个问题，，怎么用 MySQL 在一个字段中存储未知数量的经纬度信息呢？？直接用逗号拼接？觉得不够优雅。。然后在网上看到有网友说可以尝试 Mongodb，而且 Mongodb 中还有原生的地理位置索引，相当方便。于是，就想尝试一下，，欧耶！新的训练集~刷了一遍Mongodb的入门视频，又刷了一遍SSM(Spring + Spring MVC + Mongodb)框架整合视频，然后开始依样画葫芦。有几点记录下： 用@Autowried注入，但在调用相关实例的时候总是报错，具体报错信息记不得了，类似org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &#39;locationController&#39;: Unsatisfied dependency expressed through field &#39;locationDao&#39;;网上几乎所有的方法都试了，还是不行，各种心灰意冷，，最后在一篇博客中得到启发，，那篇博客好像在讲注入什么的，还通过控制台的日志信息验证自己的想法。噢？然后我也去盯控制台，发现项目启动的时候没有关于Beans注入成功的信息，，丫丫！然后继续往上捣，发现applicationContext.xml没有被正确载入。。。。。重新修改web.xml配置文件路径，搞定！Loading XML bean definitions from class path resource [applicationContext.xml]…Root WebApplicationContext: initialization completed in 1684 ms 配置文件中关于 Mongodb 数据库连接的地方，同样，，网上的方法几乎都试了，还是不行。主要是配置文件中提示cvc-complex-type.2.4.c: The matching wildcard is strict, but no declaration can be found for element &#39;mongo:mongo&#39;.最后实在没辙，去 Mongodb 官网翻doc，，找到相应jar包的版本，发现人家用的&lt;mongo:mongo-client&gt;标签，不是&lt;mongo:mongo&gt;。。因为这段配置是在网上找的，而且都用的这个标签。。但我一般都会用最新版本的jar包，，好吧。 别的还算顺利，，从搭环境到我把第一条位置信息持久化的Mongodb中已经两天了。。。但收获也是满满~ 关于微信小程序，，最近好像一直都在做关于前端的东西，博客中最近也分享的大多也是js的内容，但我明明是Java工程师。。。在上面的项目中遇到一个问题，，假如我想定时向数据库中插入位置信息，那常规实现起来可能是这样：123456789101112131415161718setInterval(function()&#123; wx.getLocation(&#123; type: 'wgs84', success: function(res) &#123; wx.getLocation(&#123; url: '', data: &#123; ... &#125;, type: 'json', method: 'POST', success: res =&gt; &#123; console.log(res.data); &#125; &#125;); &#125; &#125;);&#125;,10000); 这样的代码还是很可怕的，很容易陷入回调深渊。。想用Promise或者async和await，又怕某些手机支持到了ES5，于是想着有没有什么很好的解决办法，最好微信小程序也有个框架什么的。在网上做了做功课，发现了腾讯官方在Github上开源的一个框架wepy(微信小程序组件化开发框架WePY官方文档)。然后又开始做功课，看到文档上说是基于Vue.js框架，OK，，又去刷Vue的视频。在讲到Vue中的v-model的时候，好像明白一点什么是MVVM框架了。回过头再学wepy，，它像一个框架，又像一个翻译器。说到这儿，感觉又有点像本站所用Hexo，是一个博客框架。前者将.wyp文件翻译成[.wxml,.wxss,.js,.json]，后者将.md文件翻译成.html文件。这两者应该都是基于node.js。想想以前做前端项目时，完全不是一样的感觉。到目前为止，因为不了解node.js，，我只能说，嗯，有点意思~ 另外，，因为小程序代码包不能超过2M，所以今天尝试将目录中的静态资源文件放到服务器中，以节省空间。首先想到的是nginx，公司用的坑爹windows server 2008。事实证明的确坑爹，，已经可以在浏览器中访问本地图片列表了，但是点到某个具体的文件时就开始缓慢请求，最后报504错误。在自己Mac上的nginx模拟了下，虽然中间出了些问题，但最终还是解决了。只能将静态资源放到了tomcat中，不够优雅。。得改。关于在mac中遇到问题，location中alias和root的区别，， alias syntax: alias file-path|directory-path;default: no // 无默认值context: location // 上下文环境，处于location配置项中This directive assigns a path to be used for the indicated location. Note that it may look similar to the root // 这条命令为表明的位置分配了一个路径。需要注意的是，alias看起来有些像rootdirective, but the document root doesn’t change, just the file system path used for the request.// ？？？，但是文档根路径不会变，仅仅用来响应请求要访问的文件系统路径For example:location /i/ { alias /spool/w3/images/;}The request “/i/top.gif” will return the file “/spool/w3/images/top.gif”.// “/i/top.gif”的请求实际得到的是”/spool/w3/images/top.gif” root syntax: root pathdefault: root htmlcontext: http, server, location, if in locationroot specifies the document root for the requests. For example, with this configurationlocation /i/ { root /spool/w3;}A request for “/i/top.gif” will return the file “/spool/w3/i/top.gif”. You can use variables in the argument.note: Keep in mind that the root will still append the directory to the request so that a request for “/i/top.gif” will not look in “/spool/w3/top.gif” like might happen in an Apache-like alias configuration where the location match itself is dropped. Use the alias directive to achieve the Apache-like functionality. // 记住，请求路径仍然会拼接在root所代指的路径后，所以请求”/i/top.gif”不会在”/spool/w3/top.gif”路径下寻找；类似的像类Apache服务器中的配置???😂???,在类Apache服务器中使用alias来实现类似的功能。]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[比尔盖茨]]></title>
    <url>%2F2018%2F01%2F20%2Ftime_flies%2F</url>
    <content type="text"><![CDATA[时光飞逝从未感觉时间的力量如此强大，， 今天下午，一边写项目文档，一边听极客公园创新大会 IF2018，，依然，张鹏的主持人，在讲到未来人工智能对现有传统行业的冲击时，提到让科技带有人文色彩，缓冲这种冲击。其中，用到了比尔盖茨的一段视频，，视频中 Bill Gates 阐述了一种观点： 原文链接The robots that takes your job should pay taxes.应当向拿走你工作的机器人征税。 这样，，机器人用来做那些重复且机械化的工作，而被解放的劳动力可以用来更好的从事其他只能由人类进行的工作，比如照顾老人，小班授课等等。 但是，今天我并不想讨论这些。。只是，看到视频的一瞬间，有些晶莹的小东西在眼眶里打转，，我知道比尔盖茨老了，但是没想到老成这样。 我也不知道自己为什么会如此激动，事实上，，我一直用的都是 Macbook Pro 15” 2013 early，虽然是ebay上淘的二手的，但这的确是我第一台个人电脑。我对Windows系统并不感冒，也不是微软的拥趸，，甚至有些厌恶。但看到视频中的比尔盖茨时，，就像看到了一个很熟悉很亲近但又许久未见的亲人(Or朋友)躺在医院的病床上，身上连满了仪器，还有各种侵入式的管子，，见到他那一刻要强忍泪水。。我想不到更好的语言去描述这种感觉，但震撼良久，，尤其是看到他的右视图镜头时。 我开始思考自己为什么会有这样的情绪，，想到普鲁斯特问卷-2017中关于『你最恐惧的是什么？』的回答，，大概明白了。我害怕的是时光飞逝，而时间在 Bill Gates 的脸上留下了让人无法忽视的痕迹。而我此时看到Bill，就像收到一条来自时间的警告，，警告我，『listen~ ti ke ta ke, ti ke ta ke…The time is passing!』看到『时光飞逝』四个字并不可怕，但是看到熟悉的人『突然』衰老，，这很可怕！！！Bill 将这种可怕具象化了。。突然感觉和他更加亲近，也许我厌恶的不是 Windows，而是 Windows 平台上各种国产杀毒软件，安全管家之类的流氓行为，还有各种弹框。我安装个搜狗输入法，搜狐新闻弹个毛线？！Shit! 不晓得国外的 Windows 生态是不是也是这样。。不可否认的是 Bill Gates 让计算机真正走入千家万户，，正所谓『旧时王谢堂前燕，飞入寻常百姓家』。计算机最初本是用来计算导弹弹道，之后开始流行于商业，排版啊，计算啊，，直到1995年的 win95 出现，图形化页面的操作体验对普通用户非常友好，同时也点亮了计算机技能树中的娱乐功能。正因为这一点，包括因特网在内的信息技术才会得到如此跨越式的发展，，倘若，计算机仅限于军事、商业、科学研究，那么现在地球肯定不能被称作『地球村』。单这一点来说，，Bill Gates 功不可没。采访中，视频结尾，，Bill Gates 不好意思的挠头了，眼神也没那么严肃了，甚至还飘向了周围，然后迅速收回，，不得不说，瞬间被实力圈粉。在这儿，我想说他很可爱，合适么？哈哈 那么，，为什么当初选 Mac 呢？一方面，因为从事过苹果产品销售的工作，对Mac比较熟悉，不夸张的说，，我接触 Mac 的时间比接触 Windows 的时间要长(扶额.jpg)，，不是因为接触 Mac 时间长，而是因为接触 Wondows 时间短，虽然从小学就开始接触 Windows。。这个可以算作 Context，真正原因只有两点，， Mac 上玩主流游戏成本比较高，，尤其是 LOL，虽然有也有 Mac 版，但是是美服，网络延迟也不可想象，，嗯，Mac 的显卡也是够呛。其他游戏就不说了。。 Macbook 的触控板简直不要太好用！！！ 毕竟买来是想当做生产力工具来用的，不能玩游戏是刚需，，虽然我也没那么大瘾，毕竟手残(再次扶额..)。而触控板就是纯用户体验了，2880×1800 的分辨率也是逆天，在加上流氓软件少之又少，，就它了~]]></content>
      <categories>
        <category>呓语</category>
      </categories>
      <tags>
        <tag>比尔盖茨</tag>
        <tag>时间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL分组取前N条记录]]></title>
    <url>%2F2018%2F01%2F17%2Ftop-n_after_sql_group%2F</url>
    <content type="text"><![CDATA[SQL分组取前N条记录实际业务中有这样这样一个需求，，有6种不同的测试项目，每个项目对应很多小游戏(改善方案)，客户要求测试完成后，每周进行小游戏的循环推送，每种项目每次推送5个小游戏。 假如A项目对应的小游戏有8个，，那么第一周则推送第1-5个，第二周则推送6、7、8、1、2,以此方式进行循环。 单个项目还好说，但是6种项目怎么搞？！懵逼。。想不出来，，好吧，用存储过程搞定了。但是，在前期摸索的过程中，发现好多猿猿也有类似的需求，，只不过，我的需要循环。那么，，倘若不循环，值进行一次推送呢？6个项目一起，每种项目取前5项？可以学习下~ 以网上都能找到的例子来说：[^1]123456789101112131415161718192021222324252627282930-- 查询每门课程的前2名成绩CREATE TABLE StudentGrade( stuId CHAR(4), --学号 subId INT, --课程号 grade INT, --成绩 PRIMARY KEY (stuId,subId))-- 表中数据如下INSERT INTO StudentGrade(stuId,subId,grade) VALUES('001',1,97);INSERT INTO StudentGrade(stuId,subId,grade) VALUES('001',2,50);INSERT INTO StudentGrade(stuId,subId,grade) VALUES('001',3,70);INSERT INTO StudentGrade(stuId,subId,grade) VALUES('002',1,92);INSERT INTO StudentGrade(stuId,subId,grade) VALUES('002',2,80);INSERT INTO StudentGrade(stuId,subId,grade) VALUES('002',3,30);INSERT INTO StudentGrade(stuId,subId,grade) VALUES('003',1,93);INSERT INTO StudentGrade(stuId,subId,grade) VALUES('003',2,95);INSERT INTO StudentGrade(stuId,subId,grade) VALUES('003',3,85);INSERT INTO StudentGrade(stuId,subId,grade) VALUES('004',1,73);INSERT INTO StudentGrade(stuId,subId,grade) VALUES('004',2,78);INSERT INTO StudentGrade(stuId,subId,grade) VALUES('004',3,87);-- 要查询每门课程的前2名成绩，即001 1 97003 1 93003 2 95002 2 80004 3 87003 3 85-- 如何实现？ 查看表中所有数据：1234567891011121314select * from StudentGrade ORDER BY subid asc,grade desc|学号|科目|成绩|001 1 97003 1 93002 1 92004 1 73003 2 95002 2 80004 2 78001 2 50004 3 87003 3 85001 3 70002 3 30 两种解决方案：123456789101112131415-- 第一种select * from StudentGrade a where (select count(1) from studentGrade b where b.subId=a.subId and b.grade&gt;a.grade)&lt;2 order by subId,grade desc-- 第二种SELECT a.* from StudentGrade a left join StudentGrade b on a.subid=b.subid and a.grade&lt;b.grade GROUP BY a.stuid,a.subid,a.grade having count(b.stuid)&lt;2 order by a.subid,a.grade desc 对于第一种方案我是这么理解的，，因为b.subId=a.subId,a、b两表相连，以subId进行区分，类似分组。以科目一为例，， 若a.grade=73，则b表中的科目一中&gt;73分的共有3项，而条件要求count(1)&lt;2,这样显然是不符合要求的，所以科目一的73分不行； 同理92分。 若a.grade=93，count(1)=1 &lt; 2，符合要求~ 若a.grade=97，count(1)=0 &lt; 2，符合要求~完美~ 本来也是有点想不明白的，但是看到下面这句，，诶，有点意思，，噢~了然！ 每取每一条记录，判断同一个班级，大于当前成绩的同学是不是小于2个人[^2] 对于第二种方案，,有一种奇技淫巧，就是把a、b两表的数据都查询出来12345678910111213141516SELECT a.*,b.* from StudentGrade a left join StudentGrade b on a.subid=b.subid and a.grade&lt;b.grade GROUP BY a.stuid,a.subid,a.grade having count(b.stuid)&lt;2 order by a.subid,a.grade desc -- 结果如下001 1 97 null null null 003 1 93 001 1 97003 2 95 null null null 002 2 80 003 2 95004 3 87 null null null 003 3 85 004 3 87-- 前3列为a表，后3列为b表 如此看来，清楚明了，，因为a.subid=b.subid and a.grade&lt;b.grade，所以第2行a表的93分和b表的97分相连了，又因为count(b.stuid)&lt;2，所以只取了a表每个科目的前2项。若我们只取a表的数据，后3列消失，，完美~ 这个，，就这样吧，剩下的就是实操了，还是自己亲身command+R运行一下，体会更深~ [^1]: sql 用Group by分组后,取每组的前几条记录(转) [^2]: mysql使用GROUP BY分组实现取前N条记录的方法]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于java中的序列化]]></title>
    <url>%2F2018%2F01%2F13%2Fserialization_and_deserialization_of_java%2F</url>
    <content type="text"><![CDATA[关于java中的序列化Context最近在精简项目代码，去除无用的依赖以及没有没有使用的模块。这其中免不了删除实体类中的无效字段。于是，，问题来了：1java.io.InvalidClassException: entity.User; local class incompatible: stream classdesc serialVersionUID = 8550471390860600205, local class serialVersionUID = -7433272285406297333 用户未登录？改完之后，在测试某接口的时候，只是返回用户未登录的信息，没想太多，，于是调用模拟测试账号登录行为的接口，然后重新测试刚才的接口，但还是返回用户未登录的信息。。 这就怪了，，正常来说，用户在正常登陆时，通过SQL查到用户信息后，保存部分字段到Redis中，之后每次用户发送请求时直接通过用户ID从Redis中获取用户相关信息。所以，，首先怀疑的是用户在登陆后发送其他请求时，通过Redis获取用户信息时出问题了，然后一点点看代码。调试到这儿的时候发生问题了👇12345678910ByteArrayInputStream bais = null;try &#123; // 反序列化 bais = new ByteArrayInputStream(bytes); ObjectInputStream ois = new ObjectInputStream(bais); return ois.readObject();&#125; catch (Exception e) &#123; //Tools.error(e);&#125;return null; 👆这是从Redis中获取用户信息后的反序列化时的部分代码，，正常来说，应该是返回从流中反序列化后得到的User实例。但实际调试过程中，运行到第6行之后，又跳到第10行，，咦，什么鬼？？两个return？？嗯，，当然不是，肯定是在ois.readObject()报错了，再看第8行，妈蛋，，打印报错信息的代码被注释了！OK，反注释之后就出现了Context中的报错信息。 序列化报错信息大意为，，entity.User中本地类文件冲突，流中的类描述serialVersionUID与本地相应类的描述serialVersionUID不一致。出于安全考虑，反序列化失败。关于序列化，之前不甚了解，，正好借此机会好好了解下~ 什么时候使用序列化 把的内存中的对象持久化到一个文件中或者数据库中时候； 套接字在网络上传送对象的时候； serialVersionUID适用于Java的序列化机制。简单来说，Java 的序列化机制是通过判断类的serialVersionUID来验证版本一致性的。在进行反序列化时，JVM 会把传来的字节流中的serialVersionUID与本地相应实体类的serialVersionUID进行比较，如果相同就认为是一致的，可以进行反序列化，否则就会出现序列化版本不一致的异常，即是InvalidCastException。 serialVersionUID有两种显示的生成方式： 默认的1L，比如：private static final long serialVersionUID = 1L; 根据类名、接口名、成员方法及属性等来生成一个64位的哈希字段，比如：private static final long serialVersionUID = xxxxL; 当一个类实现了Serializable接口，如果没有显示的定义serialVersionUID，Eclipse 会提供相应的提醒。面对这种情况，我们只需要在 Eclipse 中点击类中 warning 图标一下，Eclipse就会自动给定两种生成的方式。 当实现 java.io.Serializable 接口的类没有显式地定义一个serialVersionUID变量时候，Java序列化机制会根据编译的 Class 自动生成一个serialVersionUID作序列化版本比较用，这种情况下，如果 Class 文件(类名，方法明等)没有发生变化(增加空格，换行，增加注释等等)，就算再编译多次，serialVersionUID也不会变化的。 所以，在项目中 User 类中并没有显式的定义serialVersionUID。所以，在我精简代码后，serialVersionUID发生变化，导致反序列化失败。解决方法也很简单，，显式声明与流中相同的serialVersionUID即可。1private static final long serialVersionUID = 8550471390860600205L; 静态变量序列化下面代码中Test实体类实现了Serializable接口，并初始化了一个静态变量staticVar。将对象序列化后，修改静态变量的数值，再将序列化对象读取出来，然后通过读取出来的对象获得静态变量的数值并打印出来那么结果是 10 还是 5 呢？123456789101112131415161718192021222324252627public class Test implements Serializable &#123; private static final long serialVersionUID = 1L; public static int staticVar = 5; public static void main(String[] args) &#123; try &#123; //初始时staticVar为5 ObjectOutputStream out = new ObjectOutputStream(new FileOutputStream("result.obj")); out.writeObject(new Test()); out.close(); //序列化后修改为10 Test.staticVar = 10; ObjectInputStream oin = new ObjectInputStream(new FileInputStream("result.obj")); Test t = (Test) oin.readObject(); oin.close(); //再读取，通过t.staticVar打印新的值 System.out.println(t.staticVar); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 最后的输出是 10，对于无法理解的读者认为，打印的 staticVar 是从读取的对象里获得的，应该是保存时的状态才对。之所以打印 10 的原因在于序列化时，并不保存静态变量，这其实比较容易理解，序列化保存的是对象的状态，静态变量属于类的状态，因此序列化并不保存静态变量。 但是，serialVersionUID也是static的，那它是怎么被保存的呢？在jdk_7中，，1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192java.io.ObjectOutputStream/** * Writes class descriptor representing a standard (i.e., not a dynamic * proxy) class to stream. */private void writeNonProxyDesc(ObjectStreamClass desc, boolean unshared) throws IOException&#123; bout.writeByte(TC_CLASSDESC); handles.assign(unshared ? null : desc); if (protocol == PROTOCOL_VERSION_1) &#123; // do not invoke class descriptor write hook with old protocol desc.writeNonProxy(this); &#125; else &#123; writeClassDescriptor(desc); &#125; Class cl = desc.forClass(); bout.setBlockDataMode(true); if (cl != null &amp;&amp; isCustomSubclass()) &#123; ReflectUtil.checkPackageAccess(cl); &#125; annotateClass(cl); bout.setBlockDataMode(false); bout.writeByte(TC_ENDBLOCKDATA); writeClassDesc(desc.getSuperDesc(), false);&#125;/*将指定的类描述符写入 ObjectOutputStream。类描述符用于标识写入流中的对象的类。ObjectOutputStream 的子类可以重写此方法，从而定制将类描述符写入序列化流中的方式。然后，应该重写 ObjectInputStream 中的相应方法（ readClassDescriptor），以便根据其定制的流表示形式来重构类描述符。默认情况下，此方法根据 Object Serialization 规范中定义的格式写入类描述符。*//*注意，仅当 ObjectOutputStream 没有使用旧的序列化流格式（通过调用 ObjectOutputStream 的 useProtocolVersion 方法设置）时才调用此方法。如果此序列化流在使用旧的格式（即 PROTOCOL_VERSION_1），则以不可重写或自定义的方式在内部写入类描述符。*/java.io.ObjectStreamClass/** * Writes non-proxy class descriptor information to given output stream. */void writeNonProxy(ObjectOutputStream out) throws IOException &#123; out.writeUTF(name); out.writeLong(getSerialVersionUID());//写入获取的serialVersionUID byte flags = 0; if (externalizable) &#123; flags |= ObjectStreamConstants.SC_EXTERNALIZABLE; int protocol = out.getProtocolVersion(); if (protocol != ObjectStreamConstants.PROTOCOL_VERSION_1) &#123; flags |= ObjectStreamConstants.SC_BLOCK_DATA; &#125; &#125; else if (serializable) &#123; flags |= ObjectStreamConstants.SC_SERIALIZABLE; &#125; if (hasWriteObjectData) &#123; flags |= ObjectStreamConstants.SC_WRITE_METHOD; &#125; if (isEnum) &#123; flags |= ObjectStreamConstants.SC_ENUM; &#125; out.writeByte(flags); out.writeShort(fields.length); for (int i = 0; i &lt; fields.length; i++) &#123; ObjectStreamField f = fields[i]; out.writeByte(f.getTypeCode()); out.writeUTF(f.getName()); if (!f.isPrimitive()) &#123; out.writeTypeString(f.getTypeString()); &#125; &#125;&#125;java.io.ObjectStreamClass/** * Return the serialVersionUID for this class. The serialVersionUID * defines a set of classes all with the same name that have evolved from a * common root class and agree to be serialized and deserialized using a * common format. NonSerializable classes have a serialVersionUID of 0L. * * @return the SUID of the class described by this descriptor * 回此类的 serialVersionUID。serialVersionUID 定义了一组具有相同名称的类，它们的名称都是从公共根类演化而来的，并且能够使用公共格式进行序列化和反序列化。NonSerializable 类的 serialVersionUID 为 0L。 */public long getSerialVersionUID() &#123; // REMIND: synchronize instead of relying on volatile? if (suid == null) &#123; suid = AccessController.doPrivileged( new PrivilegedAction&lt;Long&gt;() &#123; public Long run() &#123; return computeDefaultSUID(cl); &#125; &#125; ); &#125; return suid.longValue();&#125; 除此之外，，transient关键字修饰的变量也不会被序列化。 父类的序列化context：一个子类实现了Serializable接口，它的父类都没有实现Serializable接口，序列化该子类对象，然后反序列化后输出父类定义的某变量的数值，该变量数值与序列化时的数值不同。 解决：要想将父类对象也序列化，就需要让父类也实现Serializable接口。如果父类不实现的话的，就需要有默认的无参的构造函数。在父类没有实现Serializable接口时，虚拟机是不会序列化父对象的，而一个 Java 对象的构造必须先有父对象，才有子对象，反序列化也不例外。所以反序列化时，为了构造父对象，只能调用父类的无参构造函数作为默认的父对象。因此当我们取父对象的变量值时，它的值是调用父类无参构造函数后的值。如果你考虑到这种序列化的情况，在父类无参构造函数中对变量进行初始化，否则的话，父类变量值都是默认声明的值，如 int 型的默认是 0，string 型的默认是 null。 另外，，如果父类已经实现Serializable接口，其子类就无需再显式的实现Serializable接口了。 参考链接：https://www.cnblogs.com/duanxz/p/3511695.html - 学无止境]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>序列化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高墙与鸡蛋]]></title>
    <url>%2F2018%2F01%2F13%2FHigh_walls_and_eggs%2F</url>
    <content type="text"><![CDATA[高墙与鸡蛋 转载自 http://blog.sina.com.cn/s/blog_48f36ce00100e3qd.html - by 林少华的博客 [按：此文是依据村上春树在日本《文艺春秋》杂志（四月号）发表的日语原文翻译的] 我作为一个小说家，换句话说，作为以巧妙说谎为职业的人来到这里、来到耶路撒冷市。 当然，说谎的不都是小说家。诸位知道，政治家屡屡说谎，外交官和军人说谎，二手车推销员和肉铺和建筑业者也说谎。但小说家说谎和他们说谎的不同之处在于：小说家说谎不受道义上的谴责。莫如说谎说得越大越高明，小说家越能得到人们的赞赏和好评。为什么呢？ 这是因为，小说家能够通过巧妙说谎、通过栩栩如生的虚构而将真相拽到另一场所投以另一光照。以其固有的形式捕捉真相并予以准确描述在许多情况下是不可能的。惟其如此，我们才要把真相引诱出来移去虚构地带，通过将其置换为虚构形式来抓住真相的尾巴。但为此必须首先在自己心底明确真相的所在，这是巧妙说谎所需要的重要资格。 可是今天我不准备说谎，打算尽可能说实话。一年之中我也有几天不说谎，今天恰好是其中的一天。 实话实说好了。关于此次来以色列接受耶路撒冷文学奖，不少人劝我最好拒绝。甚至警告说如果前来，将开展不买我的书的运动。无须说，理由在于加沙地区的激战。迄今为止，已不止一千人在被封锁的城区丧生，据联合国报告，大多数是儿童、老人等手无寸铁的平民。 接到获奖通知以来，我本人也一再自问：这种时候来以色列接受文学奖果真是妥当的行为吗？不会给人以支持作为纷争当事者一方、拥有占绝对优势的军事力量并积极行使的国家及其方针的印象吗？那当然不是我所希望的。我不认可任何战争，不支持任何国家。同时，自不待言，我的书在书店被人拒买也不是我所希求的。 然而，经过深思熟虑，我重新坚定了来这里的决心。原因之一，就在于有那么多人劝我最好别来。或许我有一种大部分小说家都有的“犟脾气”——别人叫我“别去那里”、“别干那个”、尤其那样警告我的时候，我就偏偏想去或想干，此乃小说家的nature（天性）。为什么呢？因为小说家属于这样一种人：无论刮怎样的逆风，也只能相信自己实际目睹、自己实际手摸的东西。 正因如此，我才出现在这里。较之不来，选择了来；较之什么也不看，选择了看点儿什么；较之什么也不说，选择了向诸位说点儿什么。 有一句话（message）请允许我说出来，一句个人性质的话。这句话在我写小说时总在我脑袋里挥之不去。它并非写在纸上贴在墙壁，而是刻于我的脑壁。那是这样一句话： 假如这里有坚固的高墙和撞墙破碎的鸡蛋，我总是站在鸡蛋一边。 是的，无论高墙多么正确和鸡蛋多么错误，我也还是站在鸡蛋一边。正确不正确是由别人决定的，或是由时间和历史决定的。假如小说家站在高墙一边写作——不管出于何种理由——那个作家又有多大价值呢？ 那么，这一隐喻到底意味什么呢？在某种情况下它是简单明了的。轰炸机、坦克、火箭、白燐弹、机关枪是坚硬的高墙。被其摧毁、烧毁、击穿的非武装平民是鸡蛋。这是这一隐喻的一个含义。 但不仅仅是这个，还有更深的含义。请这样设想好了：我们每一个人都或多或少分别是一个鸡蛋，是具有无可替代的灵魂和包拢它的脆弱外壳的鸡蛋。我是，你们也是。再假如我们或多或少面对之于每一个人的坚硬的高墙。高墙有个名称，叫作体制（System）。体制本应是保护我们的，而它有时候却自行其是地杀害我们和让我们杀人，冷酷地、高效地、而且系统性地（Systematiclly）。 我写小说的理由，归根结底只有一个，那就是为了让个人灵魂的尊严浮现出来，将光线投在上面。经常投以光线，敲响警钟，以免我们的灵魂被体制纠缠和贬损。这正是故事的职责，对此我深信不疑。不断试图通过写生与死的故事、写爱的故事来让人哭泣、让人惧怕、让人欢笑，以此证明每个灵魂的无可替代性——这就是小说家的工作。我们为此而日复一日地认真编造故事。 我的父亲去年夏天去世了，活了九十岁。他是个退休教师，也是个兼职佛教僧侣。在研究生院就读期间被征召入伍，参加了中国大陆的战斗。我小的时候，他每天早上都在饭前向佛坛献上长长的深深的祈祷。一次我问父亲为什么祈祷，他回答为了在战场死去的人，为了在那里——无论友方敌方——失去性命的人。每次看见父亲祈祷的身姿，我都觉得那里似乎漂浮着死亡的阴影。 父亲去世了，其记忆——还没等我搞清是怎样的记忆——也彻底消失了。但是，那里漂浮的死亡气息仍留在我的记忆中。那是我从父亲身上继承的少数然而宝贵的事项之一。 我在这里想向诸位传达的只有一点：我们都是超越国籍、种族和宗教的一个一个的人，都是面对体制这堵高墙的一个一个的蛋。看上去我们毫无获胜的希望。墙是那么高那么硬，那么冰冷。假如我们有类似获胜希望那样的东西，那只能来自我们相信自己和他人的灵魂的无可替代性并将其温煦聚拢在一起。 请这样想想看。我们每一个人都有可以拿在手中的活的灵魂，体制则没有。不能让体制利用我们，不能让体制自行其是。不是体制创造了我们，而是我们创造了体制。 我想对诸位说的仅此一点。 荣获耶路撒冷奖，我很感谢。感谢世界很多地方都有看我书的人。我要向耶路撒冷的每一位读者致以谢意。毕竟是因了你们的力量我才出现在这里的。但愿我们能够共同拥有什么——非常有意义的什么。我很高兴得以来此向诸位讲话。 英语对照： 转载自 http://blog.sina.com.cn/s/blog_65da5f5b0101doa2.html - by 背包走天涯的博客 Good evening. I have come to Jerusalem today as a novelist, which is to say as a professional spinner of lies. Of course, novelists are not the only ones who tell lies. Politicians do it, too, as we all know. Diplomats and generals tell their own kinds of lies on occasion, as do used car salesmen, butchers and builders. The lies of novelists differ from others, however, in that no one criticizes the novelist as immoral for telling lies. Indeed, the bigger and better his lies and the more ingeniously he creates them, the more he is likely to be praised by the public and the critics. Why should that be? My answer would be this: namely, that by telling skilful lies–which is to say, by making up fictions that appear to be true–the novelist can bring a truth out to a new place and shine a new light on it. In most cases, it is virtually impossible to grasp a truth in its original form and depict it accurately. This is why we try to grab its tail by luring the truth from its hiding place, transferring it to a fictional location, and replacing it with a fictional form. In order to accomplish this, however, we first have to clarify where the truth-lies within us, within ourselves. This is an important qualification for making up good lies. Today, however, I have no intention of lying. I will try to be as honest as I can. There are only a few days in the year when I do not engage in telling lies, and today happens to be one of them. So let me tell you the truth. In Japan a fair number of people advised me not to come here to accept the Jerusalem Prize. Some even warned me they would instigate a boycott of my books if I came. The reason for this, of course, was the fierce fighting that was raging in Gaza. The U.N. reported that more than a thousand people had lost their lives in the blockaded city of Gaza, many of them unarmed citizens–children and old people. Any number of times after receiving notice of the award, I asked myself whether traveling to Israel at a time like this and accepting a literary prize was the proper thing to do, whether this would create the impression that I supported one side in the conflict, that I endorsed the policies of a nation that chose to unleash its overwhelming military power. Neither, of course, do I wish to see my books subjected to a boycott. Finally, however, after careful consideration, I made up my mind to come here. One reason for my decision was that all too many people advised me not to do it. Perhaps, like many other novelists, I tend to do the exact opposite of what I am told. If people are telling me– and especially if they are warning me– “Don’t go there,” “Don’t do that,” I tend to want to “go there” and “do that”。 It’s in my nature, you might say, as a novelist. Novelists are a special breed. They cannot genuinely trust anything they have not seen with their own eyes or touched with their own hands. And that is why I am here. I chose to come here rather than stay away. I chose to see for myself rather than not to see. I chose to speak to you rather than to say nothing. Please do allow me to deliver a message, one very personal message. It is something that I always keep in mind while I am writing fiction. I have never gone so far as to write it on a piece of paper and paste it to the wall: rather, it is carved into the wall of my mind, and it goes something like this: “Between a high, solid wall and an egg that breaks against it, I will always stand on the side of the egg.” Yes, no matter how right the wall may be and how wrong the egg, I will stand with the egg. Someone else will have to decide what is right and what is wrong; perhaps time or history will do it. But if there were a novelist who, for whatever reason, wrote works standing with the wall, of what value would such works be? What is the meaning of this metaphor? In some cases, it is all too simple and clear. Bombers and tanks and rockets and white phosphorus shells are that high wall. The eggs are the unarmed civilians who are crushed and burned and shot by them. This is one meaning of the metaphor. But this is not all. It carries a deeper meaning. Think of it this way. Each of us is, more or less, an egg. Each of us is a unique, irreplaceable soul enclosed in a fragile shell. This is true of me, and it is true of each of you. And each of us, to a greater or lesser degree, is confronting a high, solid wall. The wall has a name: it is “The System.” The System is supposed to protect us, but sometimes it takes on a life of its own, and then it begins to kill us and cause us to kill others–coldly, efficiently, systematically. I have only one reason to write novels, and that is to bring the dignity of the individual soul to the surface and shine a light upon it. The purpose of a story is to sound an alarm, to keep a light trained on the System in order to prevent it from tangling our souls in its web and demeaning them. I truly believe it is the novelist’s job to keep trying to clarify the uniqueness of each individual soul by writing stories–stories of life and death, stories of love, stories that make people cry and quake with fear and shake with laughter. This is why we go on, day after day, concocting fictions with utter seriousness. My father passed away last year at the age of ninety. He was a retired teacher and a part-time Buddhist priest. When he was in graduate school in Kyoto, he was drafted into the army and sent to fight in China. As a child born after the war, I used to see him every morning before breakfast offering up long, deeply-felt prayers at the small Buddhist altar in our house. One time I asked him why he did this, and he told me he was praying for the people who had died in the battlefield. He was praying for all the people who died, he said, both ally and enemy alike. Staring at his back as he knelt at the altar, I seemed to feel the shadow of death hovering around him. My father died, and with him he took his memories, memories that I can never know. But the presence of death that lurked about him remains in my own memory. It is one of the few things I carry on from him, and one of the most important. I have only one thing I hope to convey to you today. We are all human beings, individuals transcending nationality and race and religion, and we are all fragile eggs faced with a solid wall called The System. To all appearances, we have no hope of winning. The wall is too high, too strong–and too cold. If we have any hope of victory at all, it will have to come from our believing in the utter uniqueness and irreplaceability of our own and others’ souls and from our believing in the warmth we gain by joining souls together. Take a moment to think about this. Each of us possesses a tangible, living soul. The System has no such thing. We must not allow the System to exploit us. We must not allow the System to take on a life of its own. The System did not make us: we made the System. That is all I have to say to you. I am grateful to have been awarded the Jerusalem Prize. I am grateful that my books are being read by people in many parts of the world. And I would like to express my gratitude to the readers in Israel. You are the biggest reason why I am here. And I hope we are sharing something, something very meaningful. And I am glad to have had the opportunity to speak to you here today. Thank you very much.]]></content>
      <categories>
        <category>呓语</category>
      </categories>
      <tags>
        <tag>村上春树</tag>
        <tag>高墙与鸡蛋</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于死亡，关于宗教]]></title>
    <url>%2F2018%2F01%2F10%2FDeath_and_religion%2F</url>
    <content type="text"><![CDATA[关于死亡，关于宗教 2018-01-15 17:57:44科学是工具类，宗教是抽象类？？？两者不冲突，哈哈 很早就想写这个题目了，，可是，这个题目好像离自己又很远，年纪轻轻这个题目又能写多深呢？但，，2017年，真的有很多事情都跟死扯上了关系，又留下巨深的印象。以至于，2017年的关键词不是网易云的『等待』，也不是支付宝的『旺』，，死亡。 Chapter Ⅰ.完整的人生大概是年初的时候吧，跟周婶儿、姜老师和阿松去龙泉寺，，下山的时候不知怎么就聊到了人生和理想，亦聊到了死亡。婶儿说，，人这一辈子是不完整的，只经历了活着，没有经历死亡。就像完整的一天有白天和黑夜，但是我们出生之后只经历了黎明、白天和傍晚，，黎明和傍晚又似是无意识的，那么傍晚之后的黑夜呢？？ 深以为然，，如此，反而突然对死亡变得好奇起来，甚至有些『盼望』，迫切地想知道死亡是怎样一回事。把『人生』和『人死』两块图拼起来，岂不是圆满了？再也不害怕死亡了，，白天的太阳看腻了，晚上的星星月亮是蛮不错的~ Chapter Ⅱ.Nothing at all再后来，，国庆的时候，想来一周的时间该怎么在家消磨？于是开始刷『权利的游戏』，加上节后以后周末的时间，，七季全刷完了。其实，前五季的确是『权利的游戏』，之后便是『冰与火之歌』了。给我留下印象极深的便是第六季第二集，雪诺被红袍女复活，雪诺醒后，， 权游-雪诺复活 雪诺- I shouldn’t be here. #我不该在这里的。 洋葱骑士-The lady brought you back. #这位女士复活了你。 红袍女-Afterwards, after they stabbed you, after you died, where did you go? What did you see? #在他们刺伤你之后，在你死之后，你去了哪里？你看到了什么？ 雪诺-Nothing. There was nothing at all. #什么都没，根本什么都没有。 看到这儿的时候，我的内心是奔溃的，，宕机的那种！我满心期待的死亡，居然什么都没有？！Nothing at all！！！我想要的是死亡，不是暂停！我的世界突然变成灰色了。。只剩失望 Chapter Ⅲ.相亲相爱Sherry推荐张艾嘉的『相亲相爱』，，光听名字，这电影不招人待见，最喜欢的还是科幻片。。但是有Sherry的口碑，我对她的taste也有信心，也知道自己以名取影是狭隘的。…..总是盯着进度条看，，不过瘾，为什么不拍得再长一点？！从阿达征得阿祖的同意后，躺进棺材，突然就哽咽了，，这种情绪来得太突然，始料未及。我也绷不住了，，哭得像傻哔一样。 其实，这部电影，死亡不是主题，，只不过这个镜头，阿达突如其来的哽咽，shocked。 Chapter Ⅳ.一定有另一个世界12月30号元旦放假，回老家，，爷爷还是躺在床上。 我和哥哥，还有表弟一块，，其实，大家心里都明白，爷爷身体每况愈下，怕是时间不多了。姑姑也在老家陪床。中午炒了几个家常菜，我不喜欢喝酒，尤其是白酒，，便没有参与。留老爷子自己在床上，，以前都是一块，看着他，我也很无助。我去拿了个鹌鹑蛋，给他剥开皮，，喂他吃了。递到嘴边就张开嘴了，还是认食儿，，这种状态，欣慰。不过，，也可能是蛋黄的原因，也可能是嗓子比较干，他有点咳。我赶紧调的温水，用很浅的勺子喂他，，又不敢直接喂在嘴里，便用勺子贴着下嘴唇，以牙齿引流。喂了几勺，，我觉得应该可以把蛋黄冲下去了。但还咳，，咳得的次数多了，大概明白了，呼吸肌无力，已经没力气咳嗽了。。开始用力呼吸，声音很大，隔壁房间都可以听到。听姑姑说了，这才知道老爷子从昨晚开始就不怎么吃东西了，早上还吐了，，顿时我感觉自己闯祸了。这时候，老爷子呼吸开始缓下来了，平静了很多，，就是总扯被子。我有点无措，问姑姑，，爷爷已经不能说话了，，姑姑也不知道该怎么办了，掀开被子，摸摸爷爷身上，，除了很多汗，但是不至于热成这样这样啊。我摸摸爷爷的额头，没有发烧。其实，爷爷看上去，气色还是不错的，就是瘦了点，太瘦了。之前帮姑姑给爷爷换尿布的时候，我无法描述我看到了怎样一副躯体，，换好之后，背过去，用力憋着，尽量不哭出声音。 吃过午饭后，，我回趟家，想着准备些微信小程序的开发资料，然后回爷爷这边，守着他，无聊的时候打发下时间。我以为这次会像往常一样，，不会有事的。/**以下内容，可能涉及描述人的临终状态，，慎读预警**/ 再回爷爷这边的时候，，奶奶、姑姑、叔叔都在房间里，都在紧张的盯着爷爷。盯着，让人感觉不舒服的盯着，但此时除了盯着，好像其余也无能为力。爷爷的呼吸很有节奏，，但是在用嘴巴呼吸，张着嘴，眼睛半睁半闭。不知道是想睁着，还是想闭着。他的每一次呼吸，都是呼气长，吸气短，，呼气和吸气之间还会有很短的停顿。这个停顿着实让人揪心，，我也开始盯着。婶婶开始给两个堂弟打电话，让他们回家，，妈妈也打了电话让爸爸回来。三爷家的姑姑也来了，开始给族里话事的伯伯打电话。。我们几个还在盯着，，突然，爷爷的呼吸幅度明显小了，，像运动过后喘着的粗气突然平静下来了。呼气和吸气之间的停顿也变长了。这种感觉很不好，，姑姑看看了爷爷的眼睛，瞳孔明显散了，颜色也浅了，浅灰色。用手指以很近的距离在爷爷眼前晃也不眨眼了。这个时候，呼吸已经变成纯生理性了，大概已经没有意识了，，不知道此时对 爷爷 来说，这到底是怎样一种状态，游离么？慢慢，，坍缩了，爷爷不张嘴了，眼睛向上翻了一下。。此时，我就站在床边，用平生最大的力气憋着，背过去，还是失声了！ 我幻想过很多次亲人去世时的场景，每次想都会怕，，我怕他们离世后，我不敢再靠近他们。但此时此刻，一点点怕的感觉都没有，，很亲。爷爷离世前一直用嘴呼吸，离世后嘴巴还是张着，大人说得趁爷爷的身体还热着，姑姑托着爷爷的下巴，帮他把嘴巴合上。屋里开始有人忙活了，蒙镜子，门口放碗水，准备给爷爷擦洗身子，穿寿衣。爷爷的脸上盖上了白毛巾，姑姑忙不过来，我隔着毛巾托着爷爷的下巴，跪在床头痛哭。。 我又想到雪诺说的 Nothing at all，我希望他说的是错的。我希望真的有另外一个世界，我希望有一天我可以在那里再见到爷爷。突然间，，我好像明白宗教为什么存在了。受唯物主义的影响，我一直觉得宗教是狭隘的，反智的，荒谬的。但是，宗教描述了人死亡后的世界，让人们面对死别时能够得到宽慰，，还有天堂，还有来世！我们还会再见！我们并没有永远的分开。。宗教很大一部分是用来解答人们对身后事的疑惑的，给现世的人重生重逢的希望！科学？科学不可以。。从这一方面讲，科学好像跟宗教不冲突，反而互相补充。 在雪诺复活以前，，我从没认真想过有没有 Nothing at all 的情况，因为三大宗教都有对身后事的描述，佛教有六道轮回，基督有天堂地狱，伊斯兰有信后世。Nothing at all 一定是个BUG。]]></content>
      <categories>
        <category>呓语</category>
      </categories>
      <tags>
        <tag>死亡</tag>
        <tag>宗教</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[普鲁斯特问卷-2017]]></title>
    <url>%2F2018%2F01%2F02%2FProustQA_2017%2F</url>
    <content type="text"><![CDATA[普鲁斯特问卷-2017这份问卷本应该在2017-12-31完成，但赶上，，到底有没有另一个世界？安好，， 你认为最完美的快乐是怎样的？见到最想见的人，如果能有个拥抱就更好了~ 你最希望拥有哪种才华？把问题抽象成数学模型，再转化为编程语言~ 你最恐惧的是什么？时光飞逝.. 你目前的心境怎样？有点困，不想睡觉，还有点浮躁，，想赶紧学好微信的小程序 还在世的人中你最钦佩的是谁？埃隆马斯克吧，虽然他不是程序员 你认为自己最伟大的成就是什么？有么？ 你自己的哪个特点让你最觉得痛恨？怂？我希望自己能够坚定更一点。 你最喜欢的旅行是哪一次？大三暑假从哈尔滨搭车去满洲里 你最痛恨别人的什么特点？站着说话不腰疼，， 你最珍惜的财产是什么？『信』，，言而有信的信 你最奢侈的是什么？现在拥有的一切都挺奢侈的 你认为程度最浅的痛苦是什么？口腔溃疡？ 你认为哪种美德是被过高的评估的？『传统美德』 你最喜欢的职业是什么？我现在在做的工作–程序员 你对自己的外表哪一点不满意？脸左右不对称！！！ 你最后悔的事情是什么？大学以前对计算机的了解太狭隘 还在世的人中你最鄙视的是谁？标题档，傻哔标题档，，以及一切恶意带节奏的媒体工作者！！！ 你最喜欢男性身上的什么品质？慷慨 你使用过的最多的单词或者是词语是什么？Enjoy 你最喜欢女性身上的什么品质？优雅 你最伤痛的事是什么？失恋吧，，由最亲爱的人变成最不耐烦的人 你最看重朋友的什么特点？『信』 你这一生中最爱的人或东西是什么？到目前为止，，应该是苹果电脑吧 你希望以什么样的方式死去？猝死？也可以是安乐死，，不要太狰狞 何时何地让你感觉到最快乐？午后睡醒，一杯热咖啡，，听着网易云敲代码 如果你可以改变你的家庭一件事，那会是什么？不要让贫穷限制我们的想象力 如果你能选择的话，你希望让什么重现？希望姑父和爷爷没有生病，，健康重现 你的座右铭是什么？奋力无悔，尽力无愧，，经历过就是财富！高中时的]]></content>
      <categories>
        <category>ProustQA</category>
      </categories>
      <tags>
        <tag>普鲁斯特问卷</tag>
        <tag>2017</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Javascript面向对象编程(三):非构造函数的继承]]></title>
    <url>%2F2017%2F12%2F23%2Fjavascript_oop-inheritance_of_non-constructor%2F</url>
    <content type="text"><![CDATA[Javascript面向对象编程（三）：非构造函数的继承这个系列的第一部分介绍了”封装”，第二部分介绍了使用构造函数实现”继承”。今天是最后一个部分，介绍不使用构造函数实现”继承”。 一、什么是”非构造函数”的继承？比如，现在有一个对象，叫做”中国人”：123var Chinese = &#123; nation:'中国'&#125;; 还有一个对象，叫做”医生”：123var Doctor =&#123; career:'医生'&#125; 请问怎样才能让”医生”去继承”中国人”，也就是说，我怎样才能生成一个”中国医生”的对象？这里要注意，这两个对象都是普通对象，不是构造函数，无法使用构造函数方法实现”继承”。 二、object()方法json格式的发明人Douglas Crockford，提出了一个object()函数，可以做到这一点。12345function object(o) &#123; function F() &#123;&#125; F.prototype = o; return new F();&#125; 这个object()函数，其实只做一件事，就是把子对象的prototype属性，指向父对象，从而使得子对象与父对象连在一起。使用的时候，第一步先在父对象的基础上，生成子对象，然后，再加上子对象本身的属性，这时，子对象已经继承了父对象的属性了：👇123var Doctor = object(Chinese);Doctor.career = '医生';alert(Doctor.nation); //中国 三、浅拷贝除了使用”prototype链”以外，还有另一种思路：把父对象的属性，全部拷贝给子对象，也能实现继承。下面这个函数，就是在做拷贝：12345678function extendCopy(p) &#123; var c = &#123;&#125;; for (var i in p) &#123; c[i] = p[i]; &#125; c.uber = p; return c;&#125; 使用的时候，这样写：👇123var Doctor = extendCopy(Chinese);Doctor.career = '医生';alert(Doctor.nation); // 中国 但是，这样的拷贝有一个问题。那就是，如果父对象的属性等于数组或另一个对象，那么实际上，子对象获得的只是一个内存地址，而不是真正拷贝，因此存在父对象被篡改的可能。请看，现在给Chinese添加一个”出生地”属性，它的值是一个数组，通过extendCopy()函数，Doctor继承了Chinese。然后，我们为Doctor的”出生地”添加一个城市，然后，我们为Doctor的”出生地”添加一个城市：123456Chinese.birthPlaces = ['北京','上海','香港'];var Doctor = extendCopy(Chinese);Doctor.birthPlaces.push('厦门');alert(Doctor.birthPlaces); //北京, 上海, 香港, 厦门alert(Chinese.birthPlaces); //北京, 上海, 香港, 厦门 👆发生了什么事？Chinese的”出生地”也被改掉了！ 所以，extendCopy()只是拷贝基本类型的数据，我们把这种拷贝叫做”浅拷贝”。这是早期jQuery实现继承的方式。 四、深拷贝所谓”深拷贝”，就是能够实现真正意义上的数组和对象的拷贝。它的实现并不难，只要递归调用”浅拷贝”就行了。123456789101112function deepCopy(p, c) &#123; var c = c || &#123;&#125;; for (var i in p) &#123; if (typeof p[i] === 'object') &#123; c[i] = (p[i].constructor === Array) ? [] : &#123;&#125;; deepCopy(p[i], c[i]); &#125; else &#123; c[i] = p[i]; &#125; &#125; return c;&#125; 使用的时候这样写，给父对象加一个属性，值为数组。然后，在子对象上修改这个属性，这时，父对象就不会受到影响了。12345var Doctor = deepCopy(Chinese);Chinese.birthPlaces = ['北京','上海','香港'];Doctor.birthPlaces.push('厦门');alert(Doctor.birthPlaces); //北京, 上海, 香港, 厦门alert(Chinese.birthPlaces); //北京, 上海, 香港 目前，jQuery库使用的就是这种继承方法。（完）]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Javascript面向对象编程(二):构造函数的继承]]></title>
    <url>%2F2017%2F12%2F23%2Fjavascript_oop-inheritance_of_constructor%2F</url>
    <content type="text"><![CDATA[Javascript面向对象编程（二）：构造函数的继承 转载自Javascript面向对象编程（二）：构造函数的继承 - by 阮一峰 这个系列的第一部分，主要介绍了如何“封装”数据和方法，以及如何从原型对象生成实例。今天要介绍的是，对象之间的“继承”的五种方法。比如，现在有一个“动物”👇对象的构造函数：123function Animal()&#123; this.species = "动物";&#125; 还有一个“猫”👇对象的构造函数：1234function Cat(name,color)&#123; this.name = name; this.color = color;&#125; 怎样才能使“猫”继承“动物”呢？ 一、 构造函数绑定第一种方法也是最简单的方法，使用call或apply方法，将父对象的构造函数绑定在子对象上，即在子对象构造函数中加一行：1234567function Cat(name,color)&#123; Animal.apply(this, arguments); this.name = name; this.color = color;&#125;var cat1 = new Cat("大毛","黄色");alert(cat1.species); // 动物 二、 prototype模式第二种方法更常见，使用prototype属性。如果“猫”的prototype对象，指向一个Animal的实例，那么所有”猫”的实例，就能继承Animal了。1234Cat.prototype = new Animal();Cat.prototype.constructor = Cat;var cat1 = new Cat("大毛","黄色");alert(cat1.species); // 动物 代码的第一行，我们将Cat的prototype对象指向一个Animal的实例。它相当于完全删除了prototype对象原先的值，然后赋予一个新值。但是，第二行又是什么意思呢？原来，任何一个prototype对象都有一个constructor属性，指向它的构造函数。如果没有Cat.prototype = new Animal();这一行，Cat.prototype.constructor是指向Cat的；加了这一行以后，Cat.prototype.constructor指向Animal。每一个实例也有一个constructor属性，默认调用prototype对象的constructor属性。因此，在运行&quot;Cat.prototype = new Animal();&quot;这一行之后，cat1.constructor也指向Animal(如果没有第二行代码)！这显然会导致继承链的紊乱（cat1明明是用构造函数Cat生成的），因此我们必须手动纠正，将Cat.prototype对象的constructor值改为Cat。这就是第二行的意思。这是很重要的一点，编程时务必要遵守。下文都遵循这一点，即如果替换了prototype对象,那么，下一步必然是为新的prototype对象加上constructor属性，并将这个属性指回原来的构造函数。12o.prototype = &#123;&#125;;o.prototype.constructor = o; 三、 直接继承prototype第三种方法是对第二种方法的改进。由于Animal对象中，不变的属性都可以直接写入Animal.prototype。所以，我们也可以让Cat()跳过 Animal()，直接继承Animal.prototype。现在，我们先将Animal对象改写：12function Animal()&#123; &#125;Animal.prototype.species = "动物"; 然后，将Cat的prototype对象，然后指向Animal的prototype对象，这样就完成了继承。👇1234Cat.prototype = Animal.prototype;Cat.prototype.constructor = Cat;var cat1 = new Cat("大毛","黄色");alert(cat1.species); // 动物 与前一种方法相比，这样做的优点是效率比较高（不用执行和建立Animal的实例了），比较省内存。缺点是 Cat.prototype和Animal.prototype现在指向了同一个对象，那么任何对Cat.prototype的修改，都会反映到Animal.prototype。所以，上面这一段代码其实是有问题的，，请看第二行👆。这一句实际上把Animal.prototype对象的constructor属性也改掉了！1alert(Animal.prototype.constructor); // Cat 四、 利用空对象作为中介由于”直接继承prototype”存在上述的缺点，所以就有第四种方法，利用一个空对象作为中介：👇1234var F = function()&#123;&#125;;F.prototype = Animal.prototype;Cat.prototype = new F();Cat.prototype.constructor = Cat; F是空对象，所以几乎不占内存。这时，修改Cat的prototype对象，就不会影响到Animal的prototype对象。1alert(Animal.prototype.constructor); // Animal 我们将上面的方法，封装成一个函数，便于使用。1234567function extend(Child, Parent) &#123; var F = function()&#123;&#125;; F.prototype = Parent.prototype; Child.prototype = new F(); Child.prototype.constructor = Child; Child.uber = Parent.prototype;&#125; 使用的时候，方法如下:👇123extend(Cat,Animal);var cat1 = new Cat("大毛","黄色");alert(cat1.species); // 动物 这个extend函数，就是YUI库如何实现继承的方法。 另外，说明一点，函数体最后一行Child.uber = Parent.prototype;意思是为子对象设一个uber属性，这个属性直接指向父对象的prototype属性。（uber是一个德语词，意思是”向上”、”上一层”。）这等于在子对象上打开一条通道，可以直接调用父对象的方法。这一行放在这里，只是为了实现继承的完备性，纯属备用性质。 五、 拷贝继承上面是采用prototype对象，实现继承。我们也可以换一种思路，纯粹采用”拷贝”方法实现继承。简单说，如果把父对象的所有属性和方法，拷贝进子对象，不也能够实现继承吗？这样我们就有了第五种方法。 首先，还是把Animal的所有不变属性，都放到它的prototype对象上。12function Animal()&#123;&#125;Animal.prototype.species = "动物"; 然后，再写一个函数，实现属性拷贝的目的：👇12345678function extend2(Child, Parent) &#123; var p = Parent.prototype; var c = Child.prototype; for (var i in p) &#123; c[i] = p[i]; &#125; c.uber = p;&#125; 这个函数的作用，就是将父对象的prototype对象中的属性，一一拷贝给Child对象的prototype对象。使用的时候，这样写：123extend2(Cat, Animal);var cat1 = new Cat("大毛","黄色");alert(cat1.species); // 动物 本系列未完，请继续阅读第三部分《非构造函数的继承》。（完） 在 二、 prototype模式 第三段中删除了示例代码，当初读的时候上下语义之间有些割裂，理解起来有点麻烦。。 在 五、 拷贝继承 extend2函数中，for循环中的代码c[i] = p[i];是采用了json格式的调用了对象的方法，与平时我们一般习惯中的instance.method效果一样。]]></content>
      <tags>
        <tag>前端</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析MySQL中exists与in的使用]]></title>
    <url>%2F2017%2F12%2F19%2Fexists-and-in_in_MySQL%2F</url>
    <content type="text"><![CDATA[浅析MySQL中exists与in的使用 转载自 浅析MySQL中exists与in的使用 - by Franklin existsexists对外表用loop逐条查询，每次查询都会查看exists的条件语句，当exists里的条件语句能够返回记录行时(无论记录行是的多少，只要能返回)，条件就为真，返回当前loop到的这条记录;反之如果exists里的条 件语句不能返回记录行，则当前loop到的这条记录被丢弃，exists的条件就像一个bool条件，当能返回结果集则为true，不能返回结果集则为 false 如下：👇1select * from user where exists (select 1); 对user表的记录逐条取出，由于子条件中的select 1永远能返回记录行，那么user表的所有记录都将被加入结果集，所以与 select * from user;是一样的。 又如下👇1select * from user where exists (select * from user where userId = 0); 可以知道对user表进行loop时，检查条件语句(select * from user where userId = 0),由于userId永远不为0[^1]，所以条件语句永远返回空集，条件永远为false，那么user表的所有记录都将被丢弃。 not exists与exists相反，也就是当exists条件有结果集返回时，loop到的记录将被丢弃，否则将loop到的记录加入结果集。 总的来说，如果A表有n条记录，那么exists查询就是将这n条记录逐条取出，然后判断n遍exists条件。 inin查询相当于多个or条件的叠加，这个比较好理解，比如下面的查询👇1234select * from user where userId in (1, 2, 3);等效于👇select * from user where userId = 1 or userId = 2 or userId = 3; not in与in相反，如下1234select * from user where userId not in (1, 2, 3);等效于👇select * from user where userId != 1 and userId != 2 and userId != 3; 总的来说，in查询就是先将子查询条件的记录全都查出来，假设结果集为B，共有m条记录，然后在将子查询条件的结果集分解成m个，再进行m次查询。 值得一提的是，in查询的子条件返回结果必须只有一个字段，例如1select * from user where userId in (select id from B); 而不能是1select * from user where userId in (select id, age from B); 而exists就没有这个限制。 exists和in的性能考虑如下SQL语句:👇1231: select * from A where exists (select * from B where B.id = A.id);2: select * from A where A.id in (select id from B); 查询1.可以转化以下伪代码，便于理解👇1234567for ($i = 0; $i &lt; count(A); $i++) &#123; $a = get_record(A, $i); #从A表逐条获取记录 if (B.id = $a[id])&#123; #如果子条件成立 $result[] = $a; &#125;&#125;return $result; 大概就是这么个意思，其实可以看到,查询1主要是用到了B表的索引，A表如何对查询的效率影响应该不大。 假设B表的所有id为1,2,3,查询2可以转换为👇1select * from A where A.id = 1 or A.id = 2 or A.id = 3; 这个好理解了，这里主要是用到了A的索引，B表如何对查询影响不大。 下面再看not exists 和 not in1231. select * from A where not exists (select * from B where B.id = A.id);2. select * from A where A.id not in (select id from B); 看查询1，还是和上面一样，用了B的索引。而对于查询2，可以转化成如下语句👇1select * from A where A.id != 1 and A.id != 2 and A.id != 3; 可以知道not in是个范围查询，这种!=的范围查询无法使用任何索引,等于说A表的每条记录，都要在B表里遍历一次，查看B表里是否存在这条记录,故not exists比not in效率高。 mysql中的in语句是把外表和内表作hash连接，而exists语句是对外表作loop循环，每次loop循环再对内表进行查询。一直大家都认为exists比in语句的效率要高，这种说法其实是不准确的。这个是要区分环境的。 如果查询的两个表大小相当，那么用in和exists差别不大; 如果两个表中一个较小，一个是大表，则子查询表大的用exists，子查询表小的用in:例如：表A（小表），表B（大表）1234567891011# 效率低，用到了A表上cc列的索引；select * from A where cc in (select cc from B);# 效率高，用到了B表上cc列的索引;select * from A where exists(select cc from B where cc=A.cc);# 效率高，用到了B表上cc列的索引； select * from B where cc in (select cc from A);# 效率低，用到了A表上cc列的索引。select * from B where exists(select cc from A where cc=B.cc); not in和not exists如果查询语句使用了not in那么内外表都进行全表扫描，没有用到索引；而not extsts的子查询依然能用到表上的索引。所以无论哪个表大，用not exists都比not in要快。 in与=的区别1234select name from student where name in ('zhang','wang','li','zhao');等效于👇select name from student where name='zhang' or name='li' or name='wang' or name='zhao'; [^1]: 其实user_id是可以为0的。在 Mysql sql_mode 中 添加 NO_AUTO_VALUE_ON_ZERO。]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>数据库</tag>
        <tag>exist</tag>
        <tag>in</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL逻辑查询语句执行顺序]]></title>
    <url>%2F2017%2F12%2F19%2Fexecution_sequence_of_sql%2F</url>
    <content type="text"><![CDATA[SQL逻辑查询语句执行顺序 转载自 SQL逻辑查询语句执行顺序 - by 果冻想 测试表结构：👇12345678910111213CREATE TABLE table1 ( customer_id VARCHAR(10) NOT NULL, city VARCHAR(10) NOT NULL, PRIMARY KEY(customer_id) )ENGINE=INNODB DEFAULT CHARSET=UTF8; CREATE TABLE table2 ( order_id INT NOT NULL auto_increment, customer_id VARCHAR(10), PRIMARY KEY(order_id) )ENGINE=INNODB DEFAULT CHARSET=UTF8; 测试数据：👇123456789101112INSERT INTO table1(customer_id,city) VALUES('163','hangzhou'); INSERT INTO table1(customer_id,city) VALUES('9you','shanghai'); INSERT INTO table1(customer_id,city) VALUES('tx','hangzhou'); INSERT INTO table1(customer_id,city) VALUES('baidu','hangzhou'); INSERT INTO table2(customer_id) VALUES('163'); INSERT INTO table2(customer_id) VALUES('163'); INSERT INTO table2(customer_id) VALUES('9you'); INSERT INTO table2(customer_id) VALUES('9you'); INSERT INTO table2(customer_id) VALUES('9you'); INSERT INTO table2(customer_id) VALUES('tx'); INSERT INTO table2(customer_id) VALUES(NULL); SQL逻辑查询测试语句👇123456789#使用上述SQL查询语句来获得来自杭州，并且订单数少于2的客户。SELECT a.customer_id, COUNT(b.order_id) as total_orders FROM table1 AS a LEFT JOIN table2 AS b ON a.customer_id = b.customer_id WHERE a.city = 'hangzhou' GROUP BY a.customer_id HAVING count(b.order_id) &lt; 2 ORDER BY total_orders DESC; SQL逻辑查询语句执行顺序12345678910(7) SELECT (8) DISTINCT &lt;select_list&gt;(1) FROM &lt;left_table&gt;(3) &lt;join_type&gt; JOIN &lt;right_table&gt;(2) ON &lt;join_condition&gt;(4) WHERE &lt;where_condition&gt;(5) GROUP BY &lt;group_by_list&gt;(6) HAVING &lt;having_condition&gt;(9) ORDER BY &lt;order_by_condition&gt;(10) LIMIT &lt;limit_number&gt; 👆上面在每条语句的前面都标明了执行顺序号，不要问我怎么知道这个顺序的。我也是读各种“武林秘籍”才得知的，如果你有功夫，去阅读一下MySQL的源码，也会得出这个结果的。 好了，上面我标出了各条查询规则的执行先后顺序，那么各条查询语句是如何执行的呢？这就是我今天这篇博文的重点内容。Go on… 执行FROM语句在这些SQL语句的执行过程中，都会产生一个虚拟表，用来保存SQL语句的执行结果（这是重点），我现在就来跟踪这个虚拟表的变化，得到最终的查询结果的过程，来分析整个SQL逻辑查询的执行顺序和过程。 第一步，执行FROM语句。我们首先需要知道最开始从哪个表开始的，这就是FROM告诉我们的。现在有了&lt;left_table&gt;和&lt;right_table&gt;两个表，我们到底从哪个表开始，还是从两个表进行某种联系以后再开始呢？它们之间如何产生联系呢？——笛卡尔积 关于什么是笛卡尔积，请自行Google补脑。经过FROM语句对两个表执行笛卡尔积，会得到一个虚拟表，暂且叫VT1（vitual table 1），内容如下：👇1234567891011121314151617181920212223242526272829303132+-------------+----------+----------+-------------+| customer_id | city | order_id | customer_id |+-------------+----------+----------+-------------+| 163 | hangzhou | 1 | 163 || 9you | shanghai | 1 | 163 || baidu | hangzhou | 1 | 163 || tx | hangzhou | 1 | 163 || 163 | hangzhou | 2 | 163 || 9you | shanghai | 2 | 163 || baidu | hangzhou | 2 | 163 || tx | hangzhou | 2 | 163 || 163 | hangzhou | 3 | 9you || 9you | shanghai | 3 | 9you || baidu | hangzhou | 3 | 9you || tx | hangzhou | 3 | 9you || 163 | hangzhou | 4 | 9you || 9you | shanghai | 4 | 9you || baidu | hangzhou | 4 | 9you || tx | hangzhou | 4 | 9you || 163 | hangzhou | 5 | 9you || 9you | shanghai | 5 | 9you || baidu | hangzhou | 5 | 9you || tx | hangzhou | 5 | 9you || 163 | hangzhou | 6 | tx || 9you | shanghai | 6 | tx || baidu | hangzhou | 6 | tx || tx | hangzhou | 6 | tx || 163 | hangzhou | 7 | NULL || 9you | shanghai | 7 | NULL || baidu | hangzhou | 7 | NULL || tx | hangzhou | 7 | NULL |+-------------+----------+----------+-------------+ 总共有28（table1的记录条数 * table2的记录条数）条记录。这就是VT1👆的结果，接下来的操作就在VT1👆的基础上进行。 执行ON过滤执行完笛卡尔积以后，接着就进行ON a.customer_id = b.customer_id条件过滤，根据ON中指定的条件，去掉那些不符合条件的数据，得到VT2表👇，内容如下：12345678910+-------------+----------+----------+-------------+| customer_id | city | order_id | customer_id |+-------------+----------+----------+-------------+| 163 | hangzhou | 1 | 163 || 163 | hangzhou | 2 | 163 || 9you | shanghai | 3 | 9you || 9you | shanghai | 4 | 9you || 9you | shanghai | 5 | 9you || tx | hangzhou | 6 | tx |+-------------+----------+----------+-------------+ 👆VT2就是经过ON条件筛选以后得到的有用数据，而接下来的操作将在VT2👆的基础上继续进行。 添加外部行这一步只有在连接类型为OUTER JOIN时才发生，如LEFT OUTER JOIN、RIGHT OUTER JOIN和FULL OUTER JOIN。在大多数的时候，我们都是会省略掉OUTER关键字的，但OUTER表示的就是外部行的概念。 LEFT OUTER JOIN把左表记为保留表，得到的结果为：👇1234567891011+-------------+----------+----------+-------------+| customer_id | city | order_id | customer_id |+-------------+----------+----------+-------------+| 163 | hangzhou | 1 | 163 || 163 | hangzhou | 2 | 163 || 9you | shanghai | 3 | 9you || 9you | shanghai | 4 | 9you || 9you | shanghai | 5 | 9you || tx | hangzhou | 6 | tx || baidu | hangzhou | NULL | NULL |+-------------+----------+----------+-------------+ RIGHT OUTER JOIN把右表记为保留表，得到的结果为：👇1234567891011+-------------+----------+----------+-------------+| customer_id | city | order_id | customer_id |+-------------+----------+----------+-------------+| 163 | hangzhou | 1 | 163 || 163 | hangzhou | 2 | 163 || 9you | shanghai | 3 | 9you || 9you | shanghai | 4 | 9you || 9you | shanghai | 5 | 9you || tx | hangzhou | 6 | tx || NULL | NULL | 7 | NULL |+-------------+----------+----------+-------------+ FULL OUTER JOIN把左右表都作为保留表，得到的结果为：👇123456789101112+-------------+----------+----------+-------------+| customer_id | city | order_id | customer_id |+-------------+----------+----------+-------------+| 163 | hangzhou | 1 | 163 || 163 | hangzhou | 2 | 163 || 9you | shanghai | 3 | 9you || 9you | shanghai | 4 | 9you || 9you | shanghai | 5 | 9you || tx | hangzhou | 6 | tx || baidu | hangzhou | NULL | NULL || NULL | NULL | 7 | NULL |+-------------+----------+----------+-------------+ 添加外部行的工作就是在VT2表的基础上添加保留表中被过滤条件过滤掉的数据，非保留表中的数据被赋予NULL值，最后生成虚拟表VT3。 由于我在准备的测试SQL查询逻辑语句中使用的是LEFT JOIN，过滤掉了以下这条数据：👇1| baidu | hangzhou | NULL | NULL | 现在就把这条数据添加到VT2表中，得到的VT3表如下：👇1234567891011+-------------+----------+----------+-------------+| customer_id | city | order_id | customer_id |+-------------+----------+----------+-------------+| 163 | hangzhou | 1 | 163 || 163 | hangzhou | 2 | 163 || 9you | shanghai | 3 | 9you || 9you | shanghai | 4 | 9you || 9you | shanghai | 5 | 9you || tx | hangzhou | 6 | tx || baidu | hangzhou | NULL | NULL |+-------------+----------+----------+-------------+ 接下来的操作都会在该VT3表上进行。 执行WHERE过滤对添加外部行得到的VT3进行WHERE过滤，只有符合&lt;where_condition&gt;的记录才会输出到虚拟表VT4中。当我们执行WHERE a.city = &#39;hangzhou&#39;的时候，就会得到以下内容，并存在虚拟表VT4中：👇12345678+-------------+----------+----------+-------------+| customer_id | city | order_id | customer_id |+-------------+----------+----------+-------------+| 163 | hangzhou | 1 | 163 || 163 | hangzhou | 2 | 163 || tx | hangzhou | 6 | tx || baidu | hangzhou | NULL | NULL |+-------------+----------+----------+-------------+ 但是在使用WHERE子句时，需要注意以下两点： 由于数据还没有分组，因此现在还不能在WHERE过滤器中使用where_condition=MIN(col)这类对分组统计的过滤； 由于还没有进行列的选取操作，因此在SELECT中使用列的别名也是不被允许的，如：SELECT city as c FROM t WHERE c=&#39;shanghai&#39;;是不允许出现的。 执行GROUP BY分组GROUP BY子句主要是对使用WHERE子句得到的虚拟表进行分组操作。我们执行测试语句中的GROUP BY a.customer_id，就会得到以下内容：👇1234567+-------------+----------+----------+-------------+| customer_id | city | order_id | customer_id |+-------------+----------+----------+-------------+| 163 | hangzhou | 1 | 163 || baidu | hangzhou | NULL | NULL || tx | hangzhou | 6 | tx |+-------------+----------+----------+-------------+ 得到的内容会存入虚拟表VT5👆中，此时，我们就得到了一个VT5👆虚拟表，接下来的操作都会在该表上完成。 执行HAVING过滤HAVING子句主要和GROUP BY子句配合使用，对分组得到的VT5虚拟表进行条件过滤。当我执行测试语句中的HAVING count(b.order_id) &lt; 2时，将得到以下内容：123456+-------------+----------+----------+-------------+| customer_id | city | order_id | customer_id |+-------------+----------+----------+-------------+| baidu | hangzhou | NULL | NULL || tx | hangzhou | 6 | tx |+-------------+----------+----------+-------------+ 👆这就是虚拟表VT6。 SELECT列表现在才会执行到SELECT子句，不要以为SELECT子句被写在第一行，就是第一个被执行的。 我们执行测试语句中的SELECT a.customer_id, COUNT(b.order_id) as total_orders，从虚拟表VT6中选择出我们需要的内容。我们将得到以下内容：123456+-------------+--------------+| customer_id | total_orders |+-------------+--------------+| baidu | 0 || tx | 1 |+-------------+--------------+ 不，还没有完，👆这只是虚拟表VT7。 执行DISTINCT子句如果在查询中指定了DISTINCT子句，则会创建一张内存临时表（如果内存放不下，就需要存放在硬盘了）。这张临时表的表结构和上一步产生的虚拟表VT7是一样的，不同的是对进行DISTINCT操作的列增加了一个唯一索引，以此来除重复数据。由于我的测试SQL语句中并没有使用DISTINCT，所以，在该查询中，这一步不会生成一个虚拟表。 执行ORDER BY子句对虚拟表中的内容按照指定的列进行排序，然后返回一个新的虚拟表，我们执行测试SQL语句中的ORDER BY total_orders DESC，就会得到以下内容：123456+-------------+--------------+| customer_id | total_orders |+-------------+--------------+| tx | 1 || baidu | 0 |+-------------+--------------+ 可以看到这是对total_orders列进行降序排列的。上述结果会存储在VT8👆中。 执行LIMIT子句LIMIT子句从上一步得到的VT8虚拟表中选出从指定位置开始的指定行数据。对于没有应用ORDER BY的LIMIT子句，得到的结果同样是无序的，所以，很多时候，我们都会看到LIMIT子句会和ORDER BY子句一起使用。 MySQL数据库的LIMIT支持如下形式的选择：👇1LIMIT n, m 表示从第n条记录开始选择m条记录。而很多开发人员喜欢使用该语句来解决分页问题。对于小数据，使用LIMIT子句没有任何问题，当数据量非常大的时候，使用LIMIT n, m是非常低效的。因为LIMIT的机制是每次都是从头开始扫描，如果需要从第60万行开始，读取3条数据，就需要先扫描定位到60万行，然后再进行读取，而扫描的过程是一个非常低效的过程。所以，对于大数据处理时，是非常有必要在应用层建立一定的缓存机制（貌似现在的大数据处理，都有缓存哦）。各位，请期待我的缓存方面的文章哦。]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017_12-第三周]]></title>
    <url>%2F2017%2F12%2F19%2F2017_12_week_3rd%2F</url>
    <content type="text"><![CDATA[2017_12-第三周const关键字const:此声明创建一个常量，其作用域可以是全局或本地声明的块。 与var变量不同，全局常量不会变为窗口对象(widows)的属性。需要一个常数的初始化器；也就是说，您必须在声明的同一语句中指定它的值（这是有道理的，因为以后不能更改）。 const声明创建一个值的只读引用。但这并不意味着它所持有的值是不可变的，只是变量标识符不能重新分配。例如，在引用内容是对象的情况下，这意味着可以改变对象的内容（例如，其参数）。^1 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// 注意: 常量在声明的时候可以使用大小写，但通常情况下全部用大写字母。 // 定义常量MY_FAV并赋值7const MY_FAV = 7;// 报错MY_FAV = 20;// 输出 7console.log("my favorite number is: " + MY_FAV);// 尝试重新声明会报错 const MY_FAV = 20;// MY_FAV 保留给上面的常量，这个操作会失败var MY_FAV = 20; // 也会报错let MY_FAV = 20;// 注意块范围的性质很重要if (MY_FAV === 7) &#123; // 没问题，并且创建了一个块作用域变量 MY_FAV // (works equally well with let to declare a block scoped non const variable) let MY_FAV = 20; // MY_FAV 现在为 20 console.log('my favorite number is ' + MY_FAV); // 这被提升到全局上下文并引发错误 var MY_FAV = 20;&#125;// MY_FAV 依旧为7console.log("my favorite number is " + MY_FAV);// 常量要求一个初始值const FOO; // SyntaxError: missing = in const declaration// 常量可以定义成对象const MY_OBJECT = &#123;"key": "value"&#125;;// 重写对象和上面一样会失败MY_OBJECT = &#123;"OTHER_KEY": "value"&#125;;// 对象属性并不在保护的范围内，下面这个声明会成功执行MY_OBJECT.key = "otherValue";// 也可以用来定义数组const MY_ARRAY = [];// It's possible to push items into the array// 可以向数组填充数据MY_ARRAY.push('A'); // ["A"]// 但是，将一个新数组赋给变量会引发错误MY_ARRAY = ['B'] let关键字let语句声明一个块级作用域的本地变量，并且可选的将其初始化为一个值。^2 作用域规则let声明的变量只在其声明的块或子块中可用，这一点，与var相似。二者之间最主要的区别在于var声明的变量的作用域是整个封闭函数。1234567891011121314151617function varTest() &#123; var x = 1; if (true) &#123; var x = 2; // 同样的变量! console.log(x); // 2 &#125; console.log(x); // 2&#125;function letTest() &#123; let x = 1; if (true) &#123; let x = 2; // 不同的变量 console.log(x); // 2 &#125; console.log(x); // 1&#125; 简化内部函数代码当用到内部函数的时候，let会让你的代码更加简洁，，对比之前[立即执行函数表达式(IIFE)]。(https://someoneiscoding.github.io/2017/12/10/%E7%AB%8B%E5%8D%B3%E6%89%A7%E8%A1%8C%E5%87%BD%E6%95%B0%E8%A1%A8%E8%BE%BE%E5%BC%8F%28IIFE%29/#iife)123456789101112131415161718192021222324252627var list = document.getElementById('list');for (let i = 1; i &lt;= 5; i++) &#123; let item = document.createElement('li'); item.appendChild(document.createTextNode('Item ' + i)); item.onclick = function(ev) &#123; console.log('Item ' + i + ' is clicked.'); &#125;; list.appendChild(item);&#125;// to achieve the same effect with 'var'// you have to create a different context// using a closure to preserve the value// 要用var关键字实现同样的功能，你不得不使用闭包来维护不同的上下文环境以保护值(不被改变)。for (var i = 1; i &lt;= 5; i++) &#123; var item = document.createElement('li'); item.appendChild(document.createTextNode('Item ' + i)); (function(i)&#123; item.onclick = function(ev) &#123; console.log('Item ' + i + ' is clicked.'); &#125;; &#125;)(i); list.appendChild(item);&#125; ↑ 以上示例的工作原理是因为（匿名）内部函数的五个实例引用了变量i的五个不同实例。注意，如果你将let替换为var，则它将无法正常工作，因为所有内部函数都将返回相同的i=6的最终值。此外，我们可以通过将创建新元素的代码移动到每个循环的作用域来保持循环更清晰。 在程序或者函数的顶层，let并不会像var一样在全局对象上创造一个属性，比如：👇1234var x = 'global';let y = 'global';console.log(this.x); // "global"console.log(this.y); // undefined let暂存死区的错误在 ECMAScript 2015 中，let绑定不受变量提升的约束，这意味着let声明不会被提升到当前执行上下文的顶部。在块中的变量初始化之前，引用它将会导致ReferenceError（而使用var声明变量则恰恰相反，该变量的值是undefined）。该变量处于从块开始到初始化处理的“暂存死区”。👇123456function do_something() &#123; console.log(bar); // undefined console.log(foo); // ReferenceError: foo is not defined var bar = 1; let foo = 2;&#125; 由于词法作用域，表达式(foo + 55)内的标识符foo会解析为if块的foo，而不是覆盖值为33的foo。在这一行中，if块的foo已经在词法环境中创建，但尚未达到（并终止）其初始化（这是语句本身的一部分）：它仍处于暂存死区。👇1234567function test()&#123; var foo = 33; if (true) &#123; let foo = (foo + 55); // ReferenceError &#125;&#125;test(); 字面量 (Literals)(译注：字面量是由语法表达式定义的常量；或，通过由一定字词组成的语词表达式定义的常量)^3 在JavaScript中，你可以使用各种字面量。这些字面量是脚本中按字面意思给出的固定的值，而不是变量。（译注：字面量是常量，其值是固定的，而且在程序脚本运行中不可更改，比如false，3.1415，thisIsStringOfHelloworld ，invokedFunction:myFunction(“myArgument”)。 1var fish = ["Lion", , "Angel"]; 👆在这个数组中，有两个已被赋值的元素，和一个空元素（fish[0]是”Lion”，fish[1]是undefined，而fish[2]是”Angel”；译注：此时数组的长度属性fish.length是3)。 如果你在元素列表的尾部添加了一个逗号，它将会被忽略。在下面的例子中，数组的长度是3，并不存在myList[3]这个元素（译注：这是指数组的第4个元素噢，作者是在帮大家复习数组元素的排序命名方法）。元素列表中其它所有的逗号都表示一个新元素（的开始）。👇12var myList = ['home', , 'school', ];// 尾部的逗号在早期版本的浏览器中会产生错误，因而编程时的最佳实践方式就是移除它们。 2017-12-20ci:Case Insensitive, 即 “大小写不敏感”, a 和 A 会在字符判断中会被当做一样的。utf8_unicode_ci和utf8_general_ci对中、英文来说没有实质的差别。utf8_general_ci校对速度快，但准确度稍差。utf8_unicode_ci准确度高，但校对速度稍慢。 如果你的应用有德语、法语或者俄语，请一定使用utf8_unicode_ci。一般用utf8_general_ci就够了。]]></content>
      <categories>
        <category>周记</category>
      </categories>
      <tags>
        <tag>var</tag>
        <tag>let</tag>
        <tag>const</tag>
        <tag>字面量</tag>
        <tag>literals</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaScript的变量提升及作用域]]></title>
    <url>%2F2017%2F12%2F14%2Fjavascript_coping_and_hoisting%2F</url>
    <content type="text"><![CDATA[JavaScript的变量提升及作用域JavaScript的语法简直不要太灵活，灵活到导出是坑，甚至有人说JavaScript语言不够成熟。。 Code once,debug everywhere. 下面简单整理下常见的坑坑。 变量提升(hoisting)javascript的变量声明具有hoisting机制，JavaScript引擎在执行的时候，会把所有变量的声明都提升到当前作用域的最前面：12345var v = "hello";(function()&#123; console.log(v); var v = "world";&#125;)(); 倘若这是网页中的一部分，则第三行代码输出undefined,若是在浏览器DevTools的console中运行的话，则是两条undefined结果，第一条是console.log()输出的，第二条是执行(闭包)函数时返回的默认值(没有定义返回值时)undefined。其实上边👆的代码等价于：👇1234567var v = "hello";(function()&#123; var v; //declaration hoisting 变量声明提升 console.log(v); v = "world";&#125;)();//第三行中，只重新声明了v，没有定义(初始化赋值),所以返回undefined。 下面给我们稍加改动下，，👇123456var v = "hello";if(true)&#123; console.log(v); var v = "world";&#125;// hello 如果JavaScript有块作用域的话，应该会报错吧，，内容大概是第4行变量v已经被定义什么的。这样说不太明显，，看这个：👇12345for(var i = 0;i &lt; 10; i++)&#123; console.log(i);&#125;console.log(i);//10console.log(window.i);//10 上边在for循环中声明的变量i应该只存在与for循环的代码块中，但是却可以在代码块外访问，外边声明的变量默认是window对象的属性。由此可见javascript是没有块级作用域的。但函数是JavaScript中唯一拥有自身作用域的结构。就像文章开头的第一个代码块一样，再小改下👇：123456789var v = "hello";(function()&#123; console.log("v inside:"+v); var v = "world";&#125;)();console.log("v outside:"+v);//v inside:undefined//v outside:hello 此时，闭包函数外是访问不到内部的变量v = &quot;world&quot;的，，所以，outside输出的值为hello。若是不死心，，我们再改：👇12345678910var v = "hello";(function()&#123; var v = "world"; console.log("v inside:"+v);&#125;)();console.log("v outside:"+v);//v inside:world//v outside:hello//此处不解释。 还是关于函数内的块级作用域，，我再换种方式：👇1234567var i = function()&#123; var h = 9; console.log("inside h:"+h);&#125;console.log("outside h:"+h)// 第5行直接报错：h is not defined。 其实，我们还可以再改，，关于隐式声明的全局变量^11234567891011var i = function()&#123; h = 9; //此处去掉关键字var console.log("inside h:"+h);&#125;i();console.log("outside h:"+h);// inside h:9// outside h:9// 在函数内部声明变量时省略var关键字，会默认当做全局变量。// 另外，如果没有第五行的i()；函数i调用，则第六行还是会报错Uncaught ReferenceError: h is not defined 》》》2017-12-19-补充《《《1234567891011var x = 0;function f()&#123; var x = y = 1; // x在函数内部声明，y不是！&#125;f();console.log(x, y); // 0, 1// x是全局变量。// y是隐式声明的全局变量。// 第4行可以近似理解为 y = 1;var x = y; 需要注意的是，提升的不光有变量，函数声明也会提升，但是通过函数字面量定义的函数不会被提升，详见[JavaScript执行顺序]。(https://someoneiscoding.github.io/2017/12/02/JavaScript%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F/) 名字解析顺序 javascript中一个名字(name)以四种方式进入作用域(scope)，其优先级顺序如下：1、语言内置：所有的作用域中都有 this 和 arguments 关键字2、形式参数：函数的参数在函数作用域中都是有效的3、函数声明：形如function foo() {}4、变量声明：如 var;名字声明的优先级如上👆所示，也就是说如果一个变量的名字与函数的名字相同，那么函数的名字会覆盖变量的名字，无论其在代码中的顺序如何。但名字的初始化却是按其在代码中书写的顺序进行的，不受以上优先级的影响。看代码：123456789(function()&#123; function foo()&#123;&#125; console.log(typeof foo); //function var foo; console.log(typeof foo); //function foo = "foo"; console.log(typeof foo); //string&#125;)();]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017_12-第二周]]></title>
    <url>%2F2017%2F12%2F13%2F2017_12_week_2nd%2F</url>
    <content type="text"><![CDATA[2017_12-第二周1var a = a || &#123;&#125; 👆等价于👇1234var a;function(a)&#123; if(a === 0 || a === "" || a === false || a === null || a === undefined) a = &#123;&#125;&#125; 在之前固有的印象中，逻辑与&amp;&amp;和逻辑或||都是出现在if条件语句中，一般用来做判断条件使用，if()括号中会依据a==1 || b!=1表达式的返回值trueorfalse来做判断。👇123if(a==1 || b!=1)&#123; //do something;&#125; 猛然间看到var a = a || {}有些无措，，后来得知，||返回的不是boolean值trueorfalse，而是两边的表达式！比如a==1和b!=1,因为双目运算符的运算优先级高于逻辑或，所以最终返回的是表达的值。 TTFB:Time To First Byte 请求发送：本机——&gt;运营商路由——&gt;服务器收到响应：服务器——&gt;运营商路由——&gt;本机]]></content>
      <categories>
        <category>周记</category>
      </categories>
      <tags>
        <tag>逻辑或</tag>
        <tag>TTFB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Javascript 面向对象编程(一)：封装]]></title>
    <url>%2F2017%2F12%2F11%2Fjavascript_oop-encapsulation%2F</url>
    <content type="text"><![CDATA[Javascript 面向对象编程(一)：封装最近一直在用百度的echarts做图表什么的，在配置项中的option是一个对象，，like this var option = {}，，有时需要多个option对象，复制来复制去，也只是复制的变量，指向的还是同一个引用。。得好好学习下，翻来覆去还是阮一峰老师的总结最友好~ 原文链接：Javascript 面向对象编程（一）：封装 - by 阮一峰 学习Javascript，最难的地方是什么？我觉得，Object（对象）最难。因为Javascript的Object模型很独特，和其他语言都不一样，初学者不容易掌握。下面就是我的学习笔记，希望对大家学习这个部分有所帮助。我主要参考了以下两本书籍： 《面向对象的Javascript》（Object-Oriented JavaScript） 《Javascript高级程序设计（第二版）》（Professional JavaScript for Web Developers, 2nd Edition) 它们都是非常优秀的Javascript读物，推荐阅读。笔记分成三部分。今天的第一部分是讨论”封装”（Encapsulation），后面的第二部分和第三部分讨论”继承”（Inheritance）。 ==== ==== ==== ==== ==== ==== ==== Javascript是一种基于对象（object-based）的语言，你遇到的所有东西几乎都是对象。但是，它又不是一种真正的面向对象编程（OOP）语言，因为它的语法中没有class（类）。 那么，如果我们要把”属性”（property）和”方法”（method），封装成一个对象，甚至要从原型对象生成一个实例对象，我们应该怎么做呢？ 一、生成实例对象的原始模式假定我们把猫看成一个对象，它有”名字”和”颜色”两个属性。1234var Cat = &#123; name : '', color : ''&#125; 现在，我们需要根据这个原型对象的规格（schema），生成两个实例对象。1234567var cat1 = &#123;&#125;; // 创建一个空对象cat1.name = "大毛"; // 按照原型对象的属性赋值cat1.color = "黄色";var cat2 = &#123;&#125;;cat2.name = "二毛";cat2.color = "黑色"; 好了，这就是最简单的封装了，把两个属性封装在一个对象里面。但是，这样的写法有两个缺点，一是如果多生成几个实例，写起来就非常麻烦；二是实例与原型之间，没有任何办法，可以看出有什么联系。 二、原始模式的改进我们可以写一个函数，解决代码重复的问题。123456function Cat(name,color) &#123; return &#123; name:name, color:color &#125;&#125; 然后生成实例对象，就等于是在调用函数：12var cat1 = Cat("大毛","黄色");var cat2 = Cat("二毛","黑色"); 这种方法的问题依然是，cat1和cat2之间没有内在的联系，不能反映出它们是同一个原型对象的实例。 三、构造函数模式为了解决从原型对象生成实例的问题，Javascript提供了一个构造函数（Constructor）模式。 所谓”构造函数”，其实就是一个普通函数，但是内部使用了this变量。对构造函数使用new运算符，就能生成实例，并且this变量会绑定在实例对象上。比如，猫的原型对象现在可以这样写:1234function Cat(name,color)&#123; this.name=name; this.color=color;&#125; 我们现在就可以生成实例对象了。1234var cat1 = new Cat("大毛","黄色");var cat2 = new Cat("二毛","黑色");alert(cat1.name); // 大毛alert(cat1.color); // 黄色 这时cat1和cat2会自动含有一个constructor属性，指向它们的构造函数。12alert(cat1.constructor == Cat); //truealert(cat2.constructor == Cat); //true Javascript还提供了一个instanceof运算符，验证原型对象与实例对象之间的关系。12alert(cat1 instanceof Cat); //truealert(cat2 instanceof Cat); //true instanceof不是驼峰命名，，类似的还有typeof ——来自someone 四、构造函数模式的问题构造函数方法很好用，但是存在一个浪费内存的问题。请看，我们现在为Cat对象添加一个不变的属性type（种类），再添加一个方法eat（吃）。那么，原型对象Cat就变成了下面这样：123456function Cat(name,color)&#123; this.name = name; this.color = color; this.type = "猫科动物"; this.eat = function()&#123;alert("吃老鼠");&#125;;&#125; 还是采用同样的方法，生成实例：1234var cat1 = new Cat("大毛","黄色");var cat2 = new Cat ("二毛","黑色");alert(cat1.type); // 猫科动物cat1.eat(); // 吃老鼠 表面上好像没什么问题，但是实际上这样做，有一个很大的弊端。那就是对于每一个实例对象，type属性和eat()方法都是一模一样的内容，每一次生成一个实例，都必须为重复的内容，多占用一些内存。这样既不环保，也缺乏效率。1alert(cat1.eat == cat2.eat); //false 五、Prototype模式Javascript规定，每一个构造函数都有一个prototype属性，指向另一个对象。这个对象的所有属性和方法，都会被构造函数的实例继承。这意味着，我们可以把那些不变的属性和方法，直接定义在prototype对象上。12345678function Cat(name,color)&#123; this.name = name; this.color = color;&#125;//存储公共的属性和方法，达到所有实例共享的目的，永久不变；Cat.prototype.type = "猫科动物";Cat.prototype.eat = function()&#123;alert("吃老鼠")&#125;; 然后，生成实例：1234var cat1 = new Cat("大毛","黄色");var cat2 = new Cat("二毛","黑色");alert(cat1.type); // 猫科动物cat1.eat(); // 吃老鼠 这时所有实例的type属性和eat()方法，其实都是同一个内存地址，指向prototype对象，因此就提高了运行效率。1alert(cat1.eat == cat2.eat); //true 六、Prototype模式的验证方法为了配合prototype属性，Javascript定义了一些辅助方法，帮助我们使用它。 6.1 isPrototypeOf()这个方法用来判断，某个proptotype对象和某个实例之间的关系。12alert(Cat.prototype.isPrototypeOf(cat1)); //truealert(Cat.prototype.isPrototypeOf(cat2)); //true 6.2 hasOwnProperty()每个实例对象都有一个hasOwnProperty()方法，用来判断某一个属性到底是本地属性，还是继承自prototype对象的属性。12alert(cat1.hasOwnProperty("name")); // truealert(cat1.hasOwnProperty("type")); // false 6.3 in运算符in运算符可以用来判断，某个实例是否含有某个属性，不管是不是本地属性。12alert("name" in cat1); // truealert("type" in cat1); // true in运算符还可以用来遍历某个对象的所有属性。1for(var prop in cat1) &#123; alert("cat1["+prop+"]="+cat1[prop]); &#125; 未完，请继续阅读这个系列的第二部分《构造函数的继承》和第三部分《非构造函数的继承》。（完） 补充： 函数声明与函数字面量1234function Cat(name,color)&#123; this.name = name; this.color = color;&#125; 与1234var Cat = function (name,color)&#123; this.name = name; this.color = color;&#125; 在实例化及使用时，用法相同。 Json方式访问对象属性 12345var cat = new Cat('Command','black');//下面两种使用方式效果相同alert(cat.name);alert(cat['name']); 在第一种方式实例对象原始模式中，其实实例与原型之间没有什么关系，如果非要扯上关系的话，，只能说『原型』和『实例』之间的格式比较相像。『实例』之间也没什么关系。。这种方式生成的对象是一次性的，无法复用，，在某种程度上，『原型』也是一个『实例』。 有的博客上说new关键字可以省略，后来又查阅了些资料才知道，，原来真的是可以省略的:1234var cat = Cat('cmd','black');console.log(cat); //undefinedconsole.log(cat.name); //Cannot read property 'name' of undefinedconsole.log(window.name); //cmd 对于js的new关键字，大家可以这样理解：new就是将函数内部的this的值，赋值给当前对象的this，如：this.name（实例对象） = this.name（构造函数）当没有new的时候，this就变为了window，也就解释了。 —— js创建对象之设计模式]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017_12—第一周]]></title>
    <url>%2F2017%2F12%2F10%2F2017_12_week_1st%2F</url>
    <content type="text"><![CDATA[2017-12-04 幂等：idempotent idempotence 是一个数学与计算机学概念，常见于抽象代数中。在编程中一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。幂等函数，或幂等方法，是指可以使用相同参数重复执行，并能获得相同结果的函数。这些函数不会影响系统状态，也不用担心重复执行会对系统造成改变。例如，“setTrue()”函数就是一个幂等函数,无论多次执行，其结果都是一样的.更复杂的操作幂等保证是利用唯一交易号(流水号)实现. scaffold 英[ˈskæfəʊld] 美[ˈskæfoʊld]n. 脚手架; &lt;史&gt;断头台;[例句]Moore ascended the scaffold and addressed the executioner.穆尔走上断头台，和刽子手说话。 2017-12-05 stumbled 英 [ˈstʌmbl] 美 [ˈstʌmbəl]v. （不顺畅地） 说( stumble的过去式和过去分词 ); 跌跌撞撞地走; 绊脚; （说话、演奏等） 出错;[例句]She stumbled and fell, scraping her palms and knees.她绊了一下摔倒了，手掌和膝盖都蹭破了。 *reserved 英[rɪˈzɜ:vd] 美[rɪˈzɜ:rvd]adj. 预订的; 矜持的; 储藏着的;v. 保留[储备]某物( reserve的过去式);[例句]He was unemotional, quite quiet, and reserved他感情淡漠，沉默寡言，性格内敛。 keyword 关键字reserved word 保留字 literal 英[ˈlɪtərəl] 美[ˈlɪtərəl]adj. 照字面的; 原义的; 逐字的; 平实的，避免夸张;n. [印] 错排，文字上的错误;[例句]In many cases, the people there are fighting, in a literal sense, for their homes.很多情况下，那里的人们是真刀真枪地在为家园而抗争。 anonymous 英[əˈnɒnɪməs] 美[əˈnɑ:nɪməs]adj. 匿名的; 无名的; 假名的; 没有特色的;[例句]You can remain anonymous if you wish你愿意的话可以不透露姓名。 2017-12-07 categories 英[‘kætɪɡərɪz] 美[‘kætɪɡərɪz]n. 种类，类别( category的名词复数 ); 派别;[例句]The verbs were subdivided into transitive and intransitive categories.动词可细分为及物动词和不及物动词。 2017-12-08 favicon 英[‘fævɪkən] 美[‘fævɪkən]abbr. 偏爱图标; 网站图标(favorites icon); 2017-12-10 anchor 英[ˈæŋkə(r)] 美[ˈæŋkɚ]n. 锚; 锚状物; 靠山; 压阵队员;vt. 抛锚，抛锚泊船; 使固定，使稳固; 使稳定; 在…任节目主持人;vi. 固定; 抛锚，停泊; [体] 任主要运动员; 主持节目;[例句]We could anchor off the pier我们可以在码头附近下锚停泊。 stickler 英[ˈstɪklə(r)] 美[‘stɪklər]n. 坚持…的人;[例句]I’m a bit of a stickler for accuracy我总是要求精确。]]></content>
      <categories>
        <category>周记</category>
      </categories>
      <tags>
        <tag>幂等</tag>
        <tag>单词</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[立即执行函数表达式(IIFE)]]></title>
    <url>%2F2017%2F12%2F10%2Fimmediately-invoked_function_expression(IIFE)%2F</url>
    <content type="text"><![CDATA[立即执行函数表达式(IIFE) 原文：Immediately-Invoked Function Expression (IIFE) by Ben Alman 以防你没有注意到，(事先声明)我是一个对于专业术语有些坚持的人。所以，当我多次听到流行却易产生误解的术语「自执行匿名函数」，最终决定将的想法总结到这篇文章中。 除此之外，为了提供一些更深入更彻底的关于这种模式是如何工作的，事实上我还建议了我们应该怎样称呼这种模式。另外，如果你想跳过这里，你可以直接阅读立即调用函数表达式，但是我建议你读完整篇文章。 你需要知道的是，这篇文章不是想说「我是对了，你是错的」之类的。我发自真心地想帮助人们理解这有点儿复杂的概念，并且我认为使用前后一致的精确术语是有助于人们理解的最简单的方式之一。 所以，它到底是什么在JavaScript里，每个函数，当被调用时，都会创建一个新的执行环境。因为在函数里定义的变量和函数只能在函数内部被访问，外部无法获取；这种情况下，调用函数提供了一个非常简单的方法创建私有变量。123456789101112131415161718// 因为这个函数的返回值是另一个能通过i访问私有变量的函数，(privileged)？function makeCounter() &#123; //i只能从`makeConuter`内部访问 var i = 0; return function()&#123; console.log(++i); &#125;; &#125;// `counter`和`counter2`都有自己作用域中的变量 `i`var counter = makeCounter();counter(); //1counter(); //2var counter2 = makeCounter();counter2(); //1counter2(); //2// ReferenceError: i is not defined(它只存在于makeCounter里) 在许多情况下，你可能并不需要由makeWhatever返回的多个实例，使用单例模式就可以实现。或者在其他情况中，你甚至不需要返回值。 核心问题现在，无论你以function foo(){}的方式，还是var foo = function(){}的方式声明函数，你都可以在后边加上括号(圆括号,())来调用它们，，比如foo();。12345// 像下面这样定义的函数可以通过在函数名后加一对括号进行调用，像这样`foo()`，因为foo只是函数表达式`function()&#123;/* code */&#125;`的一个引用变量；var foo = function()&#123;/* code */&#125;//那这说明函数表达式可以通过在它自己后面加上一对括号就可以自己调用自己了吗？function()&#123; /* code */&#125;();//SyntaxError: Unexpected token ( 正如你所看到的，这里捕获了一个异常。当圆括号在全局环境或函数内部遇到function关键字，它会被默认当作一个函数声明，而不是函数表达式，如果你不明确的告诉圆括号它是一个表达式，它会将其当作没有名字的函数声明并且抛出一个语法错误，因为函数声明需要一个名字。 题外话：函数、圆括号和错误有趣的是，如果你为一个函数指定一个名字并在它后面放一对圆括号，同样的也会抛出错误，但这次是因为另外一个原因。当圆括号放在一个函数表达式后面指明了这是一个被调用的函数，而圆括号放在一个声明后面便意味着完全的和前面的函数声明分开了，此时圆括号只是一个简单的代表一个(组?)运算符(用来控制运算优先级)。12345678910// 然而函数声明语法上是无效的，它仍然是一个声明，紧跟着的圆括号是无效的，因为圆括号里需要包含表达式function foo()&#123; /* code */ &#125;();//👆SyntaxError: Unexpected token// 现在，你把一个表达式放在圆括号里，没有抛出错误...但是函数也并没有执行，因为：function foo()&#123;/* code */&#125;(1)// 它等同于如下，一个函数声明跟着一个完全没有关系的表达式:function foo()&#123;/* code */&#125;(1); 关于这个细节，你可以阅读Dmitry A. Soshnikov的文章：ECMA-262-3 in detail. Chapter 5. Functions 立即执行函数表达式(IIFE)幸运的是，修正语法错误很简单。最流行的也最被接受的方法是将函数声明包裹在圆括号里来告诉语法分析器去表达一个函数表达式，因为在JavaScript里，圆括号不能包含声明。因为这点，当圆括号为了包裹函数碰上了 function关键词，它便知道将它作为一个函数表达式去解析而不是函数声明。注意理解这里的圆括号和上面的圆括号遇到函数时的表现是不一样的，也就是说。 当圆括号出现在匿名函数的末尾想要调用函数时，它会默认将函数当成是函数声明。 当圆括号包裹函数时，它会默认将函数作为表达式去解析，而不是函数声明。123456789101112131415161718192021222324252627// 这两种模式都可以被用来立即调用一个函数表达式，利用函数的执行来创造私有变量(function()&#123;/* code */&#125;());//👆Crockford recommends this one(function()&#123;/* code */&#125;)();//👆But this one works just as well// 因为括号的作用就是为了消除函数表达式和函数声明之间的差异// 如果解释器能预料到这是一个表达式，括号可以被省略// 不过请参见下面的「重要笔记」var i = function()&#123;return 10;&#125;();true &amp;&amp; function()&#123;/*code*/&#125;();0,function()&#123;&#125;();//如果你并不关心返回值，或者让你的代码尽可能的易读，你可以通过在你的函数前面带上一个一元操作符来存储字节!function()&#123;/* code */&#125;();~function()&#123;/* code */&#125;();-function()&#123;/* code */&#125;();+function()&#123;/* code */&#125;();// 这里是另外一种方法// 我（原文作者）不清楚new方法是否会影响性能// 但它却是奏效，参见http://twitter.com/kuvos/status/18209252090847232new function()&#123; /* code */ &#125;new function()&#123; /* code */ &#125;() // 👆只有当传入参数时才需要加括号 关于括号的重要须知在一些情况下，当围绕在函数表达式周围的额外用来消除歧义的括号是没必要的（因为这时候的括号已经将其作为一个表达式去表达了），但它被当做约定俗成习惯时，仍然是一个好主意。 这样的括号指明函数表达式将会被立即调用，并且变量将会储存函数的结果，而不是函数本身。当这是一个非常长的函数表达式时，这可以节约其他人阅读你代码的时间，不用滚到页面底部去看这个函数是否被调用。 作为规则，当你书写没有歧义的代码时候，有必要阻止JavaScript解释器抛出错误；这同样很公平，可以避免让其他开发者写出抛出异常WTFError的代码影响到你! 保存闭包的状态就像当函数通过他们的名字被调用时，参数会被传递，而当函数表达式被立即调用时，参数也会被传递。一个立即调用的函数表达式可以用来锁定值并且有效的保存此时的状态，因为任何定义在一个函数内的函数都可以使用外面函数传递进来的参数和变量（这种关系被叫做闭包）。 关于闭包的更多信息，参见 Closures explained with JavaScript 12345678910111213141516171819202122232425262728293031323334/ /它的运行原理可能并不像你想的那样，因为`i`的值从来没有被锁定。相反的，每个链接，当被点击时(for循经执行完毕之后)，因此会弹出所有元素的总数(elems.length)，因为这是`i`此时的真实值。var elems = document.getElementsByTagName('a');for(var i = 0;i &lt; elems.length; i++ ) &#123; elems[i].addEventListener('click',function(e)&#123; e.preventDefault(); alert('I am link #' + i) &#125;,false);&#125;// 2018-01-27 更，编者按，，简单点说，因为在ES5中，只有(用var声明的变量)在函数中才有作用域。所以在for循环中用变量i属于for循环外，而不是for循环的&#123;&#125;中。同时，for循环又是一个同步事件，循环体中的监听事件是异步事件，异步事件处于 event loop 中，要等到所有同步事件执行完成之后，才会执行event loop 中的事件，，而那个时候，i 已然等于elems.length了。// 而像下面这样改写就可以了，，因为在IIFE里，`i`值被锁定在了`lockedInIndex`里。在循环执行结束后，尽管`i`值的数值是所有元素的总和(elems.length)，但每一次函数表达式被调用时，IIFE里的`lockedInIndex`值都是`i`传给它的值,所以当链接被点击时，正确的值被弹出。var elems = document.getElementsByTagName('a');for(var i = 0;i &lt; elems.length;i++) &#123; (function(lockedInIndex)&#123; elems[i].addEventListener('click',function(e)&#123; e.preventDefault(); alert('I am link #' + lockedInIndex); &#125;,false) &#125;)(i); // 2018-01-27 更，编者按，，在上边我们说了，在javascript中只有函数才有作用域，所以，，要想把 i 的作用于独立出来，需要用函数的方式，所以，用闭包。&#125;//你同样可以像下面这样使用IIFE，仅仅只用括号包裹点击处理函数，并不包含整个`addEventListener`。无论用哪种方式，这两个例子都可以用IIFE将值锁定，不过我发现前面一个例子可读性更好些var elems = document.getElementsByTagName( 'a' );for ( var i = 0; i &lt; elems.length; i++ ) &#123; elems[ i ].addEventListener( 'click', (function( lockedInIndex )&#123; return function(e)&#123; e.preventDefault(); alert( 'I am link #' + lockedInIndex ); &#125;; &#125;)( i ),false);&#125;// 2018-01-27 更，编者按，，另外，在ES5 中只有一种声明变量的方式，就是使用 var 关键字，然而用它声明的字面量只有在函数中才有作用域概念。然而在 ES6 中，有了 let 关键字，，let 关键字声明的变量没有变量提升，不能在同一个作用域中用let关键字声明同意个变量两次，而且有了明确的作用域概念！！！所以，在上边的例子中，我们可以把 for 循环中的 var 关键字直接改为 let，闭包什么的不需要！完美解决。 记住，在这最后两个例子里，lockedInIndex可以没有任何问题的访问i,但是作为函数的参数使用一个不同的命名标识符可以使概念更加容易的被解释。 立即执行函数一个最显著的优势是就算它没有命名或者说是匿名，函数表达式也可以在没有使用标识符的情况下被立即调用，一个闭包也可以在没有当前变量污染的情况下被使用。 「自执行匿名函数(Self-executing anonymous function)」有什么问题呢？你看到它已经被提到好几次了，但它仍未被清楚地解释，我提议将术语改成”Immediately-Invoked Function Expression“，或者，IIFE，如果你喜欢缩写的话（发音类似“iffy”）。The pronunciation “iffy“ was suggested to me, and I like it, so let’s go with that. 什么是Immediately-Invoked Function Expression呢？顾名思义，它就是一个被立即调用的函数表达式。Just like the name would lead you to believe. 我想JavaScript社区的成员应该可以在他们的文章里或者陈述里接受术语Immediately-Invoked Function Expression和IIFE，因为我感觉这样更容易让这个概念被理解，并且self-executing anonymous function真的也的确不够准确。123456789101112131415161718192021// 下面是个自执行函数，递归调用自己本身function foo()&#123;foo();&#125;;// 这是一个自执行匿名函数。因为它没有标识符，它必须是使用`arguments.callee`(which specifies the currently executing function 特指刚刚执行过的函数)属性来调用它自己var foo = function()&#123;arguments.callee();&#125;;// 这也许算是一个自执行匿名函数，但是仅仅当`foo`标识符作为它的引用时，如果你将foo换成用其他的什么名字(something else),你会获得一个 "used-to-self-execute" 匿名函数.var foo = function()&#123;foo();&#125;;// 有些人像这样叫'self-executing anonymous function'下面的函数,即使它不是自执行的，因为它并没有调用它自己。然后，它只是被立即调用了而已。(function()&#123; /*code*/ &#125;());// 为函数表达式增加标识符(也就是说创造一个命名函数)对我们的调试会有很大帮助。一旦命名，函数将不再匿名。(function foo()&#123;/* code */&#125;());// IIFEs同样也可以自执行，尽管，也许他不是最有用的模式(function()&#123;arguments.callee();&#125;())(function foo()&#123;foo();&#125;())// 另外，下面这个表达式竟会在黑莓5上抛出错误，在一个被命名的函数中，该函数名是undefined。Awesome, huh?(function foo()&#123; foo(); &#125;()); 希望上面的例子可以让你更加清楚的知道’self-executing’这个说法是有些误导性的，因为它并不是执行自己的函数，即使函数已经被执行。同样的，匿名属性也没用必要特别指出，因为，Immediately Invoked FunctionExpression，既可以是命名函数也可以匿名函数。 有趣的是：因为arguments.callee在ECMAScript 5 strict mode中被deprecated了，所以在ES5的strict mode中实际上不可能创建一个self-executing anonymous function 最后:模块模式当我调用函数表达式时，如果我不至少提醒自己一次关于模块模式，我很可能会忽略它。如果你并不熟悉JavaScript里的构建模式，它和我第一个例子很像，但是返回值用对象代替了函数。1234567891011121314151617181920212223242526// Create an anonymous function expression that gets invoked immediately,and assign its *return value* to a variable. This approach "cuts out the middleman" of the named `makeWhatever` function reference.// As explained in the above "important note," even though parens are not required around this function expression, they should still be used as a matter of convention to help clarify that the variable is being set to the function's *result* and not the function itself.//正如上面的『重要须知』解释的一样，，，即使包围函数表达式的括号不是必须时，它们也应该被很当回事的当做约定俗成的习惯保留着，用来清晰的表明变量是函数的结果，而不是变量本身。var counter = (function()&#123; var i = 0; return &#123; get: function()&#123; return i; &#125;, set: function(val)&#123; i = val; &#125;, increment: function()&#123; return ++i; &#125; &#125; &#125;()); counter.get();//0 counter.set(3); counter.increment();//4 counter.increment();//5 conuter.i;//undefined (`i` is not a property of the returned object) i;//ReferenceError: i is not defined (it only exists inside the closure) 模块模式方法不仅相当的厉害而且简单。非常少的代码，你可以有效的利用与方法和属性相关的命名，在一个对象里，组织全部的模块代码即最小化了全局变量的污染也创造了私人变量。 延伸阅读希望这篇文章能够为你提供些有用的信息，并且解答了一些问题。当然，如果你现在比之前的问题更多了，你可以通过阅读以下文章来更深入的了解函数和构建模式。 2018-01-27 更，编者按，，最后希望大家了解下ES6，还是阮一峰老师 =&gt; ECMAScript 6 简介 ECMA-262-3 in detail. Chapter 5. Functions. - Dmitry A. Soshnikov Functions and function scope - Mozilla Developer Network Named function expressions - Juriy “kangax” Zaytsev JavaScript Module Pattern: In-Depth - Ben Cherry Closures explained with JavaScript - Nick Morgan]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解与使用Javascript中的回调函数]]></title>
    <url>%2F2017%2F12%2F07%2Fcallback_function_in_javascript%2F</url>
    <content type="text"><![CDATA[理解与使用Javascript中的回调函数有点小感慨在这不得不提一下Python，在人工智能火起来之前就在断断续续的看教程。现在因为人工智能的原因，更要好好学习一下，，在学习的过程中了，第一次好像明白『函数式编程』到底是怎么一回事儿了。放张图，各位体会下，，👇因为最近工作的原因，先后遇到了几个关于js的问题，没想到需要阅读的Tab页越来越多，需要总结的页是越来越多。这个过程中，没想到朝夕相处的js中也有类似的特性，，比如闭包，之前特地去了解，可还是半知半解，，如今从Python反观js，一下子通透了~哈哈，下面进入正文 Javascript中，函数是第一类对象，这意味着函数可以像对象一样按照第一类管理被使用。既然函数实际上是对象：它们能被“存储”在变量中，能作为函数参数被传递，能在函数中被创建，能从函数中返回。 因为函数是第一类对象，我们可以在Javascript使用回调函数。在下面的文章中，我们将学到关于回调函数的方方面面。回调函数可能是在Javascript中使用最多的函数式编程技巧，虽然在字面上看起来它们一直一小段Javascript或者jQuery代码，但是对于许多开发者来说它任然是一个谜。在阅读本文之后你能了解怎样使用回调函数。 回调函数是从一个叫函数式编程的编程范式中衍生出来的概念。简单来说，函数式编程就是使用函数作为变量。函数式编程过去 - 甚至是现在，依旧没有被广泛使用 - 它过去常被看做是那些受过特许训练的，大师级别的程序员的秘传技巧。 幸运的是，函数是编程的技巧现在已经被充分阐明因此像我和你这样的普通人也能去轻松使用它。函数式编程中的一个主要技巧就是回调函数。在后面内容中你会发现实现回调函数其实就和普通函数传参一样简单。这个技巧是如此的简单以致于我常常感到很奇怪为什么它经常被包含在讲述Javascript高级技巧的章节中。 什么是回调或者高阶函数一个回调函数，也被称为高阶函数，是一个被作为参数传递给另一个函数（在这里我们把另一个函数叫做“otherFunction”）的函数，回调函数在otherFunction中被调用。一个回调函数本质上是一种编程模式（为一个常见问题创建的解决方案），因此，使用回调函数也叫做回调模式。 变量可以指向函数 函数的参数可以接收变量 一个函数可以接收另一个函数做参数 能接收函数做参数的函数就是高阶函数 下面是一个在jQuery中使用回调函数简单普遍的例子：👇12345//注意到click方法中是一个函数而不是一个变量//它就是回调函数$("#btn_1").click(function() &#123; alert("Btn 1 Clicked");&#125;); 正如你在例子中看到的，我们将一个函数作为参数传递给了click方法。click方法会调用（或者执行）我们传递给它的函数。这是Javascript中回调函数的典型用法，它在jQuery中广泛被使用。 关于回调函数的运作方式，详见异步机制 除了在参数位置定义匿名函数作为回调函数之外，另一种常见的模式是定义一个命名函数并将函数名作为变量传递给函数。比如下面的例子：👇12345678910111213141516171819202122232425262728//全局变量var allUserData = [];//普通的logStuff函数，将内容打印到控制台 function logStuff (userData)&#123; if ( typeof userData === "string")&#123; console.log(userData); &#125;else if ( typeof userData === "object")&#123; for(var item in userData)&#123; console.log(item + ": " + userData[item]); &#125; &#125;&#125; //一个接收两个参数的函数，后面一个是回调函数 function getInput (options, callback)&#123; allUserData.push(options); //确保callback是一个函数 if(typeof callback === "function")&#123; callback(options); &#125;&#125;//当我们调用getInput函数时，我们将logStuff作为一个参数传递给它 //因此logStuff将会在getInput函数内被回调（或者执行） getInput(&#123;name:"Rich",speciality:"Javascript"&#125;, logStuff);//name:Rich//speciality:Javascript 使用this对象的方法作为回调函数时的问题当回调函数是一个this对象的方法时，我们必须改变执行回调函数的方法来保证this对象的上下文。否则如果回调函数被传递给一个全局函数，this对象要么指向全局window对象（在浏览器中）,要么指向包含方法的对象。 我们在下面的代码中说明：👇123456789101112131415161718192021222324var clientData = &#123; id: 094545, fullName: "Not Set", //setUsrName是一个在clientData对象中的方法 setUserName: function (firstName, lastName)&#123; //这指向了对象中的fullName属性 this.fullName = firstName + " " + lastName; &#125;&#125;function getUserInput(firstName, lastName, callback)&#123; //在这做些什么来确认firstName/lastName //现在存储names callback(firstName, lastName);&#125;//当clientData.setUsername被执行时，this.fullName并没有设置clientData对象中的fullName属性。//相反，它将设置window对象中的fullName属性，因为getUserInput是一个全局函数。这是因为全局函数中的this对象指向window对象。getUserInput("Barack","Obama",clientData.setUserName);console.log(clientData,fullName); //Not Set//fullName属性将在window对象中被初始化 console.log(window.fullName); //Barack Obama 使用Call和Apply函数来保存this我们知道每个Javascript中的函数都有两个方法:Call和Apply。这些方法被用来设置函数内部的this对象以及给此函数传递变量。 call接收的第一个参数为被用来在函数内部当做this的对象，传递给函数的参数被挨个传递（当然使用逗号分开）。Apply函数的第一个参数也是在函数内部作为this的对象，然而最后一个参数确是传递给函数的值的数组。 听起来很复杂，那么我们来看看使用Apply和Call有多么的简单。为了修复前面例子的问题，我将在👇下面你的例子中使用Apply函数123456789101112131415//注意到我们增加了新的参数作为回调对象，叫做“callbackObj”function getUserInput(firstName, lastName, callback, callbackObj)&#123; //在这里做些什么来确认名字 //apply callback.apply(callbackObj, [firstName, lastName]); //等价call //callback.call(callbackObj, firstName, lastName);&#125;//我们将clientData.setUserName方法和clientData对象作为参数，clientData对象会被Apply方法使用来设置this对象 getUserInput("Barack", "Obama", clientData.setUserName, clientData);//clientData中的fullName属性被正确的设置console.log(clientUser.fullName); //Barack Obama 回调地狱问题以及解决方案在执行异步代码时，无论以什么顺序简单的执行代码，经常情况会变成许多层级的回调函数堆积以致代码变成下面的情形。这些杂乱无章的代码叫做回调地狱因为回调太多而使看懂代码变得非常困难。我从node-mongodb-native，一个适用于Node.js的MongoDB驱动中拿来了一个例子。这段位于下方的代码将会充分说明回调地狱：👇1234567891011121314151617var p_client = new Db('integration_tests_20', new Server("127.0.0.1", 27017, &#123;&#125;), &#123;'pk':CustomPKFactory&#125;); p_client.open(function(err, p_client) &#123; p_client.dropDatabase(function(err, done) &#123; p_client.createCollection('test_custom_key', function(err, collection) &#123; collection.insert(&#123;'a':1&#125;, function(err, docs) &#123; collection.find(&#123;'_id':new ObjectID("aaaaaaaaaaaa")&#125;, function(err, cursor) &#123; cursor.toArray(function(err, items) &#123; test.assertEquals(1, items.length); // Let's close the db p_client.close(); &#125;); &#125;); &#125;); &#125;); &#125;); &#125;); 你应该不想在你的代码中遇到这样的问题，当你遇到了–你将会时不时的遇到这种情况–这里有关于这个问题的两种解决方案。 给你的函数命名并传递它们的名字作为回调函数，而不是主函数的参数中定义匿名函数。 模块化L将你的代码分隔到模块中，这样你就可以到处一块代码来完成特定的工作。然后你可以在你的巨型应用中导入模块。 Javascript回调函数非常美妙且功能强大，它为web应用和代码提供了诸多好处。我们应该在有需求时使用它，或者为了代码的抽象性、可维护性以及可读性而使用回调函数来重构你的代码。 本文译自understand Javascript callback functions and use them，有删改。 节选自：前端乱炖-http://www.html-js.com/article/1592 有删改]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[孔雀为什么开屏呢?]]></title>
    <url>%2F2017%2F12%2F07%2Fwhy_does_the_peacock_spread_its_tail%2F</url>
    <content type="text"><![CDATA[孔雀为什么开屏呢？好像突然明白了老祖宗强调的『成家立业』，成家在前，立业在后。稳定的伴侣对人类这种有性生殖的动物来说，无疑是重中之重。宏观一点讲，人的一生可以分为这几个阶段： 生长发育至性成熟 寻找配偶 交配产子 抚养后代至性成熟 感情稳定的人儿可以将更多的精力放在家庭和事业上。而那些，那些单身狗呢？？不仅需要全局tigger去监听意中人的出现事件，还要轮询这个对象到底是不是意中人。前者是占用的资源是隐性的，是生理驱动的，，后者是显性的，甚至在某一时间段是同步且阻塞的。 试想一下，，你正在工作，忽然后客人来访，余光扫到这个对象，， 如果是男性，tigger直接无视，头都不带抬的； 如果是女性，注意力『不自觉』被分散，抬头，，肤白貌美？？工作事件被中断，各种分析，在有限的上下文中尽可能获取该异性的信息。 再试想下，，出现这样一个『意中人』，你在TA的朋友圈中添加了评论。接下来，有且仅有一种情况，，就是不停的解锁手机，打开微信，刷新朋友圈。 单身可能真的是一种非常规的生活状态吧，至少不是稳态。它像贫穷一样占用着我们有限的注意力资源，，都是生理饥渴，无暇顾及诗和远方，喂饱了再说。]]></content>
      <categories>
        <category>呓语</category>
      </categories>
      <tags>
        <tag>成家立业</tag>
        <tag>单身</tag>
        <tag>注意力资源</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[彻底理解JavaScript同步|异步|事件循环(EventLoop)]]></title>
    <url>%2F2017%2F12%2F06%2Fjavascript_sync_async_event-loop%2F</url>
    <content type="text"><![CDATA[JavaScript：彻底理解同步、异步和事件循环(Event Loop)为什么JavaScript是单线程？JavaScript语言的一大特点就是单线程，也就是说，同一个时间只能做一件事。那么，为什么JavaScript不能有多个线程呢？ JavaScript的单线程，与它的用途有关。作为浏览器脚本语言，JavaScript的主要用途是与用户互动，以及操作DOM。这决定了它只能是单线程，否则会带来很复杂的同步问题。比如，假定JavaScript同时有两个线程，一个线程在某个DOM节点上添加内容，另一个线程删除了这个节点，这时浏览器应该以哪个线程为准？所以，渲染DOM的线程和JavaScript执行的线程一定是互斥的。 所以，为了避免复杂性，从一诞生，JavaScript就是单线程，这已经成了这门语言的核心特征，将来也不会改变。为了利用多核CPU的计算能力，HTML5提出Web Worker标准，允许JavaScript脚本创建多个线程，但是子线程完全受主线程控制，且不得操作DOM。所以，这个新标准并没有改变JavaScript单线程的本质。 虽然JS是单线程的但是浏览器的内核是多线程的，在浏览器的内核中不同的异步操作由不同的浏览器内核模块调度执行，异步操作会将相关回调添加到任务队列中。而不同的异步操作添加到任务队列的时机也不同，如 onclick, setTimeout, ajax 处理的方式都不同，这些异步操作是由浏览器内核的 webcore 来执行的，webcore 包含上图中的3种 webAPI，分别是 DOM Binding、network、timer模块。 onclick由浏览器内核的DOM Binding模块来处理，当事件触发的时候，回调函数会立即添加到任务队列中。 setTimeout会由浏览器内核的timer模块来进行延时处理，当时间到达的时候，才会将回调函数添加到任务队列中。 ajax则会由浏览器内核的network模块来处理，在网络请求完成返回之后，才将回调添加到任务队列中。 同步和异步假设存在一个函数A：A(args...);同步：如果在函数A返回的时候，调用者就能够得到预期结果(即拿到了预期的返回值或者看到了预期的效果)，那么这个函数就是同步的。例如：👇12Math.sqrt(2);console.log('Hi'); 第一个函数返回时，就拿到了预期的返回值：2的平方根。 第二个函数返回时，就看到了预期的效果：在控制台打印了一个字符串。 所以这两个函数都是同步的。 异步：如果在函数A返回的时候，调用者还不能够得到预期结果，而是需要在将来通过一定的手段得到，那么这个函数就是异步的。例如：👇123fs.readFile('foo.txt', 'utf8', function(err, data) &#123; console.log(data);&#125;); 在上面的代码中，我们希望通过fs.readFile函数读取文件foo.txt中的内容，并打印出来。但是在fs.readFile函数返回时，我们期望的结果并不会发生，而是要等到文件全部读取完成之后。如果文件很大的话可能要很长时间。 下面以AJAX请求为例，来看一下同步和异步的区别： 异步AJAX： 主线程：“你好，AJAX线程。请你帮我发个HTTP请求吧，我把请求地址和参数都给你了。” AJAX线程：“好的，主线程。我马上去发，但可能要花点儿时间呢，你可以先去忙别的。” 主线程：：“谢谢，你拿到响应后告诉我一声啊。”(接着，主线程做其他事情去了。一顿饭的时间后，它收到了响应到达的通知。) 同步AJAX： 主线程：“你好，AJAX线程。请你帮我发个HTTP请求吧，我把请求地址和参数都给你了。” AJAX线程：“……” 主线程：：“喂，AJAX线程，你怎么不说话？” AJAX线程：“……” 主线程：：“喂！喂喂喂！” AJAX线程：“……” (一炷香的时间后…) 主线程：：“喂！求你说句话吧！” AJAX线程：“主线程，不好意思，我在工作的时候不能说话。你的请求已经发完了，拿到响应数据了，给你。” 正是由于JavaScript是单线程的，而异步容易实现非阻塞，所以在JavaScript中对于耗时的操作或者时间不确定的操作，使用异步就成了必然的选择。 异步过程的构成要素从上文可以看出，异步函数实际上很快就调用完成了。但是后面还有工作线程执行异步任务、通知主线程、主线程调用回调函数等很多步骤。我们把整个过程叫做异步过程。异步函数的调用在整个异步过程中，只是一小部分。 总结一下，一个异步过程通常是这样的： 主线程发起一个异步请求，相应的工作线程接收请求并告知主线程已收到(异步函数返回)；主线程可以继续执行后面的代码，同时工作线程执行异步任务；工作线程完成工作后，通知主线程；主线程收到通知后，执行一定的动作(调用回调函数)。 异步函数通常是这样的形式：A(args..., callbackFn)。它可以叫做异步过程的发起函数，或者叫做异步任务注册函数。args是这个函数需要的参数。callbackFn也是这个函数的参数，但是它比较特殊所以单独列出来。 所以，从主线程的角度看，一个异步过程包括下面两个要素： 发起函数(或叫注册函数)A 回调函数callbackFn 它们都是在主线程上调用的，其中注册函数用来发起异步过程，回调函数用来处理结果。 举个具体的例子：1setTimeout(fn, 1000); 其中的setTimeout就是异步过程的发起函数，fn是回调函数。注意：前面说的形式A(args..., callbackFn)只是一种抽象的表示，并不代表回调函数一定要作为发起函数的参数，例如：👇12345var xhr = new XMLHttpRequest();xhr.open('GET', url);xhr.onload = xxx; // 添加回调函数xhr.onerror = xxx; // 添加回调函数xhr.send(); // 发起函数 发起函数和回调函数就是分离的，发起函数和回调函数位置互换也是不影响的。也就是说，指定回调函数的部分（onload和onerror），在send()方法的前面或后面无关紧要，因为它们属于执行栈的一部分，系统总是执行完它们，才会去读取“任务队列”。 消息队列和事件循环上文讲到，异步过程中，工作线程在异步操作完成后需要通知主线程。那么这个通知机制是怎样实现的呢？答案是利用消息队列和事件循环。用一句话概括： 工作线程将消息放到消息队列，主线程通过事件循环过程去取消息。 消息队列：消息队列是一个先进先出的队列，它里面存放着各种消息。 事件循环：事件循环是指主线程重复从消息队列中取消息、执行的过程。 实际上，主线程只会做一件事情，就是从消息队列里面取消息、执行消息，再取消息、再执行。当消息队列为空时，就会等待直到消息队列变成非空。而且主线程只有在将当前的消息执行完成后，才会去取下一个消息。这种机制就叫做事件循环机制，取一个消息并执行的过程叫做一次循环。伪代码表示类似123while (queue.waitForMessage()) &#123; queue.processNextMessage();&#125; 如果当前没有任何消息queue.waitForMessage 会等待同步消息到达。执行机制如下： 所有同步任务都在主线程上执行，形成一个执行栈（execution context stack）。 主线程之外，还存在一个“任务队列”（task queue）。只要异步任务有了运行结果，就在”任务队列”之中放置一个事件。 一旦“执行栈”中的所有同步任务执行完毕，系统就会读取“任务队列”，看看里面有哪些事件。那些对应的异步任务，于是结束等待状态，进入执行栈，开始执行。 主线程不断重复上面的第三步。 执行至完成每一个消息完整的执行后，其它消息才会被执行。当你分析你的程序时，这点提供了一些优秀的特性，包括每当一个函数运行时，该函数占用的(线程)资源不能被抢占，并且在其他代码运行之前完全运行（且可以修改此函数操作的数据）。这与C语言不同，例如，如果函数在线程中运行，则可以在任何位置终止然后在另一个线程中运行其他代码。 这个模型的一个缺点在于当一个消息需要太长时间才能完成，Web应用无法处理用户的交互，例如点击或滚动。一个很好的做法是使消息处理缩短，如果可能，将一个消息裁剪成几个消息。 添加消息在浏览器里，当一个事件出现且该对象(this)绑定了事件监听器，消息可能随时被添加。如果没有事件监听器，事件该会丢失。所以点击一个附带点击事件处理函数的元素会添加一个消息。其它事件亦然。 1234var button = document.getElement('#btn');button.addEventListener('click', function(e) &#123; console.log();&#125;); 从事件的角度来看，上述代码表示：在按钮上添加了一个鼠标单击事件的事件监听器；当用户点击按钮时，鼠标单击事件触发，事件监听器函数被调用。 从异步过程的角度看，addEventListener函数就是异步过程的发起函数，事件监听器函数就是异步过程的回调函数。事件触发时，表示异步任务完成，会将事件监听器函数封装成一条消息放到消息队列中，等待主线程执行。 从生产者与消费者的角度看，异步过程是这样的：工作线程是生产者，主线程是消费者(只有一个消费者)。工作线程执行异步任务，执行完成后把对应的回调函数封装成一条消息放到消息队列中；主线程不断地从消息队列中取消息并执行，当消息队列空时主线程阻塞，直到消息队列再次非空。 事件的概念实际上并不是必须的，事件机制实际上就是异步过程的通知机制。我觉得它的存在是为了编程接口对开发者更友好。 另一方面，所有的异步过程也都可以用事件来描述。例如：setTimeout可以看成对应一个时间到了！的事件。前文的setTimeout(fn, 1000);可以看成：1timer.addEventListener('timeout', 1000, fn); 调用 setTimeout 函数会在一个时间段过去后在队列中添加一个消息。这个时间段作为函数的第二个参数被传入。如果队列中没有其它消息，消息会被马上处理。但是，如果有其它消息，setTimeout消息必须等待其它消息处理完。因此第二个参数仅仅表示需要等待的最小时间,而非确切的时间。 零延迟零延迟并不是意味着回调会立即执行。在零延迟调用 setTimeout 时，并不是过了给定的时间间隔后就马上执行回调函数。其等待的时间基于队列里正在等待的消息数量。在下面的例子中，”this is just a message” 将会在回调 (callback) 获得处理之前输出到控制台，这是因为延迟是要求运行时 (runtime) 处理请求所需的最小时间，但不是有所保证的时间。👇12345678910111213141516171819(function () &#123; console.log('this is the start'); setTimeout(function cb() &#123; console.log('this is a msg from call back'); &#125;); console.log('this is just a message'); setTimeout(function cb1() &#123; console.log('this is a msg from call back1'); &#125;, 0); console.log('this is the end');&#125;)();// "this is the start"// "this is just a message"// "this is the end"// "this is a msg from call back"// "this is a msg from call back1" …扯远了，，那么，消息队列中放的消息具体是什么东西？消息的具体结构当然跟具体的实现有关，但是为了简单起见，我们可以认为： 消息就是注册异步任务时添加的回调函数。 再次以异步AJAX为例，假设存在如下的代码：12345678$.ajax('http://segmentfault.com', function(resp) &#123; console.log('我是响应：', resp);&#125;);// 其他代码......... 主线程在发起AJAX请求后，会继续执行其他代码。AJAX线程负责请求segmentfault.com，拿到响应后，它会把响应封装成一个JavaScript对象，然后构造一条消息：1234// 消息队列中的消息就长这个样子var message = function () &#123; callbackFn(response);&#125; 其中的callbackFn就是前面代码中得到成功响应时的回调函数。 主线程在执行完当前循环中的所有代码后，就会到消息队列取出这条消息(也就是message函数)，并执行它。到此为止，就完成了工作线程对主线程的通知，回调函数也就得到了执行。如果一开始主线程就没有提供回调函数，AJAX线程在收到HTTP响应后，也就没必要通知主线程，从而也没必要往消息队列放消息。如图👇 主线程从任务队列中读取事件，这个过程是循环不断的，所以整个的这种运行机制又称为Event Loop（事件循环）。为了更好地理解Event Loop，请看下图（转引自Philip Roberts的演讲《Help, I’m stuck in an event-loop》）。上图中，主线程运行的时候，产生堆（heap）和栈（stack），栈中的代码调用各种外部API，它们在”任务队列”中加入各种事件（click，load，done）。只要栈中的代码执行完毕，主线程就会去读取任务队列，依次执行那些事件所对应的回调函数。 永不阻塞事件循环模型的一个非常有趣的特性是 JavaScript，与许多其他语言不同，它永不阻塞。 处理 I/O 通常通过事件和回调来执行，所以当一个应用正等待IndexedDB查询返回或者一个 XHR 请求返回时，它仍然可以处理其它事情，如用户输入。 Rime例外是存在的，如 alert或者同步 XHR，但应该尽量避免使用它们。注意，例外的例外也是存在的（但通常是实现错误而非其它原因）。 文章引自： https://segmentfault.com/a/1190000004322358 http://www.ruanyifeng.com/blog/2014/10/event-loop.html https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/EventLoop]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaScript执行顺序]]></title>
    <url>%2F2017%2F12%2F02%2Fexecution_sequence_of_javascript%2F</url>
    <content type="text"><![CDATA[JavaScript执行顺序JavaScript(以下简称js) 是一种描述型脚本语言，由浏览器进行动态的解析与执行。由于js编写位置比较灵活，所以处在不同位置的js代码执行顺序也是不同的。js和其他编程语言相比比较随意，所以js代码中充满各种奇葩的写法。苦逼的公司造就苦逼程序员全栈工程师，工作中总是经常自己写些简单的前端页面，经常被js的执行顺序袭扰，索性找个大块儿时间好好学习总结下，理解各型各色的写法，希望能对js的语言特性有深入的理解。 函数的声明和调用函数的定义方式大体有以下两种，浏览器对于不同的方式有不同的解析顺序。 使用function关键字声明一个函数，再指定一个函数名，叫函数声明。 123function Fn1()&#123; alert("Hello World!"); &#125; 使用function关键字声明一个函数，但未给函数命名，最后将匿名函数赋予一个变量，叫函数表达式，这是最常见的函数表达式语法形式。 123var Fn2 = function()&#123; alert("Hello World!"); &#125; 如果遇到函数声明，则进行预处理(类似C语言的编译)；如果遇到函数表达式，则只是将函数赋值给一个变量，不进行预处理，待调用的时候再进行处理。@(#函数声明)1234Fn1();function Fn1()&#123; alert("Hello World!");&#125; 👆↑ 这段代码()可以正常运行，弹出”Hello World!”警告对话框。浏览器对Fn1()进行了预处理，再从Fn1()；开始运行。 再如：@(#函数表达式)1234Fn2();var Fn2 = function()&#123; alert("Hello World!");&#125; 👆↑ 这段代码会在Chrome浏览器报错，DevTools会提示Uncaught TypeError: Fn2 is not a function。浏览器未对Fn2进行预处理，依序执行，所以报错Fn2不是函数。 js代码块及引用的外部js文件的处理这里js代码块指的是一对&lt;script type=&quot;text/javascript&quot; charset=&quot;utf-8&quot;&gt;some js code&lt;/script&gt;标签中间包裹着的js代码；外部引用的文件指的是&lt;script src=&quot;/javascripts/application.js&quot; type=&quot;text/javascript&quot; charset=&quot;utf-8&quot; async defer&gt;&lt;/script&gt;中src属性中路径下的js文件中的代码。 页面加载过程中，浏览器会对每个js代码块或文件进行独立扫描。所以在一个块或文件中，函数可以先调用，再进行函数声明(#函数声明)；但两个块中，函数声明所在的块必须在函数调用所在的块之前。略绕，，看例子👇↓1234567891011121314&lt;script type="text/javascript"&gt; Fn();&lt;/script&gt;&lt;script type="text/javascript"&gt;function Fn()&#123; alert('Hello World!');&#125;&lt;/script&gt;---------------------//Uncaught ReferenceError: Fn is not defined//报错 Fn 未被定义//两个script代码块换下位置就可以正常运行了~--------------------- 需要注意的是，外部引用的js文件也存在这种情况，，js文件中定义的变量和函数只能在之后引用。即js.js文件中以函数声明的方式定义了fn..👇↓123456789&lt;script type='text/javascript'&gt; fn();&lt;/script&gt;&lt;script scr='tesTjs.js' type='text/javascript'&gt;&lt;/script&gt;---------------------//Uncaught ReferenceError: fn is not defined//报错 fn 未被定义//两个script代码块换下位置就可以正常运行了--------------------- 重复定义函数会覆盖前面的定义这和变量的重复定义是一样的，，👇↓12345678function fn()&#123; alert(1); &#125; function fn()&#123; alert(2); &#125; fn(); // 弹出：“2” 但如果是这样呢，，👇↓12345678fn(); function fn()&#123; alert(1); &#125; function fn()&#123; alert(2); &#125; // 还是弹出：“2” body标签内的onload属性与body标签之间函数的执行body内部的函数会先于onload的函数执行，测试代码：👇↓12345678910111213//html head... &lt;script type="text/javascript"&gt; function fnOnLoad()&#123; alert("I am outside the Wall!"); &#125; &lt;/script&gt; &lt;body onload="fnOnLoad();"&gt; &lt;script type="text/javascript"&gt; alert("I am inside the Wall.."); &lt;/script&gt; &lt;/body&gt; //先弹出“I am inside the Wall..”; //后弹出“I am outside the Wall!” body的onload事件触发条件是body内容加载完成，，所以在加载body内容的过程中执行了&lt;script&gt;标签中的alert(&quot;I am inside the Wall..&quot;);。至此body标签中的内容加载完成，触发body标签中onload函数，执行fnOnLoad方法。 script标签放在什么位置scripts会引发阻塞并行下载的问题。HTTP/1.1 specification建议每次不要同时从一个hostname下载超过两个的组件。如果你把网站上引用的图片放在不同hostname上，那么每次加载该网页时，可以下载同时两个以上的图片资源。然而，当引用的外部js文件正在下载时，无论其他资源是否与该js文件处于同一hostnamme，都不能(并行)下载。所以yahoo建议将script放在尾部，这样能加速网页加载。^1 将script放在尾部的缺点，是浏览器只能先解析完整个HTML页面，再下载JS。而对于一些高度依赖于JS的网页，就会显得慢了。所以将script放在尾部也不是最优解，最优解是一边解析页面，一边下载JS。所以，出现了一种更modern的方式：使用async和defer。80%的现代浏览器都认识async和defer属性[3]，这两个属性能让浏览器做到一边下载JS(还是只能同时下载两个JS)，一边解析HTML。他的优点不是增加JS的并发下载数量，而是做到下载时不block解析HTML。^212&lt;script type="text/javascript" src="path/to/script1.js" async&gt;&lt;/script&gt; &lt;script type="text/javascript" src="path/to/script2.js" async&gt;&lt;/script&gt; 带async属性的script会异步执行，只要下载完就执行，这会导致script2.js可能先于script1.js执行（如果script2.js比较大，下载慢）。defer就能保证script有序执行，script1.js先执行，script2.js后执行。 参考链接：http://www.jb51.net/article/36755.htmhttps://developers.google.com/speed/docs/insights/BlockingJShttps://developers.google.com/speed/docs/insights/OptimizeCSSDeliveryhttps://developers.google.com/speed/docs/insights/PrioritizeVisibleContent]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP重传机制]]></title>
    <url>%2F2017%2F11%2F14%2Ftcp_retransmission_mechanism%2F</url>
    <content type="text"><![CDATA[TCP重传机制TCP要保证所有的数据包都可以到达，所以，必需要有重传机制。 注意，接收端给发送端的ACK只会确认最后一个连续的包。比如，发送端发了#1,#2,#3,#4,#5一共五份数据，接收端收到了#1，#2，于是返回ACK=3，然后收到了#4（#3未收到），此时的TCP会怎么办？我们要知道，seq和ACK是以字节数为单位，所以返回ack的时候，不能跳着确认，只能确认最大的连续收到的包，不然，发送端就以为之前的都收到了。 超时重传机制一种是不返回ack，死等#3，当发送方发现收不到#3的ack超时后，会重传#3。一旦接收方收到#3后，会ack返回4——意味着#3和#4都收到了。 但是，这种方式会有比较严重的问题，那就是因为要死等#3，所以会导致#4和#5即便已经收到了，而发送方也完全不知道发生了什么事，因为没有收到ACK，所以，发送方可能会悲观地认为也丢了，所以有可能也会导致4#和#5的重传。 对此有两种选择： 仅重传 timeout 的包。也就是第3份数据。 重传 timeout 后所有的数据，也就是#3，#4，#5这三份数据。 第一种会节省带宽，但是慢；第二种会快一点，但是会浪费带宽，也可能会做无用功。但总体来说都不好。因为都在等 timeout，timeout 可能会很长。 快速重传机制于是，TCP引入了一种叫 Fast Retransmit 的算法，不以时间驱动，而以数据驱动重传。也就是说，如果包没有连续到达，就ack最后那个可能被丢了的包，如果发送方连续收到3次相同的ack，就重传。Fast Retransmit 的好处是不用等 timeout 了再重传。 比如：如果发送方发出了#1，#2，#3，#4，#5份数据，第一份先到送了，于是就ack回2，结果#2因为某些原因没收到，3到达了，于是还是ack回2，后面的#4和#5都到了，但是还是ack回#2，因为2还是没有收到，于是发送端收到了三个ack=2的确认，知道了#2还没有到，于是就马上重传#2。然后，接收端收到了#2，此时因为#3，#4，#5都收到了，于是ack回6。示意图如下： Fast Retransmit 只解决了一个问题，就是timeout 的问题，它依然面临一个艰难的选择，就是重传之前的一个，还是重传所有的问题。对于上面的示例来说，是重传#2呢,还是重传#2，#3，#4，#5呢？因为发送端并不清楚这连续的3个ack(#2)是谁传回来的？也许发送端发了20份数据，是#6，#10，#20传来的呢。这样，发送端很有可能要重传从#2到#20的这堆数据（这就是某些TCP的实际的实现）。可见，这是一把双刃剑。 SACK 方法另外一种更好的方式叫：Selective Acknowledgment (SACK)（参看RFC 2018），这种方式需要在TCP头里加一个SACK的东西，ACK还是Fast Retransmit的 ACK，SACK则是汇报收到的数据碎版。参看下图： 这样，在发送端就可以根据回传的SACK来知道哪些数据到了，哪些没有到。于是就优化了Fast Retransmit 的算法。当然，这个协议需要两边都支持。在 Linux下，可以通过tcp_sack参数打开这个功能（Linux 2.4后默认打开）。 这里还需要注意一个问题——接收方Reneging，所谓Reneging的意思就是接收方有权把已经报给发送端SACK里的数据给丢了。这样干是不被鼓励的，因为这个事会把问题复杂化了，但是，接收方这么做可能会有些极端情况，比如要把内存给别的更重要的东西。所以，发送方也不能完全依赖SACK，还是要依赖ACK，并维护Timeout，如果后续的ack没有增长，那么还是要把SACK的东西重传，另外，接收端这边永远不能把SACK的包标记为ACK。 注意：SACK会消费发送方的资源，,试想，如果一个攻击者给数据发送方发一堆SACK的选项，这会导致发送方开始要重传甚至遍历已经发出的数据，这会消耗很多发送端的资源。详细的东西请参看《TCP SACK的性能权衡》 Duplicate SACK – 重复收到数据的问题Duplicate SACK又称D-SACK，其主要使用了 SACK来告诉发送方有哪些数据被重复接收了。RFC-2833 里有详细描述和示例。下面举几个例子（来源于RFC-2833） D-SACK使用了SACK的第一个段来做标志，如果SACK的第一个段的范围被ACK所覆盖，那么就是D-SACK;如果SACK的第一个段的范围被SACK的第二个段覆盖，那么就是D-SACK。 示例一：ACK丢包下面的示例中，丢了两个ACK，所以，发送端重传了第一个数据包（3000-3499），于是接收端发现重复收到，于是回了一个SACK=3000-3500，因为ACK都到了#4000意味着收到了#4000之前的所有数据，所以这个SACK就是D-SACK——旨在告诉发送端我收到了重复的数据，而且我们的发送端还知道，数据包没有丢，丢的是ACK包。 Transmitted Received ACK Sent Segment Segment (Including SACK Blocks) 3000-3499 3000-3499 3500 (ACK dropped) 3500-3999 3500-3999 4000 (ACK dropped) 3000-3499 3000-3499 4000, SACK=3000-3500 示例二：网络延误下面的示例中，网络包（1000-1499）被网络给延误了，导致发送方没有收到ACK，而后面到达的三个包触发了Fast Retransmit 算法，所以重传，但重传时，被延误的包又到了，所以，回了一个SACK=1000-1500，因为ACK已到了#3000，所以，这个SACK是D-SACK——标识收到了重复的包。 这个案例下，发送端知道之前因为“Fast Retransmit算法”触发的重传不是因为发出去的包丢了，也不是因为回应的ACK包丢了，而是因为网络延时了。 Transmitted Received ACK Sent Segment Segment (Including SACK Blocks) 500-999 500-999 1000 1000-1499 (delayed) 1500-1999 1500-1999 1000, SACK=1500-2000 2000-2499 2000-2499 1000, SACK=1500-2500 2500-2999 2500-2999 1000, SACK=1500-3000 1000-1499 1000-1499 3000 1000-1499 3000, SACK=1000-1500 可见，引入了D-SACK，有这么几个好处： 可以让发送方知道，是发出去的包丢了，还是回来的ACK包丢了。 是不是自己的 timeout太小了，导致重传。 网络上出现了先发的包后到的情况（又称reordering） 网络上是不是把我的数据包给复制了。 知道这些东西可以很好得帮助TCP了解网络情况，从而可以更好的做网络上的流控。Linux下的tcp_dsack参数用于开启这个功能（Linux 2.4后默认打开） 转载自：http://www.uml.org.cn/safe/201407041.asp?artid=2511 作者：火龙果软件]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>TCP</tag>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP连接的建立与释放]]></title>
    <url>%2F2017%2F10%2F19%2Festablishment_release_of_tcp-connections%2F</url>
    <content type="text"><![CDATA[TCP 连接的建立与释放TCP 是面向连接的，无论哪一方向另一方发送数据之前，都必须先在双方之间建立一条连接。在TCP/IP协议中，TCP协议提供可靠的连接服务，连接是通过三次握手进行初始化的。 TCP 连接的三个阶段： 连接建立。 数据传送。 连接释放。 TCP 连接建立过程中要解决的问题： 每一方能够确知对方的存在。 允许双方协商参数。如：Sequence Number初始值，最大窗口值，是否使用窗口扩大选项，是否使用时间戳选项，服务质量… 能够对运输实体资源进行分配。如：缓存大小，连接表中的项目… 建立TCP连接-三次握手 最初两端的 TCP 都处在 CLOSED状态。 B的 TCP 服务器进程创建传输控制块 TCB，服务器进程进入LISTEN（收听）状态，等待客户的连接请求。传输控制块：Transmission Control Block,TCB，存储连接中的信息。如：TCP 连接表，到发送和接收缓存的指针，到重传队列的指针，当前发送和接收序号… A的 TCP 客户进程创建传输控制块 TCB ，向B发出连接请求报文段。这时，首部中同步位SYN=1，初始序号seq=x。SYN报文段不携带数据，但要消耗一个序号。TCP 客户进程进入SYN-SENT（同步已发送）状态。 B收到连接请求报文段，如果同意建立连接，则向A发送确认。确认报文段中，SYN和ACK都为1，确认号ack=x+1，并选择自己的初始序号seq=y。此报文段同样不携带数据，但要消耗一个序号。TCP服务器进程进入SYN-RCVD(同步接收)状态。 TCP 客户进程收到B的确认后，向B发出确认。确认报文段的ACK=1，确认号ack=y+1，自己的seq=x+1。ACK报文段可携带数据，不携带数据则不消耗序号。TCP 连接已建立，A进入ESTABLISHED(已连接)状态。 B收到A的确认，也进入ESTABLISHED状态。 A 收到 B 的确认，为什么还要再次向 B 发送确认？为了防止已失效的连接请求报文段突然又传送到了服务端，而产生错误。 举个栗子: A 向 B 发出连接请求报文段，如果 client 发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达 server 。本来这是一个早已失效的报文段，但 server 收到此失效的连接请求报文段后，就误认为是 client 再次发出的一个新的连接请求。于是就向 client 发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要 server 发出确认，新的连接就建立了。由于现在 client 并没有请求建立连接，因此不会理睬 server 的确认，也不会向 server 发送数据。但 server 却以为新的运输连接已经建立，并一直等待 client 发来数据。这样，server 的很多资源就白白浪费掉了。采用『三次握手』的办法可以防止上述现象发生。例如刚才那种情况， client 不会向 server 的确认发出确认。server 由于收不到确认，就知道 client 并没有要求建立连接。 —— 谢希仁的《计算机网络》 释放TCP连接-四次挥手 开始时，A和B都处在ESTABLISHED状态。 A的应用进程向 TCP 发出连接释放连接报文段，停止发送数据，关闭 TCP 连接。A把报文段头部中FIN置为1，序号seq=u，u是已传送的数据的最后一个字节序号加1。A进入FIN-WAIT-1状态，等待B的确认。FIN报文段即使不携带数据，也要消耗一个序号。 B收到连接释放报文段向A发出确认，确认号ack=u+1，B自己的序号是v，v是已传送过的数据的最后一个字节加1。B进入CLOSE-WAIT状态。TCP 服务器进程通知高层应用进程，从A到B的连接被释放。TCP 进入half-close状态。 A收到B的确认，进入FIN-WAIT-2状态，等待B发出连接释放报文段。 B应用进程通知 TCP 释放连接，报文段首部FIN=1，序号为w（半关闭状态时B可能又发送了一些数据），B重复上次发送的确认号ack=u+1。B进入LAST-ACK(最后确认)状态，等待A的确认。 A收到B的连接释放报文段，向B发出确认。确认报文段中ACK=1，确认号ack=w+1，A自己的序号seq=u+1(发送的FIN报文段使用一个序号)。A进入TIME-WAIT(时间等待)状态。 经过时间等待计时器（TIME-WAIT timer）设置的时间2 MSL 后，A进入CLOSED状态。最长报文段寿命：Maximum Segment Lifetime,MSL，TCP 允许根据不同情况调整此值，RFC 793建议时间2分钟。 B收到A的确认，进入CLOSED状态，撤销传输控制块 TCB，TCP 连接释放成功。 对于4次挥手，其实是2次，因为 TCP 是全双工的。所以，发送方和接收方都需要FIN和ACK。只不过，有一方是被动的，所以看上去就成了所谓的4次挥手。如果两边同时断连接，那就会就进入到CLOSING状态，然后到达TIME_WAIT状态。@(TCP两端同时断开连接) A 为什么在 TIME-WAIT 状态等待2 MSL 时间?保证A发送的最后一个ACK报文段能够到达B。若此报文段丢失，处在LAST-ACK状态的B收不到FIN+ACK报文段的确认，B将超时重传FIN+ACK报文段，A可在2 MSL 时间内收到重传的FIN+ACK报文段。A重传确认，重新启动2MSL计时器，保证A和B顺利进入CLOSED状态，防止“已失效连接请求报文段”。A等待2 MSL，可使本连接持续时间内所产生的所有报文段全部从网络中消失。** 什么是时间保活计时器？为什么设置时间保活计时器？时间保活计时器(keepalive timer)：服务器每收到一次数据，就重新设置保活计时器，时间2小时。超时后还未收到客户数据，服务器发送探测报文段，以后每隔75分钟发送一次。连续发送10个探测报文段客户仍无响应，服务器关闭 TCP 连接。设置保活计时器的原因：处在 TCP 连接状态时，若A出现故障，防止B一直等待下去。 方框：TCP状态。箭头：状态变迁。箭头旁边的字：1.引起状态变迁的原因。2.发生状态变迁后出现的动作。粗实线箭头：客户进程的正常变迁。粗虚线箭头：服务器进程的正常变迁。细线箭头：异常变迁。 另外… 关于建连接时SYN超时。试想一下，如果 serve r端接到了 clien 发的SYN后回了SYN-ACK后 client 掉线了，server 端没有收到 client 回来的ACK，那么，这个连接处于一个中间状态，即没成功，也没失败。于是，server 端如果在一定时间内没有收到的 TCP 会重发SYN-ACK。在 Linux 下，默认重试次数为5次，重试的间隔时间从1s开始每次都翻售，5次的重试时间间隔为1s, 2s, 4s, 8s, 16s，总共31s，第5次发出后还要等32s都知道第5次也超时了，所以，总共需要 1s + 2s + 4s+ 8s+ 16s + 32s = 2^6 -1 = 63s，TCP 才会把断开这个连接。 关于SYN Flood 攻击。一些恶意的人就为此制造了 SYN Flood攻击——给服务器发了一个SYN后，就下线了，于是服务器需要默认等63s才会断开连接，这样，攻击者就可以把服务器的SYN连接的队列耗尽，让正常的连接请求不能处理。于是，Linux 下给了一个叫 tcp_syncookies 的参数来应对这个事——当SYN队列满了后，TCP 会通过源地址端口、目标地址端口和时间戳打造出一个特别的 Sequence Number 发回去（又叫cookie），如果是攻击者则不会有响应，如果是正常连接，则会把这个 SYN Cookie发回来，然后服务端可以通过 cookie 建连接（即使你不在SYN队列中）。请注意，请先千万别用 tcp_syncookies来处理正常的大负载的连接的情况。因为，SYN Cookies是妥协版的 TCP 协议，并不严谨。对于正常的请求，你应该调整三个 TCP 参数可供你选择: tcp_synack_retries 可以用他来减少重试次数； tcp_max_syn_backlog，可以增大SYN连接数； tcp_abort_on_overflow 处理不过来干脆就直接拒绝连接了。 关于ISN的初始化。ISN是不能 hard code(硬编码)，不然会出问题的——比如：如果连接建好后始终用1来做ISN，如果 client 发了30个 segment 过去，但是网络断了，于是 client 重连，又用了1做ISN，但是之前连接的那些包到了，于是就被当成了新连接的包，此时，client 的Sequence Number 可能是3，而 Server 端认为client 端的这个号是30了。全乱了。RFC793中说，ISN会和一个假的时钟绑在一起，这个时钟会在每4微秒对ISN做加一操作，直到超过2^32，又从0开始。这样，一个ISN的周期大约是4.55个小时。因为，我们假设我们的 TCP Segment 在网络上的存活时间不会超过Maximum Segment Lifetime（缩写为MSL - Wikipedia语条），所以，只要MSL的值小于4.55小时，那么，我们就不会重用到ISN。 关于MSL和TIME_WAIT。通过上面的ISN的描述，相信你也知道MSL是怎么来的了。我们注意到，在 TCP 的状态图中，从TIME_WAIT状态到CLOSED状态，有一个超时设置，这个超时设置是 2*MSL（RFC793定义了MSL为2分钟，Linux 设置成了30s）为什么要这有TIME_WAIT？为什么不直接给转成CLOSED状态呢？主要有两个原因： TIME_WAIT确保有足够的时间让对端收到了ACK，如果被动关闭的那方没有收到ACK，就会触发被动端重发FIN，一来一去正好2个MSL; 有足够的时间让这个连接不会跟后面的连接混在一起（你要知道，有些自做主张的路由器会缓存IP数据包，如果连接被重用了，那么这些延迟收到的包就有可能会跟新连接混在一起）。你可以看看这篇文章《TIME_WAIT and its design implications for protocols and scalable client server systems》 参考链接：http://www.imooc.com/article/17411 作者：江户川秋风http://www.jellythink.com/archives/705 作者：果冻想http://www.cnblogs.com/lshs/p/6038458.html 作者：lshs]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>TCP</tag>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于TCP协议]]></title>
    <url>%2F2017%2F10%2F18%2Fabout_tcp%2F</url>
    <content type="text"><![CDATA[关于TCPTCP 简介TCP协议具体是什么，不赘述，百度之。 我们经常听人说 TCP 是一个面向连接的(connection-oriented)、可靠的(reliable)、字节流式(byte stream)传输协议，TCP 的这三个特性该怎么理解呢？ 面向连接：在应用 TCP 协议进行通信之前双方通常需要通过三次握手来建立 TCP 连接，连接建立后才能进行正常的数据传输，因此广播和多播不会承载在 TCP 协议上。(谷歌提交了一个 RFC 文档，建议在 TCP 三次握手的过程允许 SYN 数据包中带数据，即 TFO(TCP Fast Open)，目前 ubuntu 14.04已经支持该 TFO 功能)。但是同时面向连接的特性给 TCP 带来了复杂的连接管理以及用于检测连接状态的存活检测机制。 可靠性：由于 TCP 处于多跳通信的 IP 层之上，而 IP 层并不提供可靠的传输，因此在TCP层看来就有四种常见传输错误问题，分别是比特错误(packet bit errors)、包乱序(packet reordering)、包重复(packet duplication)、丢包(packet erasure或称为packet drops)，TCP 要提可靠的传输，就需要有额外的机制处理这几种错误。因此可靠性体现在三个方面： TCP 通过超时重传和快速重传两个常见手段来保证数据包的正确传输，也就是说接收端在没有收到数据包或者收到错误的数据包的时候会触发发送端的数据包重传(处理比特错误和丢包)。 TCP 接收端会缓存接收到的乱序到达数据，重新排序后再向应用层提供有序的数据(处理包乱序)。 TCP 发送端会维持一个发送『窗口』动态的调整发送速率以适用接收端缓存限制和网络拥塞情况，避免了网络拥塞或者接收端缓存满而大量丢包的问题(降低丢包率)。因此可靠性需要 TCP 协议具有超时与重传管理、窗口管理、流量控制、拥塞控制等功能。另外 TFO 下 TCP 有可能向应用层提供重复的数据，也就是不可靠传输，但是只会发生在连接建立阶段。 字节流式：应用层发送的数据会在 TCP 的发送端缓存起来，统一分片(例如一个应用层的数据包分成两个 TCP 包)或者打包(例如两个或者多个应用层的数据包打包成一个 TCP 数据包)发送，到接收端的时候接收端也是直接按照字节流将数据传递给应用层。作为对比，同样是传输层的协议，UDP 并不会对应用层的数据包进行打包和分片的操作，一般一个应用层的数据包就对应一个 UDP 包。这个也是伴随 TCP 窗口管理、拥塞控制等。 TCP 的封装和协议头格式TCP 封装在IP报文中，如下图所示 TCP 的协议头格式 Source Port(源端口号)和Destination Port(目标端口号):各2字节用于区别主机中的不同进程。IP 地址用来区分不同的主机。如此，源 IP 地址+源端口号与目标 IP 地址+目标端口号就能确定唯一的 TCP 连接； Sequence Number(序列号&amp;封包序号):4字节定义了指派给本报文段第一个数据字节的编号。用来标识从TCP发送端向TCP接收端发送的数据字节流，它表示在这个报文段中的第一个数据字节在数据流中的序号。由于 TCP 封包必须要带入 IP 封包当中，所以如果 TCP 数据太大时(大于 IP 封包的容许程度)，就得要进行分段。这个 Sequence Number 就是记录每个封包的序号，可以让收收端重新将 TCP 的数据组合起来。建立连接时，双方使用各自的随机数生成器生产一个初始序号(inital squence number，ISN)，通常两个方向上的 ISN 是不同的。主要用来解决网络报乱序(reordering)的问题。 Acknowledgment Number(确认号):4字节确认号包含发送确认一端所期望收到的下一个序列号。即如果报文段的接收方成功地接收了对方发来的编号为x的字节，那么它就返回 x+1 作为确认号。不过，只有当编码位中的ACK为1时，该确认序列号的字段才有效。所以，当 client 端收到服务端响应的这个确认码时，就能确定之前发出的封包数据已经被完整的收到了。 Data Offset(数据偏移):4比特和IP数据包头部一样，TCP头部也有个Options字段，长度可变。为了确认整个TCP包大小，就需要这个标志来说明整个封包区段的起始位置。偏移量每增加1，报头长度就增加4字节，最小为5，最大15，即4*15=60个字节的头部长度。没有任何选项字段(TCP option)的TCP头部长度为20字节。 reserved(保留字段):4比特供将来使用。 Code Bits(编码位):8比特 CWR(Congestion Window Reduce):拥塞窗口减少标志,由发送主机设置，用来表明它接收到了设置ECE标志的TCP包，发送端通过降低发送窗口的大小来降低发送速率； ECE(ECN Echo)：被用来在TCP3次握手时表明一个TCP端是具备ECN功能的，并且表明接收到的TCP包的IP头部的ECN被设置为11； URG(urgent):取值1时，表明紧急指针字段(Urgent Pointer)有效,代表该封包为紧急封包。用来保证TCP连接不被中断，并且督促中间层设备要尽快处理这些数据； ACK(Acknowledge):取值1代表Acknowledgment Number字段有效，这是一个确认的TCP包，取值0则不是确认包。后续文章介绍中当ACK标志位有效的时候我们称呼这个包为ACK包，使用大写的ACK称呼。 PSH:(Push):取值1时，代表要求对方立即传送缓冲区内的其他对应封包转由应用处理，而不用进行队列处理，无需等缓冲满了再传送。 RST(Reset)：用于复位相应的TCP连接。通常在发生异常或者错误的时候会触发复位TCP连接,也被用来拒绝错误和非法的数据包。必须释放连接，然后再重新建立运输连接。 SYN(Synchronize)：表示同步序号，仅在三次握手建立TCP连接时有效，用来建立连接(SYN置为1，就表示这是一个连接请求或连接接受报文)。SYN标志位和ACK标志位搭配使用。当连接请求的时候，SYN=1，ACK=0；连接被响应的时候，SYN=1，ACK=1；这个标志的数据包经常被用来进行端口扫描。扫描者发送一个只有SYN的数据包，如果对方主机响应了一个数据包回来，就表明这台主机存在这个端口；但是由于这种扫描方式只是进行TCP三次握手的第一次握手，因此这种扫描的成功表示被扫描的机器不很安全，一台安全的主机将会强制要求一个连接严格的进行TCP的三次握手；当这个SYN标志位有效的时候我们称呼这个包为SYN包。 FIN(Finish)：带有该标志置位的数据包用来结束一个TCP会话(连接)，但对应端口仍处于开放状态，准备接收后续数据。当FIN标志有效的时候我们称呼这个包为FIN包。这个标志的数据包也经常被用于进行端口扫描。 Window(滑动窗口):2字节用来控制对方发送的数据量，可以告知对方目前本身有的缓冲器容量(Receive Buffer) 还可以接收封包。当 Window=0 时，代表缓冲器已经额满，所以应该要暂停传输数据。传输数据单位为字节。TCP连接的一端根据设置的缓存空间大小确定自己的接收窗口大小，然后通知对方以确定对方的发送窗口的上限,这个值是本机期望一次接收的字节数。用于TCP的流量控制；在TCP的发送端和接收端都会维持一个窗口，因为一个 TCP 连接是双向的，因此实际上一个 TCP 连接一共有四个窗口。此处我们先简单介绍一个发送端的窗口如下。图中的数字表示 byte 也就是和上面介绍的TCP协议头中的SN是对应的，3号 byte 以及3号之前的数据表示已经发送并且收到了接收端的ACK确认包的数据；4、5、6三个 byte 表示当前可以发送的数据包，也有可能已经已经发送了但是还没有收到ACK确认包；7号 byte 及之后的数据表示为了控制发送速率暂时不能发送的数据。其中4-6这三个 byte 就称呼为窗口大小(window size)。当 TCP 连接建立的时候，双方会通过 TCP 头中的窗口大小字段向对方通告自己接收端的窗口大小，发送端依据接收端通告的窗口大小来设置发送端的发送窗口大小，另外在拥塞控制的时候也是通过调整发送端的发送窗口来调整发送速率的。窗口这个词的来源就是当我们从这一个数据序列中单独看4、5、6这几个 byte 的时候，我们仿佛是从一个”窗口”中观察的一样。 Checksum(校验位):2字节发送端基于数据内容计算一个数值，接收端要与发送端数值结果完全一样，才能证明数据的有效性。接收端checksum校验失败的时候会直接丢掉这个数据包。CheckSum是根据伪头+TCP头+TCP数据三部分进行计算的。另外对于大的数据包，checksum并不能可靠的反应比特错误，应用层应该再添加自己的校验方式； Urgent Pointer(紧急指针):2字节指向后面是优先数据的字节,指出在本报文段中的紧急数据的最后一个字节的序号，在URG=1时有效。如果URG标志没有被设置，紧急域作为填充。加快处理标示为紧急的数据段; Options(选项):TCP首部可以有多达40字节的可选信息，用于把附加信息传递给终点，或用来对齐其它选项。 另外，我们一般称呼链路层的发出去的数据包为帧(frame)，称呼网络层发给链路层的数据包为包(packet)，称呼传输层发给网络层的数据包为段(segment)。但是正如我们描述所用，段、包、帧也经常统称为数据包或者数据报文。对应用层来说 TCP 是一个双向对称的全双工(full-duplex)协议，也就是说应用层可以同时发送数据和接收数据。这就意味着数据流在一个方向上的传输是独立于另一个方向的传输的，每个方向上都有独立的SN。 参考链接：http://www.imooc.com/article/17411 作者：江户川秋风http://www.jellythink.com/archives/705 作者：果冻想http://www.cnblogs.com/lshs/p/6038458.html 作者：lshs]]></content>
      <categories>
        <category>Java后时代</category>
      </categories>
      <tags>
        <tag>TCP</tag>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日记好像没有标题的吧？]]></title>
    <url>%2F2017%2F10%2F03%2Fthere_is_no_title_in_diary%2F</url>
    <content type="text"><![CDATA[国庆休息8天，赋闲在家，也只有在老家的时候可以做到晚上八点上床睡觉。。闲来无事，不记得之前在哪里看到的hexo博客搭建。昨天下午小事了一下，成就感满满。中途遇到访问本站总是跳转到 https://someiscoding.com ，但自己明明没有购买域名，导致每次DNS服务器无法解析地址。后来索性把GitHub上的账户名修改了下，重新配置了下_config文件，终于可以正常访问了。紧接着就是更换主题，选取比较稳妥的next主题，网上关于配置next的教程比较多，上手还快一些~因为中间一直使用终端，用的又是mac，不知道什么原因，终端中连ls命令都无法使用，总是提示命令无法找到什么的，一直以为是权限不够，需要开始ROOT权限。后来发现切换到bash中可以正常执行，默认启动的zsh不行。网上查了下，有的说是.zshrc文件中配置有问题，可能是PATH环境变量没有包括各种bin&amp;sbin。于是，在终端echo $PATH发现有bin和sbin。折腾了两个小时，还是误解，，罢了，索性备份了.zshrc文件，重新安装了oh-my-zsh。嗯，，完美！高兴！ 记第一篇流水账。]]></content>
      <categories>
        <category>呓语</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>oh-my-zsh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[my first shot]]></title>
    <url>%2F2017%2F10%2F02%2Fmy_first_shot%2F</url>
    <content type="text"><![CDATA[hello world!from Shang.]]></content>
      <categories>
        <category>呓语</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F10%2F02%2Fhello_world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <tags>
        <tag>diary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于我]]></title>
    <url>%2Fabout%2Findex.html</url>
    <content type="text"><![CDATA[半路出家的初级程序员全马PB324Finisher信息收集爱好者轻微数据洁癖终生学习者…嗯，我永远是人民的小学生~471293694@qq.com]]></content>
  </entry>
  <entry>
    <title><![CDATA[categories]]></title>
    <url>%2Fcategories%2Findex.html</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[tags]]></title>
    <url>%2Ftags%2Findex.html</url>
    <content type="text"></content>
  </entry>
</search>
